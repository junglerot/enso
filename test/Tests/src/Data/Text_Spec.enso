from Standard.Base import all

from Standard.Base.Data.Text.Extensions import Index_Out_Of_Bounds_Error_Data
import Standard.Base.Data.Text.Regex.Engine.Default as Default_Engine

from Standard.Base.Data.Text.Text_Sub_Range import all

import Standard.Test

type Auto
    Auto_Data a

type Manual
    Manual_Data b

Manual.to_text self = "[[[MyREP " + self.b.to_text + "]]]"

## Specification of operations on the Text type.

   ? Guidelines on proper handling of edge cases in Text tests:

     The following edge cases should be considered:
     - Handling of empty arguments.
     - Using grapheme-cluster based indexing instead of code unit indexing where
       appropriate: this can be tested by adding tests with graphemes that
       consist of multiple code units, like 'e\u{301}' or emojis and ensuring
       that the offsets are correct.
     - Correct handling of Unicode normalization: some graphemes can be
       expressed using different combinations of code units. All alternative
       representations of the same grapheme should be treated as equivalent, i.e.
       equality checks or substring search should work consistently. Interesting
       examples are:
       - 'e\u{301}' and '\u00E9' (both meaning 'é'),
       - reordering of modifiers (although this may not work for all sets), for
         example: 'e\u{321}\u{360}' should be equivalent to 'e\u{360}\u{321}'.
       - in general 's' should not be treated as a substring of 's\u{301}' since
         the latter is a two-codepoint encoding of a single grapheme 'ś' that is
         different from 's'.
     - Be aware that changing case can change the length of a string (in
       extended grapheme clusters), a common example being `ß` becoming `SS` or
       `ﬃ` becoming `FFI`. Case insensitive comparisons must take this into
       consideration. Note that due to this, if matching strings case
       insensitively, the length of the match can differ from the length of the
       term being matched.
     - Casing is locale-dependent. The pair of `i - I` is handled differently in
       Turkish and Azerbaijani - instead there are two separate pairs: 'İ - i'
       and 'I - ı'.
     - Handling of out of range indices should be checked. In particular, often
       the index `text.length` should still be valid to point just right at the
       end of the text. Moreover, negative indices are usually allowed to index
       from the back.
     - Note that currently the regex-based operations may not handle the edge
       cases described above too well.
spec =
    Test.group "Text" <|
        kshi = '\u0915\u094D\u0937\u093F'
        facepalm = '\u{1F926}\u{1F3FC}\u200D\u2642\uFE0F'
        accent_1 = '\u00E9'
        accent_2 = '\u0065\u{301}'
        utf_8_whitespace = 'foo\n bar     baz \u202F quux'
        utf_8_whitespace_split = ["foo", "bar", "baz", "quux"]
        sentences = '''
            I have a very long block of text, here. It goes on and on, containing
            things like decimal points (1.0314e3) and other language scripts as well
            건반(Korean).
        sentence_words = ['I', 'have', 'a', 'very', 'long', 'block', 'of', 'text', ',', 'here', '.', 'It', 'goes', 'on', 'and', 'on', ',', 'containing', 'things', 'like', 'decimal', 'points', '(', '1.0314e3', ')', 'and', 'other', 'language', 'scripts', 'as', 'well', '건반', '(', 'Korean', ')', '.']

        Test.specify "should allow naive length computation over grapheme clusters" <|
            kshi.length . should_equal 1
            facepalm.length . should_equal 1

        Test.specify "should compare strings using utf normalization" <|
            "abc"=="def" . should_be_false
            'a'=='b' . should_be_false
            'a'=='a' . should_be_true
            'a'=='' . should_be_false
            ''=='' . should_be_true

            accent_1 . should_equal accent_2

            complex_letter_1 = 'e\u{301}\u{321}\u{338}\u{360}'
            complex_letter_2 = 'e\u{338}\u{321}\u{360}\u{301}'
            complex_letter_3 = 'e\u{360}\u{321}\u{301}\u{338}'
            common_prefix = 'a\u{360}\u{321}\u{301}\u{338}bcąęóf'

            complex_letter_1 . should_equal complex_letter_2
            complex_letter_1 . should_equal complex_letter_3
            complex_letter_3 . should_equal complex_letter_2
            common_prefix+complex_letter_1+complex_letter_2+complex_letter_3 . compare_to common_prefix+complex_letter_3+complex_letter_1+complex_letter_2 . should_equal Ordering.Equal

            'e\u{301}'=='e\u{302}' . should_be_false

            'a\u0321\u0302'=='a\u0302\u0321' . should_be_true
            'a\u0321\u0302'=='A\u0302\u0321' . should_be_false

            accent_1+"a" . compare_to accent_2+"a" . should_equal Ordering.Equal
            accent_1+"A" . compare_to accent_2+"a" . should_equal Ordering.Less
            accent_1+"A" . compare_to_ignore_case accent_2+"a" . should_equal Ordering.Equal
            accent_1+"a" . compare_to accent_2+"b" . should_equal Ordering.Less
            accent_1+"a" . compare_to_ignore_case accent_2+"B" . should_equal Ordering.Less
            accent_2+"a" . compare_to accent_1+"b" . should_equal Ordering.Less
            accent_1+"a" . compare_to accent_2+"B" . should_equal Ordering.Greater
            accent_1+"a" . compare_to_ignore_case accent_2+"B" . should_equal Ordering.Less
            accent_1+"b" . compare_to accent_2+"a" . should_equal Ordering.Greater
            accent_2+"b" . compare_to accent_1+"a" . should_equal Ordering.Greater

            earlier_suffix = "aooooz"
            later_suffix = "bo"
            common_prefix+complex_letter_1+earlier_suffix . compare_to common_prefix+complex_letter_2+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_2+earlier_suffix . compare_to common_prefix+complex_letter_1+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_2+earlier_suffix . compare_to common_prefix+complex_letter_3+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_3+earlier_suffix . compare_to common_prefix+complex_letter_1+later_suffix . should_equal Ordering.Less
            common_prefix+complex_letter_3+later_suffix . compare_to common_prefix+complex_letter_1+earlier_suffix . should_equal Ordering.Greater
            common_prefix+complex_letter_1+later_suffix . compare_to common_prefix+complex_letter_2+earlier_suffix . should_equal Ordering.Greater

        Test.specify "should correctly handle case-insensitive equality" <|
            "aBc" . equals_ignore_case "Abc" . should_be_true
            "abc" . equals_ignore_case "abd" . should_be_false
            "" . equals_ignore_case "" . should_be_true
            "aaaa" . equals_ignore_case "" . should_be_false

            'e\u0301' . equals_ignore_case 'é' . should_be_true
            'E\u0301' . equals_ignore_case 'É' . should_be_true
            'e\u0301' . equals_ignore_case 'É' . should_be_true
            'E\u0301' . equals_ignore_case 'é' . should_be_true
            'a\u0321\u0302' . equals_ignore_case 'A\u0302\u0321' . should_be_true
            'e\u0301' . equals_ignore_case 'e\u0303' . should_be_false

            "I" . equals_ignore_case "i" . should_be_true
            "İ" . equals_ignore_case "i" (locale = Locale.new "tr") . should_be_true
            "I" . equals_ignore_case "ı" (locale = Locale.new "az") . should_be_true
            "I" . equals_ignore_case "i" (locale = Locale.new "tr") . should_be_false

            "Kongressstraße"=="Kongressstrasse" . should_be_false
            "Kongressstraße" . equals_ignore_case "Kongressstrasse" . should_be_true

        Test.specify "should split the text into grapheme clusters" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.characters . should_equal [kshi, facepalm, accent_1, accent_2]

        Test.specify "should allow access by index to a grapheme cluster" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at 0 . should_equal kshi
            str.at 1 . should_equal facepalm
            str.at 2 . should_equal accent_1
            str.at 3 . should_equal accent_2

        Test.specify "should allow access by negative index to a grapheme cluster" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at -4 . should_equal kshi
            str.at -3 . should_equal facepalm
            str.at -2 . should_equal accent_1
            str.at -1 . should_equal accent_2

        Test.specify "should return a dataflow error when accessing characters out of bounds" <|
            str = kshi + facepalm + accent_1 + accent_2
            str.at -5 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at -5 . catch . should_equal (Index_Out_Of_Bounds_Error_Data -5 4)
            str.at 4 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at 4 . catch . should_equal (Index_Out_Of_Bounds_Error_Data 4 4)

        Test.specify "should be able to split the text into words" <|
            "I have not one, but two cats.".words . should_equal ['I', 'have', 'not', 'one', ',', 'but', 'two', 'cats', '.']
            "แมวมีสี่ขา".words . should_equal ['แมว', 'มี', 'สี่', 'ขา']
            sentences.words . should_equal sentence_words
            "I ❤️ Unicode! 🙂🙂".words . should_equal ['I', '❤️', 'Unicode', '!', '🙂', '🙂']
            '"แมวมีสี่ขา" means that a cat has four legs.'.words . should_equal ['"', 'แมว', 'มี', 'สี่', 'ขา', '"', 'means', 'that', 'a', 'cat', 'has', 'four', 'legs', '.']

        Test.specify "should be able to split the text into lines" <|
            utf_8_vertical = 'foo\n   bar \r\n baz \r quux'
            utf_8_vertical_split = ["foo", "   bar ", " baz ", " quux"]
            utf_8_vertical.lines . should_equal utf_8_vertical_split

            'a\nb\nc'.lines . should_equal ['a', 'b', 'c']
            '\na\n\nb\n\n\n'.lines . should_equal ['', 'a', '', 'b', '', '']
            '\na\nb\n'.lines keep_endings=True . should_equal ['\n', 'a\n', 'b\n']

            '\n\n\n'.lines . should_equal ['', '', '']
            '\r\r\r'.lines . should_equal ['', '', '']
            '\r\n\r\n\r\n'.lines . should_equal ['', '', '']
            '\n\n\n'.lines keep_endings=True . should_equal ['\n', '\n', '\n']
            'a\r\nb\n\rc'.lines keep_endings=True . should_equal ['a\r\n', 'b\n', '\r', 'c']
            'a\r\nb\n\rc'.lines . should_equal ['a', 'b', '', 'c']
            'abc'.lines . should_equal ['abc']
            'abc\n'.lines . should_equal ['abc']
            'abc\n'.lines keep_endings=True . should_equal ['abc\n']
            '\na'.lines . should_equal ['', 'a']

            multiline = """
               Hello
               world
            multiline.lines . should_equal ['Hello', 'world']
            '🚀🚧\n\u{301}a\u{301}\r건반'.lines . should_equal ['🚀🚧', '\u{301}a\u{301}', '건반']

        Test.specify "should be able to split the text on arbitrary text sequence" <|
            "foo, bar, baz" . split ", " . should_equal ["foo", "bar", "baz"]
            text = "Namespace::package::package::Type"
            text.split "::" . should_equal ["Namespace", "package", "package", "Type"]
            "..a.b.c.d" . split "." . should_equal ["", "", "a", "b", "c", "d"]
            "abc".split "." . should_equal ["abc"]
            "aaa".split "a" . should_equal ["", "", "", ""]
            ".a.".split "." . should_equal ["", "a", ""]
            "".split "." . should_equal [""]
            "abc[a-z]def".split "[a-z]" . should_equal ["abc", "def"]
            'aśbs\u{301}c'.split 'ś' . should_equal ['a', 'b', 'c']
            'abc'.split '' . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on arbitrary text sequence, case-insensitively" <|
            matcher = Text_Matcher_Data Case_Insensitive_Data
            "AbCdABCDabDCba" . split "ab" matcher . should_equal ["", "Cd", "CD", "DCba"]
            "abc".split "d" matcher . should_equal ["abc"]
            "AAA".split "a" matcher . should_equal ["", "", "", ""]
            "baB".split "b" matcher . should_equal ["", "a", ""]
            "".split "a" matcher . should_equal [""]
            'aŚbS\u{301}c'.split 'ś' matcher . should_equal ['a', 'b', 'c']
            'abc'.split '' matcher . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on Regex patterns" <|
            "cababdabe" . split "ab" Regex_Matcher_Data . should_equal ["c", "", "d", "e"]
            "cababdabe" . split "(ab)+" Regex_Matcher_Data . should_equal ["c", "d", "e"]
            "abc" . split "[a-z]" Regex_Matcher_Data . should_equal ["", "", "", ""]
            "abc--def==>ghi".split "[-=>]+" Regex_Matcher_Data == ["abc", "def", "ghi"]
            "abc".split "." Regex_Matcher_Data . should_equal ["", "", "", ""]
            "abc".split "d" Regex_Matcher_Data . should_equal ["abc"]
            ".a.".split "\." Regex_Matcher_Data . should_equal ["", "a", ""]
            "".split "a" Regex_Matcher_Data . should_equal [""]
            'aśbs\u{301}c'.split 'ś' Regex_Matcher_Data . should_equal ['a', 'b', 'c']
            'abc'.split '' Regex_Matcher_Data . should_fail_with Illegal_Argument_Error_Data

        Test.specify "should be able to split the text on UTF-8 whitespace" <|
            utf_8_whitespace.split "\s+" Regex_Matcher_Data . should_equal utf_8_whitespace_split
            'abc  def\tghi'.split '\\s+' Regex_Matcher_Data . should_equal ["abc", "def", "ghi"]

        Test.specify "should convert any type to text automatically and using provided methods" <|
            t = Auto_Data (Manual_Data 123) . to_text
            t.should_equal "(Auto_Data [[[MyREP 123]]])"

        Test.specify "should escape special characters when debug-printing text" <|
            text_1 = '''
                foo
                bar\r\tbaz
            text_1.to_text.should_equal "'foo\nbar\r\tbaz'"
            text_2 = '\n\t\a\b\f\r\v\e\''
            text_2.to_text.should_equal "'\n\t\a\b\f\r\v\e\''"

        Test.specify "should allow taking or dropping every other character" <|
            "ABCDE".take (Every 1) . should_equal "ABCDE"
            "ABCDE".take (Every 2) . should_equal "ACE"
            "ABCD".take (Every 2) . should_equal "AC"
            "ABCD".take (Every 2 first=1) . should_equal "BD"
            "ABCDE".take (Every 2 first=1) . should_equal "BD"
            "ABCDE".take (Every 3) . should_equal "AD"
            "ABCDEFG".take (Every 3) . should_equal "ADG"
            "ABCDEFG".take (Every 3 first=1) . should_equal "BE"
            "ABCDEFG".take (Every 3 first=6) . should_equal "G"
            "ABCDEFG".take (Every 10) . should_equal "A"

            "ABCDE".drop (Every 1) . should_equal ""
            "ABCDE".drop (Every 2) . should_equal "BD"
            "ABCD".drop (Every 2) . should_equal "BD"
            "ABCD".drop (Every 2 first=1) . should_equal "AC"
            "ABCDE".drop (Every 2 first=1) . should_equal "ACE"
            "ABCDE".drop (Every 3) . should_equal "BCE"
            "ABCDEFG".drop (Every 3) . should_equal "BCEF"
            "ABCDEFG".drop (Every 3 first=1) . should_equal "ACDFG"
            "ABCDEFGH".drop (Every 3 first=1) . should_equal "ACDFG"
            "ABCDEFGHI".drop (Every 3 first=1) . should_equal "ACDFGI"

        Test.specify "should allow taking or dropping a random sample of a substring"
            "AAAAA".take (Sample 3) . should_equal "AAA"
            "AAAAA".drop (Sample 3) . should_equal "AA"

            ## These tests are very brittle and can be invalidated by a valid
               implementation modification, so they may need to be updated.
            "ABCDEFGH".take (Sample 0) . should_equal ""
            "ABCDEFGH".take (Sample 8 seed=42) . should_equal "FGCHABED"
            "ABCDEFGH".take (Sample 4 seed=42) . should_equal "FGCH"
            "ABCDEFGH".take (Sample 2 seed=42) . should_equal "FG"
            "ABCDEFGH".take (Sample 1 seed=42) . should_equal "F"
            "ABCDEFGH".take (Sample 100 seed=42) . should_equal "FGCHABED"

            samples_1 = 0.up_to 10000 . map seed->
                "ABCD".take (Sample 2 seed)
            samples_1.should_contain_the_same_elements_as ["AB", "BA", "AC", "CA", "AD", "DA", "BC", "CB", "BD", "DB", "CD", "DC"]

            "ABCDEFGH".drop (Sample 0) . should_equal "ABCDEFGH"
            "ABCDEFGH".drop (Sample 1 seed=42) . should_equal "ABCDEGH"
            "ABCDEFGH".drop (Sample 2 seed=42) . should_equal "ABCDEH"
            "ABCDEFGH".drop (Sample 4 seed=42) . should_equal "ABDE"
            "ABCDEFGH".drop (Sample 8 seed=42) . should_equal ""
            "ABCDEFGH".drop (Sample 100 seed=42) . should_equal ""

            samples_2 = 0.up_to 10000 . map seed->
                "ABCD".drop (Sample 2 seed)
            samples_2.should_contain_the_same_elements_as ["AB", "AC", "AD", "BC", "CD", "BD"]

        Test.specify "should allow taking or dropping many indices or subranges (possibly overlapping)" <|
            "123"*1000 . take (By_Index (Vector.new 3000 ix-> 2999-ix)) . should_equal "321"*1000
            "123"*1000 . take (By_Index (Vector.new 3000 _-> 0)) . should_equal "1"*3000
            "123456"*1000 . take (By_Index (Vector.new 100 ix-> Range_Data 6*ix+1 6*ix+3)) . should_equal "23"*100
            "AB"*1000 . take (By_Index (Vector.new 100 ix-> Range_Data ix+1 ix+5)) . should_equal "BABAABAB"*50

            "123"*1000 . drop (By_Index (Vector.new 300 ix-> 2999-ix)) . should_equal "123"*900
            "123"*1000 . drop (By_Index (Vector.new 3000 _-> 0)) . should_equal "23"+"123"*999
            "123456"*1000 . drop (By_Index (Vector.new 1000 ix-> Range_Data 6*ix+1 6*ix+3)) . should_equal "1456"*1000
            "ABCD"*25 . drop (By_Index (Vector.new 90 ix-> Range_Data ix+1 ix+5)) . should_equal "ACDABCD"

            "ABCD"*1000 . take (Range_Data 0 4000 4) . should_equal "A"*1000
            "ABCD"*1000 . take (Every 4) . should_equal "A"*1000
            "ABCD"*1000 . take (By_Index [Range_Data 0 4000 4, Range_Data 1 4000 4]) . should_equal ("A"*1000 + "B"*1000)
            "ABCD"*1000 . take (By_Index [Range_Data 0 4000 4, Range_Data 2 4000 4]) . should_equal ("A"*1000 + "C"*1000)

            "ABCD"*1000 . drop (Range_Data 0 4000 4) . should_equal "BCD"*1000
            "ABCD"*1000 . drop (Every 4) . should_equal "BCD"*1000
            "ABCD"*1000 . drop (By_Index [Range_Data 0 4000 4, Range_Data 1 4000 4]) . should_equal "CD"*1000
            "ABCD"*1000 . drop (By_Index [Range_Data 0 4000 4, Range_Data 2 4000 4]) . should_equal "BD"*1000

            "0123456789".take (By_Index [Range_Data 0 4, Range_Data 4 6, Range_Data 8 9]) . should_equal "0123458"
            "0123456789".take (By_Index [Range_Data 4 6, Range_Data 0 4, 0, 0]) . should_equal "45012300"
            "0123456789".drop (By_Index [Range_Data 0 4, Range_Data 4 6, Range_Data 8 9]) . should_equal "679"
            "0123456789".drop (By_Index [Range_Data 4 6, Range_Data 0 4, 0, 0]) . should_equal "6789"
            "0123456789".drop (By_Index [Range_Data 2 5, Range_Data 0 3, 0, 0]) . should_equal "56789"

        Test.specify "should allow selecting substrings by characters" <|
            txt = kshi + facepalm + accent_1 + accent_2
            txt.take (First 2) . should_equal (kshi + facepalm)
            txt.drop (First 2) . should_equal (accent_1 + accent_2)
            txt.take (Last 2) . should_equal (accent_1 + accent_2)
            txt.drop (Last 2) . should_equal (kshi + facepalm)
            txt.take (Range_Data 0 2) . should_equal (kshi + facepalm)
            txt.take (By_Index (Range_Data 0 2)) . should_equal (kshi + facepalm)
            txt.drop (Range_Data 0 2) . should_equal (accent_1 + accent_2)
            txt.take (Range_Data 2 4) . should_equal (accent_1 + accent_2)
            txt.drop (Range_Data 2 4) . should_equal (kshi + facepalm)
            txt.take (Every 2) . should_equal (kshi + accent_1)
            txt.take (Every 2 first=1) . should_equal (facepalm + accent_2)
            txt.drop (Every 2) . should_equal (facepalm + accent_2)
            txt.take (Range_Data 0 4 2) . should_equal (kshi + accent_1)
            txt.take (By_Index [0, 3]) . should_equal (kshi + accent_2)
            txt.take (By_Index 0) . should_equal kshi
            txt.take (By_Index 1) . should_equal facepalm
            txt.take (By_Index 2) . should_equal accent_1
            txt.take (By_Index 3) . should_equal accent_2
            txt.drop (By_Index [0, 3]) . should_equal (facepalm + accent_1)
            txt.drop (By_Index [0, 3, 0]) . should_equal (facepalm + accent_1)
            txt.drop (By_Index [0, 3, 0, 2, 1]) . should_equal ""
            txt.take (By_Index [0, 3, 0, 2, 1]) . should_equal (kshi + accent_2 + kshi + accent_1 + facepalm)
            txt.take (By_Index [0, 0, Range_Data 0 2]) . should_equal (kshi + kshi + kshi + facepalm)
            txt.drop (By_Index [Range_Data 2 4, Range_Data 0 2]) . should_equal ""

        Test.specify "take should work as in the examples" <|
            "Hello World!".take First . should_equal "H"
            "Hello World!".take (First 5) . should_equal "Hello"
            "Hello World!".take (First 100) . should_equal "Hello World!"
            "Hello World!".take (First 0) . should_equal ""
            "Hello World!".take Last . should_equal "!"
            "Hello World!".take (Last 6) . should_equal "World!"
            "Hello World!".take (Last 0) . should_equal ""
            "Hello World!".take (Last 100) . should_equal "Hello World!"
            "Hello World!".take (Before " ") . should_equal "Hello"
            "Hello World!".take (Before "z") . should_equal "Hello World!"
            "Hello World!".take (Before_Last "o") . should_equal "Hello W"
            "Hello World!".take (Before_Last "z") . should_equal "Hello World!"
            "Hello World!".take (After " ") . should_equal "World!"
            "Hello World!".take (After "z") . should_equal ""
            "Hello World!".take (After_Last "o") . should_equal "rld!"
            "Hello World!".take (After_Last "z") . should_equal ""
            "Hello World!".take (While c->c!=" ") . should_equal "Hello"
            "Hello World!".take (While c->c!="z") . should_equal "Hello World!"
            "Hello World!".take (Range_Data 3 5) . should_equal "lo"
            "Hello World!".take (Range_Data 5 12) . should_equal " World!"
            "Hello World!".take (Range_Data 6 12 2) . should_equal "Wrd"
            "Hello World!".take (Every 2 first=6) . should_equal "Wrd"
            "Hello World!".take (Every 3) . should_equal "HlWl"
            "Hello World!".take (By_Index 0) . should_equal "H"
            "Hello World!".take (By_Index [1, 0, 0, 6, 0]) . should_equal "eHHWH"
            "Hello World!".take (By_Index [Range_Data 0 3, 6, Range_Data 6 12 2]) . should_equal "HelWWrd"
            "Hello World!".take (Sample 3 seed=42) . should_equal "l d"

        Test.specify "take should report errors for start indices out of bounds but just go till the end if the end index is OOB" <|
            txt = "Hello World!"
            txt.take (Range_Data 0 14) . should_equal txt
            txt.take (Range_Data 6 100) . should_equal "World!"
            txt.take (Range_Data txt.length-1 txt.length) . should_equal "!"
            txt.take (Range_Data txt.length txt.length) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data txt.length txt.length) . catch . should_equal (Index_Out_Of_Bounds_Error_Data txt.length txt.length)
            txt.take (Range_Data txt.length 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (First 100) . should_equal txt
            txt.take (Last 100) . should_equal txt
            txt.take (By_Index 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index 13) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, 1, 13]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, Range_Data 14 15, 1]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [0, 1, Range_Data 6 100]) . should_equal "HeWorld!"
            txt.take (By_Index [0, 1, Range_Data 6 100 2]) . should_equal "HeWrd"
            txt.take (Range_Data 13 12) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (Range_Data 0 0) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 0 0)
            "".take (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "ABC".take (By_Index 3) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data 13 20) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (Range_Data 13 20 2) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 2, Range_Data 13 20]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 0, Range_Data 13 10, Range_Data 2 2 2]) . should_equal ""
            txt.take (By_Index [Range_Data 0 2 2, Range_Data 13 20 2]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.take (By_Index [Range_Data 0 2 2, Range_Data 13 20 2]) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 13 12)
            txt.take (By_Index [Range_Data 0 2 2, Range_Data txt.length 100 2]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".take (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "take should work on grapheme clusters" <|
            txt_1 = 'He\u0302llo\u0308 Wo\u0301rld!'
            txt_2 = 'He\u0302llo\u0308 Wo\u0308rld!'
            txt_1.take (Every 2) . should_equal 'Hlo\u0308Wrd'
            txt_1.take (First 2) . should_equal 'He\u{302}'
            txt_1.take (First 5) . should_equal 'He\u{302}llo\u{308}'
            txt_1.take (Last 6) . should_equal 'Wo\u{301}rld!'
            txt_1.take (Last 5) . should_equal 'o\u{301}rld!'
            txt_1.take (Before 'e\u{302}') . should_equal 'H'
            txt_1.take (Before 'ê') . should_equal 'H'
            txt_1.take (Before 'e') . should_equal txt_1
            txt_2.take (Before_Last 'o\u{308}') . should_equal 'He\u{302}llo\u{308} W'
            txt_2.take (Before_Last 'ö') . should_equal 'He\u{302}llo\u{308} W'
            txt_2.take (Before_Last 'o') . should_equal txt_2
            txt_1.take (After 'e\u{302}') . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.take (After 'ê') . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.take (After 'e\u{308}') . should_equal ''
            txt_1.take (After 'e') . should_equal ''
            txt_2.take (After_Last 'o\u{308}') . should_equal 'rld!'
            txt_2.take (After_Last 'ö') . should_equal 'rld!'
            txt_2.take (After_Last 'o') . should_equal ''
            txt_2.take (While c->c!='e\u{302}') . should_equal 'H'
            txt_2.take (While c->c!='ê') . should_equal 'H'
            txt_2.take (While c->c!='e') . should_equal txt_2
            txt_2.take (Range_Data 3 5) . should_equal 'lo\u{308}'
            txt_2.take (Range_Data 5 12) . should_equal ' Wo\u{308}rld!'

        Test.specify "take should work on emojis" <|
            '✨🚀🚧😍😃😎😙😉☺'.take First . should_equal '✨'
            '✨🚀🚧😍😃😎😙😉☺'.take (First 2) . should_equal '✨🚀'
            '✨🚀🚧😍😃😎😙😉☺'.take Last . should_equal '☺'
            '✨🚀🚧😍😃😎😙😉☺'.take (Last 0) . should_equal ''
            '✨🚀🚧😍😃😎😙😉☺'.take (Last 3) . should_equal '😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (Before '😍') . should_equal '✨🚀🚧'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (Before_Last '😍') . should_equal '✨🚀🚧😍😃'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (After '😍') . should_equal '😃😍😎😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (After_Last '😍') . should_equal '😎😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (While c->c!="😃") . should_equal '✨🚀🚧😍'
            '✨🚀🚧😍😃😍😎😙😉☺'.take (Range_Data 3 6) . should_equal '😍😃😍'

        Test.specify "take should correctly handle edge cases" <|
            "ABC".take . should_equal "A"

            "".take First . should_equal ""
            "".take Last . should_equal ""

            "".take (After "a") . should_equal ""
            "".take (After_Last "a") . should_equal ""
            "".take (Before "a") . should_equal ""
            "".take (Before_Last "a") . should_equal ""

            "".take (After "") . should_equal ""
            "".take (After_Last "") . should_equal ""
            "".take (Before "") . should_equal ""
            "".take (Before_Last "") . should_equal ""

            "".take (While _->True) . should_equal ""

            'ABC\u{301}'.take (Range_Data 0 0) . should_equal ""

            'ABC\u{301}'.take (After "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.take (After_Last "") . should_equal ""
            'ABC\u{301}'.take (Before "") . should_equal ""
            'ABC\u{301}'.take (Before_Last "") . should_equal 'ABC\u{301}'

            "ABC".take (By_Index -1) . should_equal "C"
            "ABC".take (By_Index [-1, -1, -1, -3, 2]) . should_equal "CCCAC"
            "ABC".take (By_Index []) . should_equal ""
            "ABC".take (By_Index (Range_Data -2 -1)) . should_fail_with Illegal_Argument_Error_Data
            "".take (Every 2) . should_equal ""
            "".take (Every 2 first=1) . should_equal ""
            "ABC".take (Every 5) . should_equal "A"
            "A".take (Every 5) . should_equal "A"
            "ABC".take (Every 5 first=4) . should_equal ""
            "".take (Sample 0) . should_equal ""
            "".take (Sample 100) . should_equal ""

        Test.specify "drop should work as in the examples" <|
            "Hello World!".drop First . should_equal "ello World!"
            "Hello World!".drop (First 5) . should_equal " World!"
            "Hello World!".drop (First 100) . should_equal ""
            "Hello World!".drop (First 0) . should_equal "Hello World!"
            "Hello World!".drop Last . should_equal "Hello World"
            "Hello World!".drop (Last 6) . should_equal "Hello "
            "Hello World!".drop (Last 100) . should_equal ""
            "Hello World!".drop (Before " ") . should_equal " World!"
            "Hello World!".drop (Before "z") . should_equal ""
            "Hello World!".drop (Before_Last "o") . should_equal "orld!"
            "Hello World!".drop (Before_Last "z") . should_equal ""
            "Hello World!".drop (After " ") . should_equal "Hello "
            "Hello World!".drop (After "z") . should_equal "Hello World!"
            "Hello World!".drop (After_Last "o") . should_equal "Hello Wo"
            "Hello World!".drop (After_Last "z") . should_equal "Hello World!"
            "Hello World!".drop (While c->c!=" ") . should_equal " World!"
            "Hello World!".drop (While c->c!="z") . should_equal ""
            "Hello World!".drop (Range_Data 3 5) . should_equal "Hel World!"
            "Hello World!".drop (Range_Data 5 12) . should_equal "Hello"
            "Hello World!".drop (Range_Data 6 12 2) . should_equal "Hello ol!"
            "Hello World!".drop (Every 2 first=6) . should_equal "Hello ol!"
            "Hello World!".drop (Every 3) . should_equal "elo ord!"
            "Hello World!".drop (By_Index 0) . should_equal "ello World!"
            "Hello World!".drop (By_Index [1, 0, 0, 6, 0]) . should_equal "llo orld!"
            "Hello World!".drop (By_Index [Range_Data 0 3, 6, Range_Data 6 12 2]) . should_equal "lo ol!"
            "Hello World!".drop (Sample 3 seed=42) . should_equal "HeloWorl!"

        Test.specify "drop should report errors for start indices out of bounds but just go till the end if the end index is OOB" <|
            txt = "Hello World!"
            txt.drop (Range_Data 0 14) . should_equal ""
            txt.drop (First 100) . should_equal ""
            txt.drop (Last 100) . should_equal ""
            txt.drop (By_Index 100) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index 100) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 100 12)
            txt.drop (By_Index 13) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, 1, 13]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, Range_Data 14 15, 1]) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (By_Index [0, 1, Range_Data 6 100]) . should_equal "llo "
            txt.drop (Range_Data 13 12) . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt.drop (Range_Data 14 15) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (By_Index 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            "".drop (Range_Data 0 0) . catch . should_equal (Index_Out_Of_Bounds_Error_Data 0 0)
            txt.drop (Range_Data 0 0) . should_equal txt
            txt.drop (Range_Data 5 100) . should_equal "Hello"
            txt.drop (Range_Data 5 100 2) . should_equal "HelloWrd"
            txt.drop (By_Index [0, 1, 0, Range_Data 5 100 2]) . should_equal "lloWrd"

        Test.specify "drop should work on grapheme clusters" <|
            txt_1 = 'He\u0302llo\u0308 Wo\u0301rld!'
            txt_2 = 'He\u0302llo\u0308 Wo\u0308rld!'
            txt_1.drop (Every 2) . should_equal 'e\u0302l o\u0301l!'
            txt_1.drop (First 2) . should_equal 'llo\u{308} Wo\u{301}rld!'
            txt_1.drop (First 5) . should_equal ' Wo\u{301}rld!'
            txt_1.drop (Last 6) . should_equal 'He\u{302}llo\u{308} '
            txt_1.drop (Last 5) . should_equal 'He\u{302}llo\u{308} W'
            txt_1.drop (Before 'e\u{302}') . should_equal 'e\u{302}llo\u{308} Wo\u{301}rld!'
            txt_1.drop (Before 'ê') . should_equal 'e\u{302}llo\u{308} Wo\u{301}rld!'
            txt_1.drop (Before 'e') . should_equal ''
            txt_2.drop (Before_Last 'o\u{308}') . should_equal 'o\u{308}rld!'
            txt_2.drop (Before_Last 'ö') . should_equal 'o\u{308}rld!'
            txt_2.drop (Before_Last 'o') . should_equal ''
            txt_1.drop (After 'e\u{302}') . should_equal 'He\u{302}'
            txt_1.drop (After 'ê') . should_equal 'He\u{302}'
            txt_1.drop (After 'e\u{308}') . should_equal txt_1
            txt_1.drop (After 'e') . should_equal txt_1
            txt_2.drop (After_Last 'o\u{308}') . should_equal 'He\u{302}llo\u{308} Wo\u{308}'
            txt_2.drop (After_Last 'ö') . should_equal 'He\u{302}llo\u{308} Wo\u{308}'
            txt_2.drop (After_Last 'o') . should_equal txt_2
            txt_2.drop (While c->c!='e\u{302}') . should_equal 'e\u{302}llo\u{308} Wo\u{308}rld!'
            txt_2.drop (While c->c!='ê') . should_equal 'e\u{302}llo\u{308} Wo\u{308}rld!'
            txt_2.drop (While c->c!='e') . should_equal ''
            txt_2.drop (Range_Data 3 5) . should_equal 'He\u{302}l Wo\u{308}rld!'
            txt_2.drop (Range_Data 5 12) . should_equal 'He\u{302}llo\u{308}'

        Test.specify "drop should work on emojis" <|
            '✨🚀🚧😍😃😎😙😉☺'.drop First . should_equal '🚀🚧😍😃😎😙😉☺'
            '✨🚀🚧😍😃😎😙😉☺'.drop (First 2) . should_equal '🚧😍😃😎😙😉☺'
            '✨🚀🚧😍😃😎😙😉☺'.drop Last . should_equal '✨🚀🚧😍😃😎😙😉'
            '✨🚀🚧😍😃😎😙😉☺'.drop (Last 3) . should_equal '✨🚀🚧😍😃😎'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (Before '😍') . should_equal '😍😃😍😎😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (Before_Last '😍') . should_equal '😍😎😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (After '😍') . should_equal '✨🚀🚧😍'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (After_Last '😍') . should_equal '✨🚀🚧😍😃😍'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (While c->c!="😃") . should_equal '😃😍😎😙😉☺'
            '✨🚀🚧😍😃😍😎😙😉☺'.drop (Range_Data 3 6) . should_equal '✨🚀🚧😎😙😉☺'

        Test.specify "drop should correctly handle edge cases" <|
            "ABC".drop . should_equal "BC"

            "".drop First . should_equal ""
            "".drop Last . should_equal ""

            "".drop (After "a") . should_equal ""
            "".drop (After_Last "a") . should_equal ""
            "".drop (Before "a") . should_equal ""
            "".drop (Before_Last "a") . should_equal ""

            "".drop (After "") . should_equal ""
            "".drop (After_Last "") . should_equal ""
            "".drop (Before "") . should_equal ""
            "".drop (Before_Last "") . should_equal ""

            "".drop (While _->True) . should_equal ""

            "".drop (Range_Data 0 0) . should_fail_with Index_Out_Of_Bounds_Error_Data
            'ABC\u{301}'.drop (Range_Data 0 0) . should_equal 'ABC\u{301}'

            'ABC\u{301}'.drop (After "") . should_equal ''
            'ABC\u{301}'.drop (After_Last "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.drop (Before "") . should_equal 'ABC\u{301}'
            'ABC\u{301}'.drop (Before_Last "") . should_equal ''

            "ABC".drop (By_Index -1) . should_equal "AB"
            "ABC".drop (By_Index [-1, -1, -1, -3, 2]) . should_equal "B"
            "ABC".drop (By_Index []) . should_equal "ABC"
            "".drop (Every 2) . should_equal ""
            "".drop (Every 2 first=1) . should_equal ""
            "ABC".drop (Every 5) . should_equal "BC"
            "ABC".drop (Every 5 first=4) . should_equal "ABC"
            "".drop (Sample 0) . should_equal ""
            "".drop (Sample 100) . should_equal ""

        Test.specify "should correctly convert character case" <|
            "FooBar Baz".to_case Case.Lower . should_equal "foobar baz"
            "FooBar Baz".to_case Case.Upper . should_equal "FOOBAR BAZ"

            "foo bar baz".to_case Case.Title . should_equal "Foo Bar Baz"
            "foo-bar, baz.baz foo_foo".to_case Case.Title . should_equal "Foo-Bar, Baz.baz Foo_foo"
            "jAck the rippER".to_case Case.Title (Locale.uk) . should_equal "Jack The Ripper"

            "i".to_case Case.Upper . should_equal "I"
            "I".to_case Case.Lower . should_equal "i"
            "i".to_case Case.Upper (Locale.new "tr") . should_equal "İ"
            "I".to_case Case.Lower (Locale.new "tr") . should_equal "ı"
            "İ".to_case Case.Lower . should_equal "i̇"
            "ı".to_case Case.Upper . should_equal "I"

            "Straße".to_case Case.Upper . should_equal "STRASSE"
            "STRASSE".to_case Case.Lower . should_equal "strasse"
            "et cætera".to_case Case.Upper . should_equal "ET CÆTERA"
            ("β".to_case Case.Upper == "B") . should_be_false
            "δλφξ".to_case Case.Upper . should_equal "ΔΛΦΞ"
            "ΔΛΦΞ".to_case Case.Lower . should_equal "δλφξ"
            "δλ φξ".to_case Case.Title . should_equal "Δλ Φξ"

            '✨🚀🚧😍😃😎😙😉☺'.to_case Case.Upper . should_equal '✨🚀🚧😍😃😎😙😉☺'
            '✨🚀🚧😍😃😎😙😉☺'.to_case Case.Lower . should_equal '✨🚀🚧😍😃😎😙😉☺'
            '✨🚀🚧😍😃😎😙😉☺'.to_case Case.Title . should_equal '✨🚀🚧😍😃😎😙😉☺'

            "123".to_case Case.Upper . should_equal "123"
            "abc123".to_case Case.Upper . should_equal "ABC123"

        Test.specify "should dump characters to a vector" <|
            kshi_chars = kshi.char_vector
            kshi_chars . should_equal [2325, 2381, 2359, 2367]

        Test.specify "should convert a vector of characters to text" <|
            kshi_chars = [2325, 2381, 2359, 2367]
            Text.from_char_vector kshi_chars . should_equal kshi

        Test.specify "should insert text at a non-negative index position" <|
            "Hello World!".insert 0 " Cruel" . should_equal " CruelHello World!"
            "Hello World!".insert 5 " Cruel" . should_equal "Hello Cruel World!"
            "Hello World!".insert ("Hello World!".length - 1) " Cruel" . should_equal "Hello World Cruel!"
            "Hello World!".insert "Hello World!".length " Cruel" . should_equal "Hello World! Cruel"
            txt = kshi + facepalm + accent_1
            txt.insert 0 " Cruel" . should_equal (" Cruel" + kshi + facepalm + accent_1)
            txt.insert 1 " Cruel" . should_equal (kshi + " Cruel" + facepalm + accent_1)
            txt.insert 2 " Cruel" . should_equal (kshi + facepalm + " Cruel" + accent_1)
            txt.insert 3 " Cruel" . should_equal (kshi + facepalm + accent_1 + " Cruel")

        Test.specify "should report Index_Out_Of_Bounds_Error_Data when inserting text at an invalid non-negative index position" <|
            "Hello World!".insert ("Hello World!".length + 1) "foo" . should_fail_with Index_Out_Of_Bounds_Error_Data
            (kshi + facepalm + accent_1).insert 4 "foo" . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should insert text at a negative index position" <|
            "Hello World!".insert -1 " Cruel" . should_equal "Hello World! Cruel"
            "Hello World!".insert -5 " Cruel" . should_equal "Hello Wo Cruelrld!"
            "Hello World!".insert -("Hello World!".length) " Cruel" . should_equal "H Cruelello World!"
            "Hello World!".insert -("Hello World!".length + 1) " Cruel" . should_equal " CruelHello World!"
            txt = kshi + facepalm + accent_1
            txt.insert -1 " Cruel" . should_equal (txt + " Cruel")
            txt.insert -(txt.length) " Cruel" . should_equal (kshi + " Cruel" + facepalm + accent_1)

        Test.specify "should report Index_Out_Of_Bounds_Error_Data when inserting text at an invalid negative index position" <|
            "Hello World!".insert -("Hello World!".length + 2) " Cruel" . should_fail_with Index_Out_Of_Bounds_Error_Data
            txt = kshi + facepalm + accent_1
            txt.insert -(txt.length + 2) " Cruel" . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check by index if is a digit" <|
            str = kshi + "A12" + accent_2
            str.is_digit . should_be_false
            str.is_digit 1 . should_be_false
            str.is_digit 2 . should_be_true
            str.is_digit 3 . should_be_true
            str.is_digit 4 . should_be_false
            str.is_digit 5 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check by negative index if is a digit" <|
            str = kshi + "A12" + accent_2
            str.is_digit -1 . should_be_false
            str.is_digit -2 . should_be_true
            str.is_digit -3 . should_be_true
            str.is_digit -4 . should_be_false
            str.is_digit -5 . should_be_false
            str.is_digit -100 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to check if a text consists only of whitespace" <|
            '  \t\n'.is_whitespace . should_be_true
            'AB'.is_whitespace . should_be_false
            '  A   '.is_whitespace . should_be_false

            '\v\f\u{200a}\u{202f}\u{205F}\u{3000}\u{feff}'.is_whitespace . should_be_true
            # The Unicode Zero Width Space is not considered whitespace
            '\u{200b}'.is_whitespace . should_be_false

        Test.specify "should return a dataflow error when checking is digit for out of bounds" <|
            str = kshi + "A12" + accent_2
            str.at -6 . should_fail_with Index_Out_Of_Bounds_Error_Data
            str.at 5 . should_fail_with Index_Out_Of_Bounds_Error_Data

        Test.specify "should be able to reverse characters" <|
            "Hello World!".reverse . should_equal "!dlroW olleH"

            "".reverse . should_equal ""
            'e\u{301}'.reverse . should_equal 'e\u{301}'
            'e\u{301}\u00E9'.reverse . should_equal '\u00E9e\u{301}'
            'e\u{321}\u{360}'.reverse . should_equal 'e\u{321}\u{360}'
            'Iñtërnâtiônàlizætiøn☃💩'.reverse . should_equal '💩☃nøitæzilànôitânrëtñI'
            'ほげほげ'.reverse . should_equal 'げほげほ'
            '\u{10000}'.reverse . should_equal '\u{10000}'

        Test.specify "should allow to iterate over characters" <|
            str = kshi + accent_1 + accent_2 + 'abc'
            builder = Vector.new_builder
            str.each builder.append
            builder.to_vector . should_equal [kshi, accent_1, accent_2, 'a', 'b', 'c']

            builder2 = Vector.new_builder
            'a'.each builder2.append
            builder2.to_vector . should_equal ['a']

        Test.specify "should check for contains using Unicode normalization" <|
            "Hello".contains "ell" . should_be_true

            "Cześć".contains 's\u{301}' . should_be_true
            "Cześć".contains 'c\u{301}' . should_be_true
            "Cześć".contains 'ść' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'ś' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'ć' . should_be_true
            'Czes\u{301}c\u{301}'.contains 'ść' . should_be_true
            "Cześć".contains 'sc' . should_be_false
            'Czes\u{301}c\u{301}'.contains 'sc' . should_be_false
            "Cześć".contains 's' . should_be_false
            "Cześć".contains 'c' . should_be_false
            'Czes\u{301}c\u{301}'.contains 's' . should_be_false

            "ABC" . contains "a" . should_be_false
            "" . contains "foo" . should_be_false
            "abc" . contains "" . should_be_true
            "" . contains "" . should_be_true
            "foo foo foo" . contains "foo" . should_be_true

            "Hello!".contains "lo" . should_be_true
            "Hello!".contains "Lo" . should_be_false

        Test.specify "should allow for case-insensitive contains checks" <|
            "Hello!".contains 'LO' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "FoObar" . contains "foo" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "aaaIAAA" . contains "i" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Foo" . contains "bar" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            "Ściana" . contains "ś" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Ściana" . contains "s" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false

            "Straße" . contains "ss" . should_be_false
            "Strasse" . contains "ß" . should_be_false
            "Straße" . contains "ss" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Strasse" . contains "ß" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

        Test.specify "should allow for Regex contains checks" <|
            "Hello!".contains "[a-z]" Regex_Matcher_Data . should_be_true
            "foobar" . contains "b.." Regex_Matcher_Data . should_be_true
            "foob" . contains "b.." Regex_Matcher_Data . should_be_false

            "123 meters and 4 centimeters" . contains "[0-9]+" Regex_Matcher_Data . should_be_true
            "foo" . contains "[0-9]+" Regex_Matcher_Data . should_be_false

            'ś' . contains 's' . should_be_false
            's\u{301}' . contains 's' . should_be_false
            's\u{301}' . contains 'ś' . should_be_true
            'ś' . contains 's\u{301}' . should_be_true

            ## These first two cases are not really desirable, but we are
               documenting here what is the current behaviour.
            ## This shows what regex is doing by default and we cannot easily fix
               that.
            's\u{301}' . contains 's' Regex_Matcher_Data . should_be_true
            'ś' . contains 's' Regex_Matcher_Data . should_be_false
            's\u{301}' . contains 'ś' Regex_Matcher_Data . should_be_true
            'ś' . contains 's\u{301}' Regex_Matcher_Data . should_be_true

            "Cześć" . contains "ś" Regex_Matcher_Data . should_be_true
            "Cześć" . contains 's\u{301}' Regex_Matcher_Data . should_be_true
            'Czes\u{301}c\u{301}' . contains 's\u{301}' Regex_Matcher_Data . should_be_true
            'Czes\u{301}c\u{301}' . contains 'ś' Regex_Matcher_Data . should_be_true
            ## These two tests below are disabled due to how regex is handling
               letters with accents. See the tests above for explanation.
            #"Cześć" . contains "s" Regex_Matcher_Data . should_be_false
            #'Czes\u{301}c\u{301}' . contains 's' Regex_Matcher_Data . should_be_false

            "fooBar" . contains "b.." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_true
            "foar" . contains "b.." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_false

            long_text = """
                Hello from a long text. EOL
                SOL Hmm...
            long_text . contains "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=True) . should_be_true
            long_text . contains "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=False) . should_be_false

        Test.specify "should check for starts_with using Unicode normalization" <|
            "Hello".starts_with "He" . should_be_true

            "Ściana".starts_with 'S\u{301}' . should_be_true
            "Ściana".starts_with 'Ś' . should_be_true
            "Ściana".starts_with 'S' . should_be_false
            'S\u{301}ciana'.starts_with 'Ś' . should_be_true
            'S\u{301}ciana'.starts_with 'S\u{301}' . should_be_true
            'S\u{301}ciana'.starts_with 'S' . should_be_false

            "ABC" . starts_with "A" . should_be_true
            "ABC" . starts_with "a" . should_be_false
            "" . starts_with "foo" . should_be_false
            "abc" . starts_with "" . should_be_true
            "" . starts_with "" . should_be_true
            "foo foo foo" . starts_with "foo" . should_be_true

            "Hello!".starts_with "he" . should_be_false

        Test.specify "starts_with should work as shown in the examples" <|
            "Hello!".starts_with "Hello" . should_be_true
            "Hello!".starts_with "hello" . should_be_false
            "Hello!".starts_with "hello" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Hello!".starts_with "[a-z]" Regex_Matcher_Data . should_be_false
            "Hello!".starts_with "[A-Z]" Regex_Matcher_Data . should_be_true

        Test.specify "should allow for case-insensitive starts_with checks" <|
            "Hello".starts_with "he" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

            "Ściana".starts_with 's\u{301}' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Ściana".starts_with 's' (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            'S\u{301}ciana'.starts_with 'ś' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            'S\u{301}ciana'.starts_with 's\u{301}' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            'S\u{301}ciana'.starts_with 's' (Text_Matcher_Data Case_Insensitive_Data) . should_be_false

            "ABC" . starts_with "A" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "ABC" . starts_with "a" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "ABC" . starts_with "C" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            "" . starts_with "foo" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            "abc" . starts_with "" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "" . starts_with "" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "fOo FOO foo" . starts_with "FoO" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

            "Hello!".starts_with "he" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

        Test.specify "should allow for Regex starts_with checks" <|
            "Hello!".starts_with "[A-Z]" Regex_Matcher_Data . should_be_true
            "foobar" . starts_with ".o." Regex_Matcher_Data . should_be_true
            "foob" . starts_with ".f." Regex_Matcher_Data . should_be_false

            "123 meters and 4 centimeters" . starts_with "[0-9]+" Regex_Matcher_Data . should_be_true
            "foo 123" . starts_with "[0-9]+" Regex_Matcher_Data . should_be_false

            # Correct non-regex behaviour for reference.
            'ś' . starts_with 's' == False
            's\u{301}' . starts_with 's' == False
            's\u{301}' . starts_with 'ś' == True
            'ś' . starts_with 's\u{301}' == True

            # These two behave as expected.
            's\u{301}' . starts_with 'ś' Regex_Matcher_Data == True
            'ś' . starts_with 's\u{301}' Regex_Matcher_Data == True

            ## These two are included to document the current behaviour
               (even though ideally, we would want them to return False).
            'ś' . starts_with 's' Regex_Matcher_Data == True
            's\u{301}' . starts_with 's' Regex_Matcher_Data == True

            "ściana" . starts_with "ś" Regex_Matcher_Data . should_be_true
            "ściana" . starts_with 's\u{301}' Regex_Matcher_Data . should_be_true
            's\u{301}ciana' . starts_with 's\u{301}' Regex_Matcher_Data . should_be_true
            's\u{301}ciana' . starts_with 'ś' Regex_Matcher_Data . should_be_true

            ## These two tests below are disabled due to how regex is handling
               letters with accents. See the tests above for explanation.
            #"ściana" . starts_with "s" Regex_Matcher_Data . should_be_false
            # 's\u{301}ciana' . starts_with 's' Regex_Matcher_Data . should_be_false

            "fOOBar" . starts_with ".o." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_true
            "faaaar" . starts_with ".o." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_false

            long_text = """
                EOL
                SOL Hmm...
            long_text . starts_with "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=True) . should_be_true
            long_text . starts_with "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=False) . should_be_false

            "aaazzz" . starts_with "a|b" Regex_Matcher_Data . should_be_true
            "bbbzzz" . starts_with "a|b" Regex_Matcher_Data . should_be_true
            "zzzaaa" . starts_with "a|b" Regex_Matcher_Data . should_be_false
            "zzzbbb" . starts_with "a|b" Regex_Matcher_Data . should_be_false
            "aaazzz" . starts_with "(a|b){2}" Regex_Matcher_Data . should_be_true
            "bbbzzz" . starts_with "(a|b){2}" Regex_Matcher_Data . should_be_true
            "zzzaaa" . starts_with "(a|b){2}" Regex_Matcher_Data . should_be_false
            "ABC" . starts_with "\AA" Regex_Matcher_Data . should_be_true
            "ABC" . starts_with "\AA\z" Regex_Matcher_Data . should_be_false
            "foobar" . starts_with "" Regex_Matcher_Data . should_be_true
            "" . starts_with "" Regex_Matcher_Data . should_be_true

        Test.specify "should check for ends_with using Unicode normalization" <|
            "Hello".ends_with "lo" . should_be_true
            "Hello".ends_with "LO" . should_be_false

            "rzeczywistość".ends_with 'c\u{301}' . should_be_true
            "rzeczywistość".ends_with 'ć' . should_be_true
            "rzeczywistość".ends_with 'c' . should_be_false
            'rzeczywistos\u{301}c\u{301}'.ends_with 'ć' . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'c\u{301}' . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'c' . should_be_false

            "ABC" . ends_with "C" . should_be_true
            "ABC" . ends_with "c" . should_be_false
            "" . ends_with "foo" . should_be_false
            "abc" . ends_with "" . should_be_true
            "" . ends_with "" . should_be_true
            "foo foo foo" . ends_with "foo" . should_be_true

        Test.specify "ends_with should work as shown in the examples" <|
            "Hello World".ends_with "World" . should_be_true
            "Hello World".ends_with "world" . should_be_false
            "Hello World".ends_with "world" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "Hello World".ends_with "[A-Z][a-z]{4}" Regex_Matcher_Data . should_be_true

        Test.specify "should allow for case-insensitive ends_with checks" <|
            "Hello".ends_with "LO" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

            "rzeczywistość".ends_with 'C\u{301}' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "rzeczywistość".ends_with 'C' (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            'rzeczywistos\u{301}c\u{301}'.ends_with 'Ć' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'C\u{301}' (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            'rzeczywistos\u{301}c\u{301}'.ends_with 'C' (Text_Matcher_Data Case_Insensitive_Data) . should_be_false

            "ABC" . ends_with "C" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "ABC" . ends_with "c" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "ABC" . ends_with "A" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            "" . ends_with "foo" (Text_Matcher_Data Case_Insensitive_Data) . should_be_false
            "abc" . ends_with "" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "" . ends_with "" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true
            "fOo FOO fOo" . ends_with "FoO" (Text_Matcher_Data Case_Insensitive_Data) . should_be_true

        Test.specify "should allow for Regex ends_with checks" <|
            "Hello".ends_with "[a-z]" Regex_Matcher_Data . should_be_true
            "Hello!".ends_with "[a-z]" Regex_Matcher_Data . should_be_false

            "foobar" . ends_with ".o." Regex_Matcher_Data . should_be_false
            "foobar" . ends_with ".a." Regex_Matcher_Data . should_be_true

            "123 meters and 4 centimeters" . ends_with "[0-9]+" Regex_Matcher_Data . should_be_false
            "foo 123" . ends_with "[0-9]+" Regex_Matcher_Data . should_be_true

            "rzeczywistość" . ends_with "ć" Regex_Matcher_Data . should_be_true
            "rzeczywistość" . ends_with 'c\u{301}' Regex_Matcher_Data . should_be_true
            'rzeczywistos\u{301}c\u{301}' . ends_with 'c\u{301}' Regex_Matcher_Data . should_be_true
            'rzeczywistos\u{301}c\u{301}' . ends_with 'ć' Regex_Matcher_Data . should_be_true
            "rzeczywistość" . ends_with "c" Regex_Matcher_Data . should_be_false
            'rzeczywistos\u{301}c\u{301}' . ends_with 'c' Regex_Matcher_Data . should_be_false

            'rzeczywistos\u{301}c\u{301}' . ends_with 'Ć' (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_true
            "fOOBar" . ends_with ".A." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_true
            "faaaar" . ends_with ".o." (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data) . should_be_false

            long_text = """
                Hnnnn EOL
                SOL
            long_text . ends_with "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=True) . should_be_true
            long_text . ends_with "EOL.SOL" (Regex_Matcher_Data dot_matches_newline=False) . should_be_false

            "zzzaaa" . ends_with "a|b" Regex_Matcher_Data . should_be_true
            "zzzbbb" . ends_with "a|b" Regex_Matcher_Data . should_be_true
            "aaazzz" . ends_with "a|b" Regex_Matcher_Data . should_be_false
            "bbbzzz" . ends_with "a|b" Regex_Matcher_Data . should_be_false
            "zzzaaa" . ends_with "(a|b){2}" Regex_Matcher_Data . should_be_true
            "zzzbbb" . ends_with "(a|b){2}" Regex_Matcher_Data . should_be_true
            "aaazzz" . ends_with "(a|b){2}" Regex_Matcher_Data . should_be_false
            "ABC" . ends_with "C\z" Regex_Matcher_Data . should_be_true
            "ABC" . ends_with "\AC\z" Regex_Matcher_Data . should_be_false
            "foobar" . ends_with "" Regex_Matcher_Data . should_be_true
            "" . ends_with "" Regex_Matcher_Data . should_be_true

        Test.specify "should allow to pad a text" <|
            "Hello World!".pad 15 . should_equal "Hello World!   "
            "HELLO".pad 9 "AB" . should_equal "HELLOABAB"
            "HELLO".pad 8 "AB" . should_equal "HELLOABA"
            "HELLO".pad 8 "AB" Location.Start . should_equal "BABHELLO"
            "".pad 4 . should_equal "    "
            "A".pad 3 "" . should_fail_with Illegal_Argument_Error_Data
            "ABCDE".pad 3 "" . should_fail_with Illegal_Argument_Error_Data
            "".pad 0 "" . should_fail_with Illegal_Argument_Error_Data

            "".pad 0 . should_equal ""
            "ABC".pad 3 . should_equal "ABC"
            "AB".pad -1 . should_equal "AB"
            "ABC".pad -100 . should_equal "ABC"

            'a\u{301}'.pad 2 . should_equal 'a\u{301} '
            "".pad 2 'a\u{302}' . should_equal 'a\u{302}a\u{302}'
            'XX'.pad 5 'yy\u{301}' . should_equal 'XXyy\u{301}y'
            'XX'.pad 5 'y\u{301}y' . should_equal 'XXy\u{301}yy\u{301}'
            'XX'.pad 4 'yy\u{301}Z' . should_equal 'XXyy\u{301}'

            '🚀'.pad 3 'B' Location.End . should_equal '🚀BB'
            '🚀'.pad 3 'B' Location.Start . should_equal 'BB🚀'

            ## It is technically possible to use a combining diacritical mark as
               the padding, then the actual length of the text will not increase
               because all padding will still constitute a single grapheme
               cluster.
            'e'.pad 7 '\u{301}' . length . should_equal 1

        Test.specify "should allow to trim a text" <|
            " Hello! ".trim . should_equal  "Hello!"
            " Hello! ".trim Location.Start . should_equal  "Hello! "
            " Hello! ".trim Location.End . should_equal  " Hello!"
            "ABC123".trim Location.Start "ABC" . should_equal  "123"
            "ABBA123".trim Location.Start "ABC" . should_equal  "123"
            "ABCZ-]".trim Location.Both "[A-Z]" . should_equal "BC"

            "   ".trim . should_equal ""
            "  Hello World!   ".trim . should_equal  "Hello World!"
            "  Hello World!   ".trim Location.Start . should_equal  "Hello World!   "
            "  Hello World!   ".trim Location.End . should_equal  "  Hello World!"
            "ABCD".trim Location.Start "ABCDEF" . should_equal ""
            "ABCD".trim Location.End "ABCDEF" . should_equal ""
            "ABCD".trim Location.Both "ABCDEF" . should_equal ""

            "".trim . should_equal ""
            "A".trim . should_equal "A"
            " A ".trim . should_equal "A"
            '   A\u{301} \n   '.trim . should_equal 'A\u{301}'
            "🚧".trim . should_equal "🚧"
            "  🚧  🚧  ".trim . should_equal "🚧  🚧"
            "  🚧  🚧  ".trim Location.End . should_equal "  🚧  🚧"

            "ABCD".trim Location.Start (_ -> True) . should_equal ""
            "ABCD".trim Location.Both (_ -> True) . should_equal ""
            "ABCD".trim Location.Both (_ -> False) . should_equal "ABCD"
            "123AB98".trim Location.Both _.is_digit . should_equal "AB"

            ' \t\n\r'.trim . should_equal ''
            '\t\t  Test\nFoo\r\n'.trim . should_equal 'Test\nFoo'
            # Check various kinds of Unicode whitespace
            '\v\f\u{200a}\u{202f}\u{205F}\u{3000}\u{feff}'.trim . should_equal ''

            # A whitespace with an accent is not treated as whitespace anymore
            '      \u{301}   '.trim . should_equal ' \u{301}'
            ' \u{301}'.trim . should_equal ' \u{301}'

        Test.specify "should allow repeating as in the examples" <|
            "ABBA".repeat 5 . should_equal "ABBAABBAABBAABBAABBA"
            "A".repeat 5 . should_equal "AAAAA"
            "Hello ".repeat 2 . should_equal "Hello Hello "

        Test.specify "should allow more general repeating" <|
            'He\u{302}llo\u{308}'.repeat 1 . should_equal 'He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'.repeat 3 . should_equal 'He\u{302}llo\u{308}He\u{302}llo\u{308}He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'.repeat 0 . should_equal ''
            'He\u{302}llo\u{308}'.repeat -5 . should_equal ''

            ''.repeat 100 . should_equal ''

            '✨🚀🚧'.repeat 2 . should_equal '✨🚀🚧✨🚀🚧'

        Test.specify "should allow repeating using * as in the examples" <|
            "ABBA"*5 . should_equal "ABBAABBAABBAABBAABBA"
            "A"*5 . should_equal "AAAAA"
            "Hello "*2 . should_equal "Hello Hello "

        Test.specify "should allow more general repeating using *" <|
            'He\u{302}llo\u{308}'*1 . should_equal 'He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'*3 . should_equal 'He\u{302}llo\u{308}He\u{302}llo\u{308}He\u{302}llo\u{308}'
            'He\u{302}llo\u{308}'*0 . should_equal ''
            'He\u{302}llo\u{308}'*(-5) . should_equal ''

            ''*100 . should_equal ''

            '✨🚀🚧'*2 . should_equal '✨🚀🚧✨🚀🚧'

        Test.specify "location_of should work as shown in examples" <|
            example_1 =
                "Hello World!".location_of "J" == Nothing
                "Hello World!".location_of "o" == Span_Data (Range_Data 4 5) "Hello World!"
                "Hello World!".location_of "o" mode=Matching_Mode.Last == Span_Data (Range_Data 4 5) "Hello World!"

            example_2 =
                term = "straße"
                text = "MONUMENTENSTRASSE 42"
                match = text . location_of term matcher=(Text_Matcher_Data Case_Insensitive_Data)
                term.length . should_equal 6
                match.length . should_equal 7

            example_3 =
                ligatures = "ﬃﬄ"
                ligatures.length . should_equal 2
                term_1 = "IFF"
                match_1 = ligatures . location_of term_1 matcher=(Text_Matcher_Data Case_Insensitive_Data)
                term_1.length . should_equal 3
                match_1.length . should_equal 2
                term_2 = "ffiffl"
                match_2 = ligatures . location_of term_2 matcher=(Text_Matcher_Data Case_Insensitive_Data)
                term_2.length . should_equal 6
                match_2.length . should_equal 2
                match_1 . should_equal match_2

            example_4 =
                "Hello World!".location_of_all "J" . should_equal []
                "Hello World!".location_of_all "o" . map .start . should_equal [4, 7]

            example_5 =
                term = "strasse"
                text = "MONUMENTENSTRASSE ist eine große Straße."
                match = text . location_of_all term matcher=(Text_Matcher_Data Case_Insensitive_Data)
                term.length . should_equal 7
                match . map .length . should_equal [7, 6]

            example_6 =
                ligatures = "ﬃﬄFFIFF"
                ligatures.length . should_equal 7
                match_1 = ligatures . location_of_all "IFF" matcher=(Text_Matcher_Data Case_Insensitive_Data)
                match_1 . map .length . should_equal [2, 3]
                match_2 = ligatures . location_of_all "ffiff" matcher=(Text_Matcher_Data Case_Insensitive_Data)
                match_2 . map .length . should_equal [2, 5]

            # Put them in blocks to avoid name clashes.
            example_1
            example_2
            example_3
            example_4
            example_5
            example_6

        Test.specify "should allow to find location_of occurrences within a text" <|
            "Hello World!".location_of_all "J" . should_equal []
            "Hello World!".location_of_all "o" . map .start . should_equal [4, 7]

            accents = 'a\u{301}e\u{301}o\u{301}'
            accents.location_of accent_1 . should_equal (Span_Data (Range_Data 1 2) accents)

            "".location_of "foo" . should_equal Nothing
            "".location_of "foo" mode=Matching_Mode.Last . should_equal Nothing
            "".location_of_all "foo" . should_equal []
            "".location_of "" . should_equal (Span_Data (Range_Data 0 0) "")
            "".location_of "" mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            "".location_of_all "" . should_equal [Span_Data (Range_Data 0 0) ""]
            abc = 'A\u{301}ßC'
            abc.location_of "" . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.location_of "" mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)
            abc.location_of_all "" . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]

        Test.specify "should allow case-insensitive matching in location_of" <|
            hello = "Hello WORLD!"
            case_insensitive = Text_Matcher_Data Case_Insensitive_Data
            hello.location_of "world" . should_equal Nothing
            hello.location_of "world" matcher=case_insensitive . should_equal (Span_Data (Range_Data 6 11) hello)

            hello.location_of "o" mode=Regex_Mode.First matcher=case_insensitive . should_equal (Span_Data (Range_Data 4 5) hello)
            hello.location_of "o" mode=Matching_Mode.Last matcher=case_insensitive . should_equal (Span_Data (Range_Data 7 8) hello)

            accents = 'A\u{301}E\u{301}O\u{301}'
            accents.location_of accent_1 matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 2) accents)

            "Strasse".location_of "ß" matcher=case_insensitive . should_equal (Span_Data (Range_Data 4 6) "Strasse")
            "Monumentenstraße 42".location_of "STRASSE" matcher=case_insensitive . should_equal (Span_Data (Range_Data 10 16) "Monumentenstraße 42")

            '\u0390'.location_of '\u03B9\u0308\u0301' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 1) '\u0390')
            'ԵՒ'.location_of 'և' . should_equal Nothing
            'ԵՒ'.location_of 'և' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) 'ԵՒ')
            'և'.location_of 'ԵՒ' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 1) 'և')

            ligatures = 'ffaﬀﬁﬂﬃﬄﬅﬆZ'
            ligatures.location_of 'FFI' matcher=case_insensitive . should_equal (Span_Data (Range_Data 3 5) ligatures)
            ligatures.location_of 'FF' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) ligatures)
            ligatures.location_of 'ff' matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 7 8) ligatures)
            ligatures.location_of_all 'ff' . should_equal [Span_Data (Range_Data 0 2) ligatures]
            ligatures.location_of_all 'FF' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 2) ligatures, Span_Data (Range_Data 3 4) ligatures, Span_Data (Range_Data 6 7) ligatures, Span_Data (Range_Data 7 8) ligatures]
            ligatures.location_of_all 'ffi' matcher=case_insensitive . should_equal [Span_Data (Range_Data 3 5) ligatures, Span_Data (Range_Data 6 7) ligatures]
            'fffi'.location_of_all 'ﬀ' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 2) 'fffi']
            'fffi'.location_of_all 'ﬃ' . should_equal []
            'fffi'.location_of_all 'ﬃ' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 4) 'fffi']
            'FFFI'.location_of 'ﬃ' matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 4) 'FFFI')

            'ﬃﬄ'.location_of 'IF' matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 2) 'ﬃﬄ')
            'ﬃﬄ'.location_of 'F' Matching_Mode.Last matcher=case_insensitive . should_equal (Span_Data (Range_Data 1 2) 'ﬃﬄ')
            'ﬃﬄ'.location_of_all 'F' matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 1) 'ﬃﬄ', Span_Data (Range_Data 0 1) 'ﬃﬄ', Span_Data (Range_Data 1 2) 'ﬃﬄ', Span_Data (Range_Data 1 2) 'ﬃﬄ']
            'aaﬃbb'.location_of_all 'af' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 3) 'aaﬃbb']
            'aaﬃbb'.location_of_all 'affi' matcher=case_insensitive . should_equal [Span_Data (Range_Data 1 3) 'aaﬃbb']
            'aaﬃbb'.location_of_all 'ib' matcher=case_insensitive . should_equal [Span_Data (Range_Data 2 4) 'aaﬃbb']
            'aaﬃbb'.location_of_all 'ffib' matcher=case_insensitive . should_equal [Span_Data (Range_Data 2 4) 'aaﬃbb']

            "".location_of "foo" matcher=case_insensitive . should_equal Nothing
            "".location_of "foo" matcher=case_insensitive mode=Matching_Mode.Last . should_equal Nothing
            "".location_of_all "foo" matcher=case_insensitive . should_equal []
            "".location_of "" matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 0) "")
            "".location_of "" matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            "".location_of_all "" matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 0) ""]
            abc = 'A\u{301}ßC'
            abc.location_of "" matcher=case_insensitive . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.location_of "" matcher=case_insensitive mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)
            abc.location_of_all "" matcher=case_insensitive . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]

        Test.specify "should allow regexes in location_of" <|
            hello = "Hello World!"
            regex = Regex_Matcher_Data
            regex_insensitive = Regex_Matcher_Data case_sensitive=Case_Insensitive_Data
            hello.location_of ".o" Matching_Mode.First matcher=regex . should_equal (Span_Data (Range_Data 3 5) hello)
            hello.location_of ".o" Matching_Mode.Last matcher=regex . should_equal (Span_Data (Range_Data 6 8) hello)
            hello.location_of_all ".o" matcher=regex . map .start . should_equal [3, 6]

            "foobar".location_of "BAR" Regex_Mode.First matcher=regex_insensitive . should_equal (Span_Data (Range_Data 3 6) "foobar")

            ## Regex matching does not do case folding
            "Strasse".location_of "ß" Regex_Mode.First matcher=regex_insensitive . should_equal Nothing

            ## But it should handle the Unicode normalization
            accents = 'a\u{301}e\u{301}o\u{301}'
            accents.location_of accent_1 Regex_Mode.First matcher=regex . should_equal (Span_Data (Range_Data 1 2) accents)
        Test.specify "should correctly handle regex edge cases in location_of" pending="Figure out how to make Regex correctly handle empty patterns." <|
            regex = Regex_Matcher_Data
            "".location_of "foo" matcher=regex . should_equal Nothing
            "".location_of "foo" matcher=regex mode=Matching_Mode.Last . should_equal Nothing
            "".location_of_all "foo" matcher=regex . should_equal []
            "".location_of "" matcher=regex . should_equal (Span_Data (Range_Data 0 0) "")
            "".location_of_all "" matcher=regex . should_equal [Span_Data (Range_Data 0 0) ""]
            "".location_of "" matcher=regex mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 0 0) "")
            abc = 'A\u{301}ßC'
            abc.location_of "" matcher=regex . should_equal (Span_Data (Range_Data 0 0) abc)
            abc.location_of_all "" matcher=regex . should_equal [Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 0 0) abc, Span_Data (Range_Data 1 1) abc, Span_Data (Range_Data 2 2) abc, Span_Data (Range_Data 3 3) abc]
            abc.location_of "" matcher=regex mode=Matching_Mode.Last . should_equal (Span_Data (Range_Data 3 3) abc)

        Test.specify "should handle overlapping matches as shown in the examples"
            "aaa".location_of "aa" mode=Matching_Mode.Last matcher=Text_Matcher_Data . should_equal (Span_Data (Range_Data 1 3) "aaa")
            "aaa".location_of "aa" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal (Span_Data (Range_Data 0 2) "aaa")

            "aaa aaa".location_of "aa" mode=Matching_Mode.Last matcher=Text_Matcher_Data . should_equal (Span_Data (Range_Data 5 7) "aaa aaa")
            "aaa aaa".location_of "aa" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal (Span_Data (Range_Data 4 6) "aaa aaa")

    Test.group "Regex matching" <|
        Test.specify "should be possible on text" <|
            match = "My Text: Goes Here".match "^My Text: (.+)$" mode=Regex_Mode.First
            match . should_be_a Default_Engine.Match_Data
            match.group 1 . should_equal "Goes Here"

        Test.specify "should be possible on unicode text" <|
            match = "Korean: 건반".match "^Korean: (.+)$" mode=Regex_Mode.First
            match . should_be_a Default_Engine.Match_Data
            match.group 1 . should_equal "건반"

        Test.specify "should be possible in ascii mode" <|
            match = "İ".match "\w" mode=Regex_Mode.First match_ascii=True
            match . should_equal Nothing

        Test.specify "should be possible in case-insensitive mode" <|
            match = "MY".match "my" mode=Regex_Mode.First case_insensitive=True
            match . should_be_a Default_Engine.Match_Data
            match.group 0 . should_equal "MY"

        Test.specify "should be possible in dot_matches_newline mode" <|
            match = 'Foo\n'.match "(....)" mode=Regex_Mode.First dot_matches_newline=True
            match . should_be_a Default_Engine.Match_Data
            match.group 0 . should_equal 'Foo\n'

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.match "^(...)$" multiline=True
            match.length . should_equal 2
            match.at 0 . group 1 . should_equal "Foo"
            match.at 1 . group 1 . should_equal "bar"

        Test.specify "should be possible in comments mode" <|
            match = "abcde".match "(..) # Match two of any character" comments=True mode=Regex_Mode.First
            match . should_be_a Default_Engine.Match_Data
            match.group 0 . should_equal "ab"

    Test.group "Regex matches" <|
        Test.specify "should be possible on text" <|
            "My Text: Goes Here".matches "^My Text: (.+)$" . should_be_true

        Test.specify "should be possible on unicode text" <|
            "Korean: 건반".matches "^Korean: (.+)$" . should_be_true

        Test.specify "should be possible in ascii mode" <|
            "İ".matches "\w" match_ascii=True . should_be_false

        Test.specify "should be possible in case-insensitive mode" <|
            "MY".matches "my" case_insensitive=True . should_be_true

        Test.specify "should be possible in dot_matches_newline mode" <|
            'Foo\n'.matches "(....)" dot_matches_newline=True . should_be_true

        multiline_matches_message = """
            This test does not make sense once we require matches to match the
            whole string. The `multiline` parameter may not make sense for the
            `matches` function. This should be revisited when Text library is
            being redesigned.
        Test.specify "should be possible in multiline mode" pending=multiline_matches_message <|
            text = """
                Foo
                bar
            text.matches "^(...)$" multiline=True . should_be_true

        Test.specify "should be possible in comments mode" <|
            "abcde".matches "(.....) # Match any five characters" comments=True . should_be_true

    Test.group "Regex finding" <|
        Test.specify "should be possible on text" <|
            match = "My Text: Goes Here".find "^My Text: (.+)$" mode=Regex_Mode.First
            match . should_be_a Text
            match . should_equal "My Text: Goes Here"

        Test.specify "should be possible on unicode text" <|
            match = "Korean: 건반".find "^Korean: (.+)$" mode=Regex_Mode.First
            match . should_be_a Text
            match . should_equal "Korean: 건반"

        Test.specify "should be possible in ascii mode" <|
            match = "İ".find "\w" mode=Regex_Mode.First match_ascii=True
            match . should_equal Nothing

        Test.specify "should be possible in case-insensitive mode" <|
            match = "MY".find "my" mode=Regex_Mode.First case_insensitive=True
            match . should_be_a Text
            match . should_equal "MY"

        Test.specify "should be possible in dot_matches_newline mode" <|
            match = 'Foo\n'.find "(....)" mode=Regex_Mode.First dot_matches_newline=True
            match . should_be_a Text
            match . should_equal 'Foo\n'

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.find "^(...)$" multiline=True
            match.length . should_equal 2
            match.at 0 . should_equal "Foo"
            match.at 1 . should_equal "bar"

        Test.specify "should be possible in comments mode" <|
            match = "abcde".find "(..) # Match two of any character" comments=True mode=Regex_Mode.First
            match . should_be_a Text
            match . should_equal "ab"

    Test.group "Regex splitting" <|
        Test.specify "should be possible on text" <|
            splits = "abcde".split "[bd]" Regex_Matcher_Data
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "c"
            splits.at 2 . should_equal "e"

        Test.specify "should be possible on unicode text" <|
            match = "Korean: 건반 (hangul)".split " " Regex_Matcher_Data
            match.length . should_equal 3
            match.at 0 . should_equal "Korean:"
            match.at 1 . should_equal "건반"
            match.at 2 . should_equal "(hangul)"

        Test.specify "should be possible in ascii mode" <|
            splits = "İiİ".split "\w" (Regex_Matcher_Data match_ascii=True)
            splits.length . should_equal 2
            splits.at 0 . should_equal "İ"
            splits.at 1 . should_equal "İ"

        Test.specify "should be possible in case-insensitive mode" <|
            splits = "abaBa".split "b" (Regex_Matcher_Data case_sensitive=Case_Insensitive_Data)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "a"
            splits.at 2 . should_equal "a"

        Test.specify "should be possible in dot_matches_newline mode" <|
            splits = 'ab\nabcd'.split "b." (Regex_Matcher_Data dot_matches_newline=True)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "a"
            splits.at 2 . should_equal "d"

        Test.specify "should be possible in multiline mode" <|
            text = """
                Foo
                bar
            match = text.split "$" (Regex_Matcher_Data multiline=True)
            match.length . should_equal 3

        Test.specify "should be possible in comments mode" <|
            splits = "abcde".split "[bd] # Split on the letters `b` and `d`" (Regex_Matcher_Data comments=True)
            splits.length . should_equal 3
            splits.at 0 . should_equal "a"
            splits.at 1 . should_equal "c"
            splits.at 2 . should_equal "e"

    Test.group "Text.replace" <|
        Test.specify "should work as in examples" <|
            'aaa'.replace 'aa' 'b' . should_equal 'ba'
            "Hello World!".replace "[lo]" "#" matcher=Regex_Matcher_Data . should_equal "He### W#r#d!"
            "Hello World!".replace "l" "#" mode=Matching_Mode.First . should_equal "He#lo World!"
            '"abc" foo "bar" baz'.replace '"(.*?)"' '($1)' matcher=Regex_Matcher_Data . should_equal '(abc) foo (bar) baz'
            'ß'.replace 'S' 'A' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'AA'
            'aﬃb'.replace 'i' 'X' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'aXb'

        Test.specify "should correctly handle empty-string edge cases" <|
            [Regex_Mode.All, Matching_Mode.First, Matching_Mode.Last] . each mode->
                'aaa'.replace '' 'foo' mode=mode . should_equal 'aaa'
                ''.replace '' '' mode=mode . should_equal ''
                'a'.replace 'a' '' mode=mode . should_equal ''
                ''.replace 'a' 'b' mode=mode . should_equal ''

            'aba' . replace 'a' '' Matching_Mode.First . should_equal 'ba'
            'aba' . replace 'a' '' Matching_Mode.Last . should_equal 'ab'
            'aba' . replace 'a' '' . should_equal 'b'
            'aba' . replace 'c' '' . should_equal 'aba'

        Test.specify "should correctly handle first, all and last matching with overlapping occurrences" <|
            "aaa aaa".replace "aa" "c" . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last . should_equal "aaa ac"

        Test.specify "should correctly handle case-insensitive matches" <|
            'AaąĄ' . replace "A" "-" matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal '--ąĄ'
            'AaąĄ' . replace "A" "-" . should_equal '-aąĄ'
            'HeLlO wOrLd' . replace 'hElLo' 'Hey,' matcher=(Text_Matcher_Data True) . should_equal 'HeLlO wOrLd'
            'HeLlO wOrLd' . replace 'hElLo' 'Hey,' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'Hey, wOrLd'

            "Iiİı" . replace "i" "-" . should_equal "I-İı"
            "Iiİı" . replace "I" "-" . should_equal "-iİı"
            "Iiİı" . replace "İ" "-" . should_equal "Ii-ı"
            "Iiİı" . replace "ı" "-" . should_equal "Iiİ-"

            "Iiİı" . replace "i" "-" matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal "--İı"
            "Iiİı" . replace "I" "-" matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal "--İı"
            "Iiİı" . replace "İ" "-" matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal "Ii-ı"
            "Iiİı" . replace "ı" "-" matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal "Iiİ-"

            tr_insensitive = Text_Matcher_Data (Case_Insensitive_Data (Locale.new "tr"))
            "Iiİı" . replace "i" "-" matcher=tr_insensitive . should_equal "I--ı"
            "Iiİı" . replace "I" "-" matcher=tr_insensitive . should_equal "-iİ-"
            "Iiİı" . replace "İ" "-" matcher=tr_insensitive . should_equal "I--ı"
            "Iiİı" . replace "ı" "-" matcher=tr_insensitive . should_equal "-iİ-"

        Test.specify "should correctly handle Unicode edge cases" <|
            'sśs\u{301}' . replace 's' 'O' . should_equal 'Ośs\u{301}'
            'sśs\u{301}' . replace 's' 'O' Matching_Mode.Last . should_equal 'Ośs\u{301}'
            'śs\u{301}s' . replace 's' 'O' Matching_Mode.First . should_equal 'śs\u{301}O'

            'sśs\u{301}' . replace 'ś' 'O' . should_equal 'sOO'
            'sśs\u{301}' . replace 's\u{301}' 'O' . should_equal 'sOO'

            'SŚS\u{301}' . replace 's' 'O' . should_equal 'SŚS\u{301}'
            'SŚS\u{301}' . replace 's' 'O' Matching_Mode.Last . should_equal 'SŚS\u{301}'
            'ŚS\u{301}S' . replace 's' 'O' Matching_Mode.First . should_equal 'ŚS\u{301}S'

            'SŚS\u{301}' . replace 'ś' 'O' . should_equal 'SŚS\u{301}'
            'SŚS\u{301}' . replace 's\u{301}' 'O' . should_equal 'SŚS\u{301}'

            'SŚS\u{301}' . replace 's' 'O' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'OŚS\u{301}'
            'SŚS\u{301}' . replace 's' 'O' Matching_Mode.Last matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'OŚS\u{301}'
            'ŚS\u{301}S' . replace 's' 'O' Matching_Mode.First matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'ŚS\u{301}O'

            'SŚS\u{301}' . replace 'ś' 'O' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'SOO'
            'SŚS\u{301}' . replace 's\u{301}' 'O' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'SOO'

            '✨🚀🚧😍😃😍😎😙😉☺' . replace '🚧😍' '|-|:)' . should_equal '✨🚀|-|:)😃😍😎😙😉☺'
            'Rocket Science' . replace 'Rocket' '🚀' . should_equal '🚀 Science'

            "Korean: 건반".replace "건반" "keyboard" . should_equal "Korean: keyboard"

        Test.specify "will approximate ligature matches" <|
            # TODO do we want to improve this? highly non-trivial for very rare edge cases
            ## Currently we lack 'resolution' to extract a partial match from
               the ligature to keep it, probably would need some special
               mapping.
            'ﬃﬃ'.replace 'ff' 'aa' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'aaaa'
            'ﬃﬃ'.replace 'ff' 'aa' mode=Matching_Mode.First matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'aaﬃ'
            'ﬃﬃ'.replace 'ff' 'aa' mode=Matching_Mode.Last matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'ﬃaa'
            'aﬃﬃb'.replace 'IF' 'X' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'aXb'
            'aiﬃffz' . replace 'if' '-' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'a--fz'
            'AFFIB'.replace 'ﬃ' '-' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'A-B'

            'ß'.replace 'SS' 'A' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'A'
            'ß'.replace 'S' 'A' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'AA'
            'ß'.replace 'S' 'A' mode=Matching_Mode.First matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'A'
            'ß'.replace 'S' 'A' mode=Matching_Mode.Last matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'A'
            'STRASSE'.replace 'ß' '-' matcher=(Text_Matcher_Data Case_Insensitive_Data) . should_equal 'STRA-E'

        Test.specify "should perform simple replacement in Regex mode" <|
            "ababab".replace "b" "a" matcher=Regex_Matcher_Data . should_equal "aaaaaa"
            "ababab".replace "b" "a" mode=Matching_Mode.First matcher=Regex_Matcher_Data . should_equal "aaabab"
            "ababab".replace "b" "a" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal "ababaa"

            "aaaa".replace "aa" "c" matcher=Regex_Matcher_Data . should_equal "cc"
            "aaaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher_Data . should_equal "caa"
            "aaaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal "aac"

            "aaa".replace "aa" "c" matcher=Regex_Matcher_Data . should_equal "ca"
            "aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher_Data . should_equal "ca"
            "aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Text_Matcher_Data . should_equal "ac"
            "aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal "ca"

            "aaa aaa".replace "aa" "c" matcher=Text_Matcher_Data . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Text_Matcher_Data . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Text_Matcher_Data . should_equal "aaa ac"
            "aaa aaa".replace "aa" "c" matcher=Regex_Matcher_Data . should_equal "ca ca"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.First matcher=Regex_Matcher_Data . should_equal "ca aaa"
            "aaa aaa".replace "aa" "c" mode=Matching_Mode.Last matcher=Regex_Matcher_Data . should_equal "aaa ca"

        Test.specify "in Regex mode should work with Unicode" <|
            "Korean: 건반".replace "건반" "keyboard" matcher=Regex_Matcher_Data . should_equal "Korean: keyboard"
            'sśs\u{301}'.replace 'ś' '-' matcher=Regex_Matcher_Data . should_equal 's--'
            'sśs\u{301}'.replace 's\u{301}' '-' matcher=Regex_Matcher_Data . should_equal 's--'

        Test.specify "in Regex mode should support various Regex options" <|
            r1 = "İiİ".replace "\w" "a" matcher=(Regex_Matcher_Data match_ascii=True)
            r1 . should_equal "İaİ"
            r2 = "abaBa".replace "b" "a" matcher=(Regex_Matcher_Data case_sensitive=Case_Insensitive_Data)
            r2 . should_equal "aaaaa"
            r3 = 'ab\na'.replace "b." "a"  matcher=(Regex_Matcher_Data dot_matches_newline=True)
            r3 . should_equal "aaa"

            text = """
                Foo
                bar
            r4 = text.replace '\n' ""  matcher=(Regex_Matcher_Data multiline=True)
            r4 . should_equal "Foobar"

            r5 = "ababd".replace "b\w # Replacing a `b` followed by any word character" "a" matcher=(Regex_Matcher_Data comments=True)
            r5 . should_equal "aaa"

        Test.specify "in Regex mode should allow referring to capture groups in substitutions" <|
            '<a href="url">content</a>'.replace '<a href="(.*?)">(.*?)</a>' '$2 is at $1' matcher=Regex_Matcher_Data . should_equal 'content is at url'
            '<a href="url">content</a>'.replace '<a href="(?<address>.*?)">(?<text>.*?)</a>' '${text} is at ${address}' matcher=Regex_Matcher_Data . should_equal 'content is at url'

main = Test.Suite.run_main spec
