from Standard.Base import all
import Standard.Base.Error.Problem_Behavior
from Standard.Base.Data.Text.Encoding as Encoding_Module import Encoding, Encoding_Error

import Standard.Table
import Standard.Table.Data.Column
from Standard.Table.Errors import all
import Standard.Table.IO.File_Read
from Standard.Table.IO.File_Format import Delimited
from Standard.Table.Data.Data_Formatter as Data_Formatter_Module import Data_Formatter
import Standard.Table.IO.Quote_Style
from Standard.Table.IO.Line_Ending_Style import all

import Standard.Test
import Standard.Test.Problems

import project.Util

spec =
    Test.group "Delimited File Parsing" <|
        Test.specify "should load a simple table with headers" <|
            c_1 = ["a", ['1', '4', '7', '10']]
            c_2 = ["b", ['2', Nothing, '8', '11']]
            c_3 = ["c", [Nothing, '6', '9', '12']]
            expected_table = Table.new [c_1, c_2, c_3]
            simple_empty = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True value_formatter=Nothing)
            simple_empty.should_equal expected_table

        Test.specify "should load a simple table without headers" <|
            c_1 = ["Column_1", ['a', '1', '4', '7', '10']]
            c_2 = ["Column_2", ['b', '2', Nothing, '8', '11']]
            c_3 = ["Column_3", ['c', Nothing, '6', '9', '12']]
            expected_table = Table.new [c_1, c_2, c_3]
            simple_empty = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False value_formatter=Nothing)
            simple_empty.should_equal expected_table

        Test.specify "should work in presence of missing headers" <|
            action on_problems = File.read (enso_project.data / "missing_header.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems
            tester table =
                table.columns.map .name . should_equal ["a", "Column_1", "c", "Column_2", "d"]
                table.at "a" . to_vector . should_equal ["1"]
                table.at "Column_1" . to_vector . should_equal ["2"]
                table.at "c" . to_vector . should_equal ["3"]
                table.at "Column_2" . to_vector . should_equal ["4"]
                table.at "d" . to_vector . should_equal ["5"]
            problems = [Invalid_Output_Column_Names [Nothing, Nothing]]
            Problems.test_problem_handling action problems tester

        Test.specify "should infer headers based on the first two rows" <|
            t1 = File.read (enso_project.data / "data_small.csv") (Delimited "," headers=File_Format.Infer)
            t1.columns.map .name . should_equal ["Code", "Index", "Flag", "Value", "ValueWithNothing", "TextWithNothing", "Hexadecimal", "Leading0s", "QuotedNumbers", "Mixed Types"]

            t2 = File.read (enso_project.data / "all_text.csv") (Delimited "," headers=File_Format.Infer)
            t2.columns.map .name . should_equal ["Column_1", "Column_2"]
            t2.at "Column_1" . to_vector . should_equal ["a", "c", "e", "g"]
            t2.at "Column_2" . to_vector . should_equal ["b", "d", "f", "h"]

            t3 = File.read (enso_project.data / "two_rows1.csv") (Delimited "," headers=File_Format.Infer)
            t3.columns.map .name . should_equal ["a", "b", "c"]
            t3.at "a" . to_vector . should_equal ["x"]
            t3.at "b" . to_vector . should_equal [Nothing]
            t3.at "c" . to_vector . should_equal [Nothing]

            t4 = File.read (enso_project.data / "two_rows2.csv") (Delimited "," headers=File_Format.Infer)
            t4.columns.map .name . should_equal ["Column_1", "Column_2", "Column_3"]
            t4.at "Column_1" . to_vector . should_equal ["a", "d"]
            t4.at "Column_2" . to_vector . should_equal ["b", "e"]
            t4.at "Column_3" . to_vector . should_equal ["c", "f"]

            t5 = File.read (enso_project.data / "numbers_in_header.csv") (Delimited "," headers=File_Format.Infer)
            t5.columns.map .name . should_equal ["Column_1", "Column_2", "Column_3"]
            t5.at "Column_1" . to_vector . should_equal ["a", "1"]
            t5.at "Column_2" . to_vector . should_equal ["b", "2"]
            t5.at "Column_3" . to_vector . should_equal [0, 3]

            t6 = File.read (enso_project.data / "quoted_numbers_in_header.csv") (Delimited "," headers=File_Format.Infer)
            t6.columns.map .name . should_equal ["1", "x"]
            t6.at "1" . to_vector . should_equal ["y"]
            t6.at "x" . to_vector . should_equal [2]

        Test.specify "should not use the first row as headers if it is the only row, unless specifically asked to" <|
            t1 = File.read (enso_project.data / "one_row.csv") (Delimited "," headers=File_Format.Infer)
            t1.columns.map .name . should_equal ["Column_1", "Column_2", "Column_3"]
            t1.at "Column_1" . to_vector . should_equal ["x"]
            t1.at "Column_2" . to_vector . should_equal ["y"]
            t1.at "Column_3" . to_vector . should_equal ["z"]

            t2 = File.read (enso_project.data / "one_row.csv") (Delimited "," headers=True)
            t2.columns.map .name . should_equal ["x", "y", "z"]
            t2.row_count .  should_equal 0
            t2.at "x" . to_vector . should_equal []

        Test.specify "should be able to load even an empty file" <|
            table = File.read (enso_project.data / "empty.txt") (Delimited "," headers=True value_formatter=Nothing)
            table.columns.map .name . should_equal []
            table.row_count . should_equal 0

        Test.specify "should correctly handle file opening issues" <|
            nonexistent_file = enso_project.data / "a_filename_that_does_not_exist.foobar"
            r1 = File.read nonexistent_file (Delimited "," headers=True value_formatter=Nothing)
            r1.should_fail_with File.File_Not_Found

            directory = enso_project.data
            r2 = File.read directory (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error
            r2.should_fail_with File.IO_Error

        Test.specify "should work with all kinds of line endings" <|
            path name = enso_project.data / 'transient' / name
            create_file name ending_style =
                lines = ['a,b,c', 'd,e,f', '1,2,3']
                text = lines.join ending_style
                text.write (path name)

            test_file name =
                table = File.read (path name) (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['d', '1']
                table.at 'b' . to_vector . should_equal ['e', '2']
                table.at 'c' . to_vector . should_equal ['f', '3']

            create_file 'crlf.csv' '\r\n'
            test_file 'crlf.csv'
            create_file 'lf.csv' '\n'
            test_file 'lf.csv'
            create_file 'cr.csv' '\r'
            test_file 'cr.csv'

            # Currently mixed line endings are not supported.
            'a,b,c\nd,e,f\r1,2,3'.write (path 'mixed.csv')
            File.read (path 'mixed.csv') (Delimited "," headers=True value_formatter=Nothing) Problem_Behavior.Report_Error . should_fail_with Invalid_Row

            ['crlf.csv', 'lf.csv', 'cr.csv', 'mixed.csv'].each (path >> .delete)

        Test.specify "should allow to override line endings style" <|
            file = enso_project.data / "transient" / "lf.csv"
            lines = ['a,b,c', 'd,e,f', '1,2,3']
            text = lines.join '\n'
            text.write file

            format = Delimited ',' headers=False value_formatter=(Data_Formatter trim_values=False)

            reference_table = Table.new [["Column_1", ["a", "d", "1"]], ["Column_2", ["b", "e", "2"]], ["Column_3", ["c", "f", "3"]]]
            collapsed_table = Table.new <|
                ['a', 'b', 'c\nd', 'e', 'f\n1', 2, 3].map_with_index i-> v->
                    ["Column_" + (i+1).to_text, [v]]
            File.read file format . should_equal reference_table
            File.read file (format.with_line_endings Unix_Line_Endings) . should_equal reference_table
            File.read file (format.with_line_endings Classic_Mac_Line_Endings) . should_equal collapsed_table
            File.read file (format.with_line_endings Windows_Line_Endings) . should_equal collapsed_table
            file.delete

            file_2 = enso_project.data / "transient" / "crlf.csv"
            lines.join '\r\n' . write file_2
            File.read file_2 (format.with_line_endings Windows_Line_Endings) . should_equal reference_table

            # For some reason loading the CRLF file in Unix mode trims the CR characters. We may want to revisit this at some point.
            table = File.read file_2 (format.with_line_endings Unix_Line_Endings)
            table . should_equal reference_table
            file_2.delete

        Test.specify "should work with Windows-1252 encoding" <|
            table = File.read (enso_project.data / "windows.csv") (Delimited "," headers=True encoding=Encoding.windows_1252) Problem_Behavior.Report_Error
            table.columns.map .name . should_equal ['a', 'b', 'c']
            table.at 'a' . to_vector . should_equal ['$¢']
            table.at 'b' . to_vector . should_equal ['¤']
            table.at 'c' . to_vector . should_equal ['¥']

        Test.specify "should work with UTF-16 encoding" <|
            table = File.read (enso_project.data / "utf16.csv") (Delimited "," headers=True encoding=Encoding.utf_16_be) Problem_Behavior.Report_Error
            table.columns.map .name . should_equal ['ą', '🚀b', 'ć😎']
            table.at 'ą' . to_vector . should_equal ['ą']
            table.at '🚀b' . to_vector . should_equal ['✨🚀🚧😍😃😍😎😙😉☺']
            table.at 'ć😎' . to_vector . should_equal ['แมวมีสี่ขา']

        Test.specify "should report errors when encountering malformed characters" <|
            utf8_file = (enso_project.data / "transient" / "utf8_invalid.csv")
            utf8_bytes = [97, 44, 98, 44, 99, 10, -60, -123, 44, -17, -65, -65, 44, -61, 40, -61, 40, 10]
            utf8_bytes.write_bytes utf8_file
            action_1 on_problems =
                utf8_file.read (Delimited "," headers=True) on_problems
            tester_1 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['ą']
                table.at 'b' . to_vector . should_equal ['\uFFFF']
                table.at 'c' . to_vector . should_equal ['\uFFFD(\uFFFD(']
            problems_1 = [Encoding_Error "Encoding issues at bytes 13, 15."]
            Problems.test_problem_handling action_1 problems_1 tester_1
            utf8_file.delete

            action_2 on_problems =
                (enso_project.data / "utf16_invalid.csv").read (Delimited "," headers=True encoding=Encoding.utf_16_be) on_problems
            tester_2 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                # This column does not raise a problem - the '\uFFFD' is simply present in the input file.
                table.at 'a' . to_vector . should_equal ['\uFFFD']
                table.at 'b' . to_vector . should_equal ['\uFFFF']
                # However, this column will raise a problem as the '\uFFFD' comes from replacing an invalid codepoint.
                table.at 'c' . to_vector . should_equal ['\uFFFD']
            problems_2 = [Encoding_Error "Encoding issues at byte 22."]
            Problems.test_problem_handling action_2 problems_2 tester_2

        Test.specify "should handle duplicated columns" <|
            action on_problems = File.read (enso_project.data / "duplicated_columns.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems
            tester table =
                table.columns.map .name . should_equal ['a', 'b', 'c', 'a_1']
                table.at 'a' . to_vector . should_equal ['1']
                table.at 'a_1' . to_vector . should_equal ['4']
            problems = [Duplicate_Output_Column_Names ['a']]
            Problems.test_problem_handling action problems tester

        Test.specify "should handle quotes" <|
            t1 = File.read (enso_project.data / "double_quoted.csv") (Delimited "," headers=True value_formatter=Nothing)
            t1.at 'a' . to_vector . should_equal ['a, x', '"a']
            t1.at 'c' . to_vector . should_equal ['3', '"']

            t2 = File.read (enso_project.data / "escape_quoted.csv") (Delimited "," headers=True value_formatter=Nothing . with_quotes quote_escape="\")
            t2.at 'a' . to_vector . should_equal ['a"b', 'a\\\"z']

            t3 = File.read (enso_project.data / "no_quoting.csv") (Delimited "," headers=True value_formatter=Nothing . without_quotes)
            t3.at 'a' . to_vector . should_equal ['"y']
            t3.at 'b' . to_vector . should_equal ['z"']
            t3.at 'c' . to_vector . should_equal ['a']

        Test.specify "should support rows spanning multiple lines if quoted" <|
            t1 = File.read (enso_project.data / "multiline_quoted.csv") (Delimited "," headers=True value_formatter=Nothing)
            t1.at 'a' . to_vector . should_equal ['1', '4']
            t1.at 'b' . to_vector . should_equal ['start\n\ncontinue', '5']
            t1.at 'c' . to_vector . should_equal ['3', '6']

        Test.specify "should behave correctly in presence of a mismatched quote" <|
            action_1 on_problems =
                File.read (enso_project.data / "mismatched_quote.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems

            tester_1 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1', 'abc', '7']
                table.at 'b' . to_vector . should_equal ['2', 'def', '8']
                table.at 'c' . to_vector . should_equal ['3', 'g h i"', '9']
            problems_1 = [Mismatched_Quote]
            Problems.test_problem_handling action_1 problems_1 tester_1

            action_2 on_problems =
                File.read (enso_project.data / "mismatched_quote2.csv") (Delimited "," headers=True value_formatter=Nothing) on_problems

            tester_2 table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1', 'abc']
                table.at 'b' . to_vector . should_equal ['2', '"def,g h i\n7,8,9\n']
                table.at 'c' . to_vector . should_equal ['3', Nothing]
            problems_2 = [Invalid_Row 3 1 ['abc', '"def,g h i\n7,8,9\n'], Mismatched_Quote]
            Problems.test_problem_handling action_2 problems_2 tester_2

        Test.specify "should handle too long and too short rows" <|
            action keep_invalid_rows on_problems =
                File.read (enso_project.data / "varying_rows.csv") (Delimited "," headers=True keep_invalid_rows=keep_invalid_rows value_formatter=Nothing) on_problems

            tester_kept table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1', '1', '1', Nothing, '1', '1']
                table.at 'b' . to_vector . should_equal ['2', '2', '2', Nothing, Nothing, '2']
                table.at 'c' . to_vector . should_equal ['3', '3', Nothing, Nothing, Nothing, '3']
            problems_kept = [Invalid_Row 2 0 ['1', '2', '3', '4'], Invalid_Row 4 2 ['1', '2'], Invalid_Row 5 3 [Nothing], Invalid_Row 6 4 ['1'], Invalid_Row 7 5 ['1', '2', '3', '4', '5', '6', '7', '8']]
            Problems.test_problem_handling (action keep_invalid_rows=True) problems_kept tester_kept

            tester_dropped table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['1']
                table.at 'b' . to_vector . should_equal ['2']
                table.at 'c' . to_vector . should_equal ['3']
            problems_dropped = [Invalid_Row 2 Nothing ['1', '2', '3', '4'], Invalid_Row 4 Nothing ['1', '2'], Invalid_Row 5 Nothing [Nothing], Invalid_Row 6 Nothing ['1'], Invalid_Row 7 Nothing ['1', '2', '3', '4', '5', '6', '7', '8']]
            Problems.test_problem_handling (action keep_invalid_rows=False) problems_dropped tester_dropped

        Test.specify "should aggregate invalid rows over some limit" <|
            action on_problems =
                File.read (enso_project.data / "many_invalid_rows.csv") (Delimited "," headers=True keep_invalid_rows=False value_formatter=Nothing) on_problems

            tester table =
                table.columns.map .name . should_equal ['a', 'b', 'c']
                table.at 'a' . to_vector . should_equal ['0', '5']
                table.at 'b' . to_vector . should_equal ['x', 'u']
                table.at 'c' . to_vector . should_equal ['y', 'v']
            problems = [Invalid_Row 3 Nothing ['1'], Invalid_Row 4 Nothing ['2'], Invalid_Row 5 Nothing ['3'], Invalid_Row 6 Nothing ['4'], Invalid_Row 8 Nothing ['6'], Invalid_Row 9 Nothing ['7'], Invalid_Row 10 Nothing ['8'], Invalid_Row 11 Nothing ['9'], Invalid_Row 12 Nothing ['10'], Invalid_Row 13 Nothing ['11'], Additional_Invalid_Rows 3]
            Problems.test_problem_handling action problems tester

        Test.specify "should allow to skip rows" <|
            t1 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 value_formatter=Nothing)
            t1.at "Column_1" . to_vector . should_equal ['7', '10']

            t2 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True skip_rows=3 value_formatter=Nothing)
            t2.columns.map .name . should_equal ['7', '8', '9']
            t2.at "7" . to_vector . should_equal ['10']

        Test.specify "should allow to set a limit of rows to read" <|
            t1 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False row_limit=2 value_formatter=Nothing)
            t1.at "Column_1" . to_vector . should_equal ['a', '1']

            t2 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True row_limit=2 value_formatter=Nothing)
            t2.at "a" . to_vector . should_equal ['1', '4']

            t3 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 row_limit=1 value_formatter=Nothing)
            t3.at "Column_1" . to_vector . should_equal ['7']

            t4 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False row_limit=0 value_formatter=Nothing)
            t4.columns.map .name . should_equal ['Column_1', 'Column_2', 'Column_3']
            t4.row_count . should_equal 0

            t5 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=True row_limit=0 value_formatter=Nothing)
            t5.columns.map .name . should_equal ['a', 'b', 'c']
            t5.at 'a' . to_vector . should_equal []
            t5.row_count . should_equal 0

            t6 = File.read (enso_project.data / "simple_empty.csv") (Delimited "," headers=False skip_rows=3 row_limit=1000 value_formatter=Nothing)
            t6.at "Column_1" . to_vector . should_equal ['7', '10']

        Test.specify "should check arguments" <|
            path = (enso_project.data / "simple_empty.csv")
            pb = Problem_Behavior.Report_Error
            path.read (Delimited "," headers=False . with_quotes quote='abc') pb . should_fail_with Illegal_Argument_Error
            path.read (Delimited "," headers=False . with_quotes quote='🚧') pb . should_fail_with Illegal_Argument_Error
            path.read (Delimited "," headers=False . with_quotes quote_escape='//') pb . should_fail_with Illegal_Argument_Error
            path.read (Delimited 'a\u{301}' headers=False) pb . should_fail_with Illegal_Argument_Error

        Test.specify "should correctly guess column types" <|
            t = (enso_project.data / "data_small.csv") . read (Delimited "," headers=True)
            t.at "Code" . to_vector . should_equal ["gxl", "wca", "nfw", "der"]
            t.at "Index" . to_vector . should_equal [7, 0, 1, 7]
            t.at "Flag" . to_vector . should_equal [True, False, True, True]
            t.at "Value" . to_vector . should_equal [38.76109, -66.77495, 88.65713, 0.86658]
            t.at "ValueWithNothing" . to_vector . should_equal [63.13, 31.0, -68.71, Nothing]
            t.at "TextWithNothing" . to_vector . should_equal ["pq6igd2wyd", "  2pr4102wc4  ", "", Nothing]
            t.at "Hexadecimal" . to_vector . should_equal ["4DD4675B", Nothing, "01896EAB", "F32E1EFE"]
            t.at "Leading0s" . to_vector . should_equal ["001", "002", "123", Nothing]
            t.at "QuotedNumbers" . to_vector . should_equal ["1", "2", Nothing, "34"]
            t.at "Mixed Types" . to_vector . should_equal ["33", Nothing, "45", "True"]

            t2 = (enso_project.data / "data_small.csv") . read (Delimited "," headers=True value_formatter=(Data_Formatter allow_leading_zeros=True))
            t2.at "Leading0s" . to_vector . should_equal [1, 2, 123, Nothing]

        Test.specify "should be able to detect types automatically" <|
            t1 = (enso_project.data / "data_small.csv") . read
            t1.at "Code" . to_vector . should_equal ["gxl", "wca", "nfw", "der"]
            t1.at "Index" . to_vector . should_equal [7, 0, 1, 7]

            t2 = (enso_project.data / "sample.tsv") . read
            t2.at "a" . to_vector . should_equal [1, 4]
            t2.at "b" . to_vector . should_equal [2, 5]
            t2.at "c" . to_vector . should_equal [3, 6]
            t2.columns.map .name . should_equal ["a", "b", "c"]

        Test.specify "should be able to parse raw text" <|
            text1 = """
                a,b,c
                1,2,3
                4,5,6
            t1 = Table.Table.from text1 (format = Delimited ",")
            t1.columns.map .name . should_equal ["a", "b", "c"]
            t1.at "a" . to_vector . should_equal [1, 4]
            t1.at "b" . to_vector . should_equal [2, 5]
            t1.at "c" . to_vector . should_equal [3, 6]

            text2 = 'a\tb\n1\t2\n3\t4'
            t2 = Table.Table.from text2
            t2.columns.map .name . should_equal ["a", "b"]
            t2.at "a" . to_vector . should_equal [1, 3]
            t2.at "b" . to_vector . should_equal [2, 4]

        Test.specify "should be able to read column names starting with #" <|
            reference_table = Table.new [["#", ["a", ";1", "5"]], ["x", [42, 2, 6]], ["y", ["c # comment??", "3", "7;comment?"]]]
            table = File.read (enso_project.data / "comments.csv")
            table.should_equal reference_table

        Test.specify "should be able to handle comments if enabled" <|
            table_hash = Table.new [["a", [";1", "5"]], ["42", [2, 6]], ["c # comment??", ["3", "7;comment?"]]]
            table_semicolon = Table.new [["#", ["a", "5"]], ["x", [42, 6]], ["y", ["c # comment??", "7;comment?"]]]

            File.read (enso_project.data / "comments.csv") (Delimited ',' . with_comments . with_headers) . should_equal table_hash
            File.read (enso_project.data / "comments.csv") (Delimited ',' . with_comments ';' . with_headers) . should_equal table_semicolon

        Test.specify "should allow to build the Delimited configuration using builders" <|
            Delimited "," . clone . should_equal (Delimited ",")
            Delimited "," encoding=Encoding.ascii skip_rows=123 row_limit=100 headers=False value_formatter=Nothing . clone . should_equal (Delimited "," headers=False value_formatter=Nothing skip_rows=123 row_limit=100 encoding=Encoding.ascii)
            Delimited "," . clone quote_style=Quote_Style.No_Quotes headers=False value_formatter=Nothing . should_equal (Delimited "," headers=False value_formatter=Nothing quote_style=Quote_Style.No_Quotes)

            Delimited '\t' . with_quotes "|" . should_equal (Delimited '\t' quote_style=(Quote_Style.With_Quotes quote='|' quote_escape='|'))
            Delimited '\t' . with_quotes "-" '\\' True . should_equal (Delimited '\t' quote_style=(Quote_Style.With_Quotes always_quote=True quote='-' quote_escape='\\'))
            Delimited '\t' . without_quotes . should_equal (Delimited '\t' quote_style=Quote_Style.No_Quotes)

            Delimited ',' . with_headers . should_equal (Delimited ',' headers=True)
            Delimited ',' . without_headers . should_equal (Delimited ',' headers=False)
            Delimited "," skip_rows=123 headers=False value_formatter=Nothing quote_style=Quote_Style.No_Quotes . with_headers . should_equal (Delimited "," skip_rows=123 value_formatter=Nothing quote_style=Quote_Style.No_Quotes headers=True)
            Delimited "," skip_rows=123 headers=True value_formatter=Nothing quote_style=Quote_Style.No_Quotes . without_headers . should_equal (Delimited "," skip_rows=123 value_formatter=Nothing quote_style=Quote_Style.No_Quotes headers=False)

            Delimited ',' . with_parsing . should_equal (Delimited ',')
            Delimited ',' . without_parsing . should_equal (Delimited ',' value_formatter=Nothing)
            custom_formatter = Data_Formatter true_values=["A", "B", "C"] false_values=["D", "E", "F"]
            Delimited ',' . with_parsing custom_formatter . should_equal (Delimited ',' value_formatter=custom_formatter)
            Delimited ',' row_limit=456 . without_parsing . should_equal (Delimited ',' value_formatter=Nothing row_limit=456)

            Delimited ',' . with_comments . should_equal (Delimited ',' comment_character='#')
            Delimited ',' . with_comments ';' . should_equal (Delimited ',' comment_character=';')
            Delimited ',' comment_character='#' . without_comments . should_equal (Delimited ',' comment_character=Nothing)
            Delimited ',' . with_line_endings Unix_Line_Endings . should_equal (Delimited ',' line_endings=Unix_Line_Endings)

main = Test.Suite.run_main spec
