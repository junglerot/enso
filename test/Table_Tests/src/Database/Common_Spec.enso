from Standard.Base import all

from Standard.Table import Table, Sort_Column
from Standard.Table.Data.Aggregate_Column.Aggregate_Column import all
from Standard.Table.Errors import all

from Standard.Database import all
from Standard.Database.Errors import all

from Standard.Test import Test, Test_Suite, Problems
import Standard.Test.Extensions

import project.Util
import project.Database.Helpers.Name_Generator

spec prefix connection =
    tables_to_clean = Vector.new_builder
    upload prefix data temporary=True =
        name = Name_Generator.random_name prefix
        table = connection.upload_table name data temporary=temporary
        tables_to_clean.append name
        table

    ## We have to upload the table as non-temporary, because otherwise it will
       not be visible in the list of tables and make `Table.query` confused.
    t1 = upload "T1" (Table.new [["a", [1, 4]], ["b", [2, 5]], ["c", [3, 6]]]) temporary=False
    Test.group prefix+"Basic Table Access" <|
        Test.specify "should allow to materialize tables and columns into local memory" <|
            df = t1.read
            a = t1.at 'a' . read
            df.at 'a' . to_vector . should_equal [1, 4]
            a.to_vector . should_equal [1, 4]
        Test.specify "should allow to materialize columns directly into a Vector" <|
            v = t1.at 'a' . to_vector
            v . should_equal [1, 4]
        Test.specify "should handle bigger result sets" <|
            n = 1000
            original = Table.new [["a", Vector.new n ix->ix], ["b", Vector.new n ix-> ix *  3.1415926], ["c", Vector.new n ix-> ix.to_text]]
            table = upload "Big" original
            table.read.row_count . should_equal n

    Test.group prefix+"Table.query" <|
        name = t1.name
        Test.specify "should allow to access a Table by name" <|
            t2 = connection.query (SQL_Query.Table_Name name)
            t2.read . should_equal t1.read

        Test.specify "should allow to access a Table by an SQL query" <|
            t2 = connection.query (SQL_Query.Raw_SQL ('SELECT a, b FROM "' + name + '" WHERE a >= 3'))
            m2 = t2.read
            m2.column_names . should_equal ["a", "b"]
            m2.at "a" . to_vector . should_equal [4]
            m2.at "b" . to_vector . should_equal [5]
            m2.at "c" . should_fail_with No_Such_Column

        Test.specify "should allow a shorthand trying to deduce if the query is a table name or an SQL query" <|
            t2 = connection.query name
            t2.read . should_equal t1.read

            t3 = connection.query ('SELECT a, b FROM "' + name + '" WHERE a >= 3')
            m3 = t3.read
            m3.column_names . should_equal ["a", "b"]
            m3.at "a" . to_vector . should_equal [4]

            ## The effective name may get a deduplication prefix/suffix so we
               need to use `t4.name` instead of the literal string. Still it
               will contain the weird characters we wanted.

               Also, the table name cannot be too long as Postgres truncates at
               63 chars (and we append 37 chars of uniqueness suffix) and the
               test logic will break then.
            t4 = upload 'aSELECT "A",\'B\' FROM t;--' (Table.new [["X", ["a", "B"]], ["Y", [2, 5]]]) temporary=False
            t5 = connection.query t4.name
            m5 = t5.read
            m5.column_names . should_equal ["X", "Y"]
            m5.at "X" . to_vector . should_equal ["a", "B"]
            m5.at "Y" . to_vector . should_equal [2, 5]

        Test.specify "should report an error depending on input SQL_Query type" <|
            r2 = connection.query (SQL_Query.Table_Name "NONEXISTENT-TABLE")
            r2.should_fail_with Table_Not_Found
            r2.catch.name . should_equal "NONEXISTENT-TABLE"
            r2.catch.to_display_text . should_equal "Table NONEXISTENT-TABLE was not found in the database."

            r3 = connection.query (SQL_Query.Raw_SQL "MALFORMED-QUERY")
            r3.should_fail_with SQL_Error

        Test.specify "should make a best-effort attempt at returning a reasonable error for the short-hand" <|
            r2 = connection.query "NONEXISTENT-TABLE"
            r2.should_fail_with Table_Not_Found
            r2.catch.name . should_equal "NONEXISTENT-TABLE"
            r2.catch.treated_as_query . should_be_true
            error_text = r2.catch.to_display_text
            Test.with_clue "r2.catch.to_display_text = "+error_text <|
                error_text.starts_with "The name NONEXISTENT-TABLE was treated as a query, but the query failed" . should_be_true
                error_text.ends_with "wrap it in `SQL_Query.Table_Name`." . should_be_true

            r3 = connection.query "SELECT * FROM ........"
            r3.should_fail_with SQL_Error

    Test.group prefix+"Masking Tables" <|
        Test.specify "should allow to select rows from a table or column based on an expression" <|
            t2 = t1.filter (t1.at "a" == 1)
            df = t2.read
            df.at "a" . to_vector . should_equal [1]
            df.at "b" . to_vector . should_equal [2]
            df.at "c" . to_vector . should_equal [3]
            t2.at "a" . to_vector . should_equal [1]
            t2.at "b" . to_vector . should_equal [2]
            t2.at "c" . to_vector . should_equal [3]

    Test.group prefix+"Missing Values" <|
        t4 = upload "T4" <|
            Table.new [["a", [0, 1, Nothing, 42, Nothing]], ["b", [True, Nothing, True, False, Nothing]], ["c", ["", "foo", "bar", Nothing, Nothing]]]
        Test.specify "fill_missing should replace nulls" <|
            t4.at 'a' . fill_missing 10 . to_vector . should_equal [0, 1, 10, 42, 10]
            t4.at 'b' . fill_missing False . to_vector . should_equal [True, False, True, False, False]
            t4.at 'c' . fill_missing "NA" . to_vector . should_equal ["", "foo", "bar", "NA", "NA"]

        Test.specify "should correctly be counted" <|
            t4.row_count . should_equal 5
            col = t4.at 'a'
            col.length . should_equal 5
            col.count . should_equal 3
            col.count_missing . should_equal 2

    Test.group prefix+"Sorting" <|
        df = upload "clothes" <|
            Table.new [["id", [1,2,3,4,5,6]], ["name", ["shoes","trousers","dress","skirt","blouse","t-shirt"]], ["quantity", [20,10,20,10,30,30]], ["rating", [3.0,Nothing,7.3,3.0,2.2,Nothing]], ["price", [37.2,42.1,64.1,87.4,13.5,64.2]]]

        Test.specify "should allow sorting by a single column name" <|
            r_1 = df.order_by ([Sort_Column.Name 'quantity'])
            r_1.at 'id' . to_vector . should_equal [2,4,1,3,5,6]

            r_3 = df.order_by ([Sort_Column.Name 'rating' Sort_Direction.Descending])
            r_3.at 'id' . to_vector . should_equal [3,1,4,5,2,6]

        Test.specify 'should allow sorting by multiple column names' <|
            r_1 = df.order_by ([Sort_Column.Name 'quantity', Sort_Column.Name 'rating'])
            r_1.at 'id' . to_vector . should_equal [2,4,1,3,6,5]

            r_2 = df.order_by ([Sort_Column.Name 'rating' Sort_Direction.Descending, Sort_Column.Name 'quantity' Sort_Direction.Descending])
            r_2.at 'id' . to_vector . should_equal [3,1,4,5,6,2]

        Test.specify 'should allow sorting with specific by-column rules' <|
            r_1 = df.order_by ([Sort_Column.Name "quantity", Sort_Column.Name "price" Sort_Direction.Descending])
            r_1.at 'id' . to_vector . should_equal [4,2,3,1,6,5]

        Test.specify 'should correctly reorder all kinds of columns and leave the original columns untouched' <|
            ints = [1, 2, 3, 4, 5]
            reals = [1.3, 4.6, 3.2, 5.2, 1.6]
            bools = [False, False, True, True, False]
            texts = ["foo", "foo", "bar", "baz", "spam"]
            df = upload "T8" <|
                Table.new [["ord", [0,3,2,4,1]], ["ints", ints], ["reals", reals], ["bools", bools], ["texts", texts]]
            r = df.order_by ([Sort_Column.Name 'ord'])

            r.at 'ints' . to_vector . should_equal [1, 5, 3, 2, 4]
            df.at 'ints' . to_vector . should_equal ints

            r.at 'reals' . to_vector . should_equal [1.3, 1.6, 3.2, 4.6, 5.2]
            df.at 'reals' . to_vector . should_equal reals

            r.at 'bools' . to_vector . should_equal [False, False, True, False, True]
            df.at 'bools' . to_vector . should_equal bools

            r.at 'texts' . to_vector . should_equal ['foo', 'spam', 'bar', 'foo', 'baz']
            df.at 'texts' . to_vector . should_equal texts

        Test.specify 'should sort columns with specified ordering and missing placement' <|
            c = df.at 'rating'

            r_1 = c.sort
            r_1.to_vector.should_equal [Nothing, Nothing, 2.2, 3.0, 3.0, 7.3]

            r_2 = c.sort Sort_Direction.Descending
            r_2.to_vector.should_equal [7.3, 3.0, 3.0, 2.2, Nothing, Nothing]

    Test.group prefix+"Aggregation" <|
        builders = [Vector.new_builder,Vector.new_builder,Vector.new_builder]
        insert v =
            builders.zip v .append
        insert ["foo",  0.4,     50]
        insert ["foo",  0.2,     10]
        insert ["foo",  0.4,     30]
        insert ["bar",  3.5,     20]
        insert ["foo",  Nothing, 20]
        insert ["baz",  6.7,     40]
        insert ["foo",  Nothing, 10]
        insert ["bar",  97,      60]
        insert ["quux", Nothing, 70]
        insert ["zzzz", Nothing, Nothing]
        insert ["zzzz", 1, 1]
        insert ["zzzz", 0, 0]
        insert ["zzzz", 0, 1]
        insert ["zzzz", 1, 0]
        insert ["zzzz", 0, 0]
        insert ["zzzz", Nothing, Nothing]
        t = upload "T9" <|
            Table.new [["name", builders.at 0 . to_vector], ["price", builders.at 1 . to_vector], ["quantity", builders.at 2 . to_vector]]

        ## A helper which makes sure that the groups in a materialized
           (InMemory) table are ordered according to a specified column or list
           of columns.
        determinize_by order_column table =
            table.order_by ([Sort_Column.Name order_column])

        Test.specify "should allow counting group sizes and elements" <|
            ## Names set to lower case to avoid issue with Redshift where columns are
               returned in lower case.
            aggregates = [Count "count", Count_Not_Nothing "price" "count not nothing price", Count_Nothing "price" "count nothing price"]

            t1 = determinize_by "name" (t.aggregate ([Group_By "name"] + aggregates) . read)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            t1.at  "count" . to_vector . should_equal [2, 1, 5, 1, 7]
            t1.at  "count not nothing price" . to_vector . should_equal [2, 1, 3, 0, 5]
            t1.at  "count nothing price" . to_vector . should_equal [0, 0, 2, 1, 2]

            t2 = t.aggregate aggregates . read
            t2.at  "count" . to_vector . should_equal [16]
            t2.at  "count not nothing price" . to_vector . should_equal [11]
            t2.at  "count nothing price" . to_vector . should_equal [5]

        Test.specify "should allow simple arithmetic aggregations" <|
            ## Names set to lower case to avoid issue with Redshift where columns are
               returned in lower case.
            aggregates = [Sum "price" "sum price", Sum "quantity" "sum quantity", Average "price" "avg price"]
            ## TODO can check the datatypes

            t1 = determinize_by "name" (t.aggregate ([Group_By "name" Nothing] + aggregates) . read)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            t1.at  "sum price" . to_vector . should_equal [100.5, 6.7, 1, Nothing, 2]
            t1.at  "sum quantity" . to_vector . should_equal [80, 40, 120, 70, 2]
            t1.at  "avg price" . to_vector . should_equal [50.25, 6.7, (1/3), Nothing, (2/5)]

            t2 = t.aggregate aggregates . read
            t2.at  "sum price" . to_vector . should_equal [110.2]
            t2.at  "sum quantity" . to_vector . should_equal [312]
            t2.at  "avg price" . to_vector . should_equal [(110.2 / 11)]
    Test.group prefix+"Table.filter" <|
        Test.specify "report error when trying to filter by a custom predicate" <|
            t1.filter "a" (x -> x % 2 == 0) . should_fail_with Unsupported_Database_Operation.Error

    clean_table name = Panic.recover Any <|
        sql = 'DROP TABLE "' + name + '"'
        Panic.rethrow <| connection.execute_update sql
    tables_to_clean.to_vector.each clean_table

main = Test_Suite.run_main <|
    spec "[SQLite] " (Database.connect (SQLite In_Memory))
