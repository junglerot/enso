from Standard.Base import all
from Standard.Database import all
import Standard.Table.Data.Table as Materialized_Table
import Standard.Test

from Standard.Table.Data.Aggregate_Column import all

spec prefix connection pending=Nothing =
    clean_table name = Panic.recover Any <|
        sql = 'DROP TABLE "' + name + '"'
        Panic.rethrow <| connection.execute_update sql
    t1 = connection.upload_table "T1" (Materialized_Table.new [["a", [1, 4]], ["b", [2, 5]], ["c", [3, 6]]])
    Test.group prefix+"Basic Table Access" pending=pending <|
        Test.specify "should allow to materialize tables and columns into local memory" <|
            df = t1.to_dataframe
            a = t1.at 'a' . to_dataframe
            df.at 'a' . to_vector . should_equal [1, 4]
            a.to_vector . should_equal [1, 4]
        Test.specify "should allow to materialize columns directly into a Vector" <|
            v = t1.at 'a' . to_vector
            v . should_equal [1, 4]
        Test.specify "should preserve indexes when materializing tables" <|
            # TODO add multi indexes when implemented
            df = t1.set_index 'a' . to_dataframe
            df.at 'b' . to_vector . should_equal [2, 5]
            df.columns.map .name . should_equal ['b', 'c']
            ix = df.index
            ix.name . should_equal 'a'
            ix.to_vector . should_equal [1, 4]
        Test.specify "should preserve indexes when materializing columns" <|
            # TODO add multi indexes when implemented
            b = t1.set_index 'a' . at 'b'
            col = b . to_dataframe
            col.to_vector . should_equal [2, 5]

            ix = col.index
            ix.name . should_equal 'a'
            ix.to_vector . should_equal [1, 4]

            ix2 = b.to_table.index
            ix2.name . should_equal 'a'
            ix2.to_vector . should_equal [1, 4]
        Test.specify "should work correctly when there are no columns" <|
            empty = t1.select []
            empty.to_dataframe.columns.length . should_equal 0
            empty.to_dataframe.row_count . should_equal empty.row_count
        Test.specify "should handle bigger result sets" <|
            n = 1000
            original = Materialized_Table.new [["a", Vector.new n ix->ix], ["b", Vector.new n ix-> ix *  3.1415926], ["c", Vector.new n ix-> ix.to_text]]
            table = connection.upload_table "Big" original
            materialized = table.to_dataframe
            materialized.row_count . should_equal n

    Test.group prefix+"Mapping Operations" pending=pending <|
        t2 = connection.upload_table "T2" <| Materialized_Table.new [["x", [1, 4, 5, Nothing]], ["y", [2, 3, 5, Nothing]], ["b", [False, False, True, Nothing]]]
        x = t2.at "x"
        y = t2.at "y"
        b = t2.at "b"
        Test.specify "should allow combining columns with supported operations" <|
            (x + y).to_vector . should_equal [3, 7, 10, Nothing]
            (x - y).to_vector . should_equal [-1, 1, 0, Nothing]
            (x * y).to_vector . should_equal [2, 12, 25, Nothing]
            (x / y).to_vector . should_equal [0, 1, 1, Nothing]
            (x == y).to_vector . should_equal [False, False, True, Nothing]
            (x != y).to_vector . should_equal [True, True, False, Nothing]
            (x < y).to_vector . should_equal [True, False, False, Nothing]
            (x <= y).to_vector . should_equal [True, False, True, Nothing]
            (x > y).to_vector . should_equal (x <= y).not.to_vector
            (x >= y).to_vector . should_equal (x < y).not.to_vector
            (((x < y) || (x == y)) == (x <= y)).to_vector . should_equal [True, True, True, Nothing]
            (b || b.not).to_vector . should_equal [True, True, True, Nothing]

        Test.specify "should allow casting constants to be applied to the whole column" <|
            (x + 100).to_vector . should_equal [101, 104, 105, Nothing]
            (x * 10).to_vector . should_equal [10, 40, 50, Nothing]
            (x / 2).to_vector . should_equal [0, 2, 2, Nothing]
            (x - 10).to_vector . should_equal [-9, -6, -5, Nothing]
            (x == 4).to_vector . should_equal [False, True, False, Nothing]
            (x < 1000).to_vector . should_equal [True, True, True, Nothing]
            (b || False).to_vector . should_equal [False, False, True, Nothing]
            (b || True).to_vector . should_equal [True, True, True, True]
            (b && False).to_vector . should_equal [False, False, False, False]
            (x + Nothing).to_vector . should_equal [Nothing, Nothing, Nothing, Nothing]
            x.is_missing.to_vector . should_equal [False, False, False, True]
            (x == Nothing).to_vector . should_equal [Nothing, Nothing, Nothing, Nothing]

        t3 = connection.upload_table "T3" <| Materialized_Table.new [["s1", ["foobar", "bar", "baz", Nothing]], ["s2", ["foo", "ar", "a", Nothing]]]
        s1 = t3.at "s1"
        s2 = t3.at "s2"
        Test.specify "should handle Text operations" <|
            s1.starts_with s2 . to_vector . should_equal [True, False, False, Nothing]
            s1.starts_with "foo" . to_vector . should_equal [True, False, False, Nothing]
            s1.starts_with "ba" . to_vector . should_equal [False, True, True, Nothing]

            s1.contains s2 . to_vector . should_equal [True, True, True, Nothing]
            s1.contains "a" . to_vector . should_equal [True, True, True, Nothing]
            s1.contains "oo" . to_vector . should_equal [True, False, False, Nothing]

            s1.ends_with s2 . to_vector . should_equal [False, True, False, Nothing]
            s1.ends_with "ar" . to_vector . should_equal [True, True, False, Nothing]
            s1.ends_with "a" . to_vector . should_equal [False, False, False, Nothing]

    Test.group prefix+"Masking Tables" pending=pending <|
        Test.specify "should allow to select rows from a table or column based on an expression" <|
            t2 = t1.where (t1.at "a" == 1)
            df = t2.to_dataframe
            df.at "a" . to_vector . should_equal [1]
            df.at "b" . to_vector . should_equal [2]
            df.at "c" . to_vector . should_equal [3]
            t2.at "a" . to_vector . should_equal [1]
            t2.at "b" . to_vector . should_equal [2]
            t2.at "c" . to_vector . should_equal [3]

    Test.group prefix+"Joining Tables" pending=pending <|
        a = connection.upload_table "TA" <| Materialized_Table.new [["x", [0, 1, 7, 3, 6]], ["y", ["foo", "bar", "baz", "spam", "eggs"]]]
        b = connection.upload_table "TB" <| Materialized_Table.new [["w", [6, 3, 5, 5, 3, 3]], ["z", ["foo", "foo", "bar", "spam", "bar", "eggs"]]]

        ## The tests below use `sort`, because the SQL backend is not guaranteed
           to return the rows in any particular order. This is the `sort` from
           the Dataframes library, so it is independent of the library under
           testing here.
        Test.specify "should allow joining tables index-on-index" <|
            r_1 = a.set_index 'x' . join (b.set_index 'w') . to_dataframe . sort by=['y', 'z']
            r_1.at 'y' . to_vector . should_equal ['bar', 'baz', 'eggs', 'foo', 'spam', 'spam', 'spam']
            r_1.at 'z' . to_vector . should_equal [Nothing, Nothing, 'foo', Nothing, 'bar', 'eggs', 'foo']

            r_2 = a.set_index 'y' . join (b.set_index 'z') drop_unmatched=True . to_dataframe . sort by=['x', 'w']
            r_2.at 'x' . to_vector . should_equal [0, 0, 1, 1, 3, 6]
            r_2.at 'w' . to_vector . should_equal [3, 6, 3, 5, 5, 3]

        Test.specify "should allow joining tables column-on-index" <|
            r_1 = a.join (b.set_index 'w') on='x' . to_dataframe . sort by=['y', 'z']
            r_1.at 'y' . to_vector . should_equal ['bar', 'baz', 'eggs', 'foo', 'spam', 'spam', 'spam']
            r_1.at 'z' . to_vector . should_equal [Nothing, Nothing, 'foo', Nothing, 'bar', 'eggs', 'foo']
            r_2 = a.join (b.set_index 'z') drop_unmatched=True on='y' . to_dataframe . sort by=['x', 'w']
            r_2.at 'x' . to_vector . should_equal [0, 0, 1, 1, 3, 6]
            r_2.at 'w' . to_vector . should_equal [3, 6, 3, 5, 5, 3]

        Test.specify "should allow self-joins and append suffixes to disambiguate column names" <|
            r_1 = a.join (a.set_index 'x') on='x' . to_dataframe . sort by='x'
            r_1.columns.map .name . should_equal ['x', 'y_left', 'y_right']
            r_1.at 'x' . to_vector . should_equal [0, 1, 3, 6, 7]
            expected_y = ['foo', 'bar', 'spam', 'eggs', 'baz']
            r_1.at 'y_left' . to_vector . should_equal expected_y
            r_1.at 'y_right' . to_vector . should_equal expected_y

            r_2 = a.set_index 'x' . join (a.set_index 'x') left_suffix='_old' right_suffix='_new'
            r_2.columns.map .name . should_equal ['y_old', 'y_new']

        Test.specify "should correctly handle multi-joins" <|
            ta = connection.upload_table "M_TA" <| Materialized_Table.new [["id", [0, 1]], ["name", ["Foo", "Hmm"]]]
            tb = connection.upload_table "M_TB" <| Materialized_Table.new [["id", [2, 0]], ["name", ["Bar", "Hmm"]]]
            tc = connection.upload_table "M_TC" <| Materialized_Table.new [["id_a", [0, 1]], ["id_b", [2, 0]]]
            ta_2 = ta.set_index "id"
            tb_2 = tb.set_index "id"
            res = (tc.join ta_2 on="id_a") . join tb_2 on="id_b" left_suffix="_a" right_suffix="_b"
            sel = res.select ["name_a", "name_b"]
            df = sel.to_dataframe . sort by="name_a"
            df . at "name_a" . to_vector . should_equal ["Foo", "Hmm"]
            df . at "name_b" . to_vector . should_equal ["Bar", "Hmm"]

    Test.group prefix+"Missing Values" pending=pending <|
        t4 = connection.upload_table "T4" <|
            Materialized_Table.new [["a", [0, 1, Nothing, 42, Nothing]], ["b", [True, Nothing, True, False, Nothing]], ["c", ["", "foo", "bar", Nothing, Nothing]]]
        Test.specify "fill_missing should replace nulls" <|
            t4.at 'a' . fill_missing 10 . to_vector . should_equal [0, 1, 10, 42, 10]
            t4.at 'b' . fill_missing False . to_vector . should_equal [True, False, True, False, False]
            t4.at 'c' . fill_missing "NA" . to_vector . should_equal ["", "foo", "bar", "NA", "NA"]

        Test.specify "should correctly be counted" <|
            t4.row_count . should_equal 5
            col = t4.at 'a'
            col.length . should_equal 5
            col.count . should_equal 3
            col.count_missing . should_equal 2

        Test.specify "drop_missing should drop missing rows in a Column" <|
            col = t4.at 'a'
            col.drop_missing.to_vector . should_equal [0, 1, 42]

        Test.specify "drop_missing_rows should drop rows that contain at least one missing column in a Table" <|
            d = t4.drop_missing_rows.to_dataframe
            d.at 'a' . to_vector . should_equal [0]
            d.at 'b' . to_vector . should_equal [True]
            d.at 'c' . to_vector . should_equal [""]

        Test.specify "drop_missing_columns should drop columns that contain at least one missing row in a Table" <|
            t5 = connection.upload_table "T5" <|
                Materialized_Table.new [["a", [1, 2, 3]], ["b", [True, False, Nothing]], ["c", ["foo", Nothing, "aaa"]]]

            r = t5.drop_missing_columns
            r.columns.map .name . should_equal ["a"]
            r.at "a" . to_vector . should_equal [1, 2, 3]

            empty = t4.drop_missing_columns
            empty.columns.length . should_equal 0
            empty.to_dataframe.columns.length . should_equal 0

    Test.group prefix+"Old Aggregation" pending=pending <|
        t = connection.upload_table "T6" <|
            Materialized_Table.new [["name", ["foo", "bar", "foo", "baz", "foo", "bar", "quux"]], ["price", [0.4, 3.5, Nothing, 6.7, Nothing, 97, Nothing]], ["quantity", [10, 20, 30, 40, 50, 60, 70]]]
        agg = t.group by='name'
        ## A helper which makes sure that the groups are ordered according to the index, using the Table library
        determinize col =
            df = col.to_dataframe.to_table
            df.sort by=df.index . at col.name

        Test.specify "should allow counting group sizes" <|
            determinize agg.count . to_vector . should_equal [2, 1, 3, 1]

        Test.specify "should allow aggregating columns with basic arithmetic aggregators" <|
            determinize (agg.at 'price' . mean) . to_vector . should_equal [50.25, 6.7, 0.4, Nothing]
            determinize (agg.at 'price' . min) . to_vector . should_equal [3.5, 6.7, 0.4, Nothing]
            determinize (agg.at 'price' . max) . to_vector . should_equal [97, 6.7, 0.4, Nothing]

        Test.specify "should allow to join multiple aggregations" <|
            m1 = agg.at 'price' . mean
            m2 = agg.at 'quantity' . max
            df = (m1.join m2).to_dataframe
            df2 = df.sort by=df.index
            df2.at 'price_mean' . to_vector . should_equal [50.25, 6.7, 0.4, Nothing]
            df2.at 'quantity_max' . to_vector . should_equal [60, 40, 50, 70]

        Test.specify "should correctly compute the result size" <|
            m = agg.at 'price' . mean
            m.length . should_equal m.to_vector.length
            m.length . should_equal 4

        Test.specify "should correctly count values" <|
           m = agg.at 'price' . mean
           m.count . should_equal 3
           m.count_missing . should_equal 1

    Test.group prefix+"Column-wide statistics" pending=pending <|
        Test.specify 'should allow computing basic column-wide stats' <|
            t7 = connection.upload_table "T7" <|
                Materialized_Table.new [['price', [0.4, 3.5, Nothing, 6.7, Nothing, 97, Nothing]]]
            price = t7.at 'price'
            price.sum.should_equal 107.6
            price.min.should_equal 0.4
            price.max.should_equal 97
            price.mean.should_equal 26.9

    Test.group prefix+"Sorting" pending=pending <|
        df = connection.upload_table "clothes" <|
            Materialized_Table.new [["id", [1,2,3,4,5,6]], ["name", ["shoes","trousers","dress","skirt","blouse","t-shirt"]], ["quantity", [20,10,20,10,30,30]], ["rating", [3.0,Nothing,7.3,3.0,2.2,Nothing]], ["price", [37.2,42.1,64.1,87.4,13.5,64.2]]]

        Test.specify "should allow sorting by a single column name" <|
            r_1 = df.sort by="quantity"
            r_1.at 'id' . to_vector . should_equal [2,4,1,3,5,6]

            r_2 = df.sort by="rating" missing_last=False
            r_2.at 'id' . to_vector . should_equal [2,6,5,1,4,3]

            r_3 = df.sort by="rating" missing_last=False order=Sort_Order.Descending
            r_3.at 'id' . to_vector . should_equal [2,6,3,1,4,5]

        Test.specify 'should allow sorting by multiple column names' <|
            r_1 = df.sort by=['quantity', 'rating']
            r_1.at 'id' . to_vector . should_equal [4,2,1,3,5,6]

            r_2 = df.sort by=['rating', 'quantity'] missing_last=False order=Sort_Order.Descending
            r_2.at 'id' . to_vector . should_equal [6,2,3,1,4,5]

        Test.specify 'should allow sorting by external columns' <|
            quality_ratio = df.at 'rating' / df.at 'price'

            r_1 = df.sort by=quality_ratio
            r_1.at 'id' . to_vector . should_equal [4,1,3,5,2,6]

            r_2 = df.sort by=['quantity', quality_ratio]
            r_2.at 'id' . to_vector . should_equal [4,2,1,3,5,6]

        Test.specify 'should allow sorting with specific by-column rules' <|
            r_1 = df.sort by=['quantity', (Order_Rule 'price' order=Sort_Order.Descending)]
            r_1.at 'id' . to_vector . should_equal [4,2,3,1,6,5]

        Test.specify 'should return dataflow error when passed a non-existent column' <|
            r = df.sort by='foobar'
            r.should_fail_with No_Such_Column_Error

        Test.specify 'should correctly reorder all kinds of columns and leave the original columns untouched' <|
            ints = [1, 2, 3, 4, 5]
            reals = [1.3, 4.6, 3.2, 5.2, 1.6]
            bools = [False, False, True, True, False]
            texts = ["foo", "foo", "bar", "baz", "spam"]
            df = connection.upload_table "T8" <|
                Materialized_Table.new [["ord", [0,3,2,4,1]], ["ints", ints], ["reals", reals], ["bools", bools], ["texts", texts]]
            r = df.sort by='ord'

            r.at 'ints' . to_vector . should_equal [1, 5, 3, 2, 4]
            df.at 'ints' . to_vector . should_equal ints

            r.at 'reals' . to_vector . should_equal [1.3, 1.6, 3.2, 4.6, 5.2]
            df.at 'reals' . to_vector . should_equal reals

            r.at 'bools' . to_vector . should_equal [False, False, True, False, True]
            df.at 'bools' . to_vector . should_equal bools

            r.at 'texts' . to_vector . should_equal ['foo', 'spam', 'bar', 'foo', 'baz']
            df.at 'texts' . to_vector . should_equal texts

        Test.specify 'should sort columns with specified ordering and missing placement' <|
            c = df.at 'rating'

            r_1 = c.sort
            r_1.to_vector.should_equal [2.2, 3.0, 3.0, 7.3, Nothing, Nothing]

            r_2 = c.sort order=Sort_Order.Descending
            r_2.to_vector.should_equal [7.3, 3.0, 3.0, 2.2, Nothing, Nothing]

            r_3 = c.sort order=Sort_Order.Descending missing_last=False
            r_3.to_vector.should_equal [Nothing, Nothing, 7.3, 3.0, 3.0, 2.2]

    Test.group prefix+"Index" pending=pending <|
        t0 = connection.upload_table "Tix" <|
            Materialized_Table.new [["ix", [1,2,3]], ["c1", [4,5,6]]]
        t = t0.set_index 'ix'
        Test.specify "should be accessible by `at` like other columns" <|
            t.at 'ix' . to_vector . should_equal t.index.to_vector
        Test.specify "should be accessible by `select` like other columns" <|
            t.select ['ix'] . columns . first . to_vector . should_equal t.index.to_vector
        Test.specify "treated as a column indexed by itself should still correctly compute values" <|
            col = t.index+10
            vec = [11, 12, 13]
            col.to_vector . should_equal vec
            df_col = col.to_dataframe
            df_col.to_vector . should_equal vec
            df_col.index.to_vector . should_equal [1, 2, 3]

    Test.group prefix+"Aggregation" pending=pending <|
        builders = [Vector.new_builder,Vector.new_builder,Vector.new_builder]
        insert v =
            builders.zip v .append
        insert ["foo",  0.4,     50]
        insert ["foo",  0.2,     10]
        insert ["foo",  0.4,     30]
        insert ["bar",  3.5,     20]
        insert ["foo",  Nothing, 20]
        insert ["baz",  6.7,     40]
        insert ["foo",  Nothing, 10]
        insert ["bar",  97,      60]
        insert ["quux", Nothing, 70]
        insert ["zzzz", Nothing, Nothing]
        insert ["zzzz", 1, 1]
        insert ["zzzz", 0, 0]
        insert ["zzzz", 0, 1]
        insert ["zzzz", 1, 0]
        insert ["zzzz", 0, 0]
        insert ["zzzz", Nothing, Nothing]
        t = connection.upload_table "T9" <|
            Materialized_Table.new [["name", builders.at 0 . to_vector], ["price", builders.at 1 . to_vector], ["quantity", builders.at 2 . to_vector]]

        ## A helper which makes sure that the groups in a materialized
           (InMemory) table are ordered according to a specified column or list
           of columns.
        determinize_by order_column table =
            table.sort by=order_column

        Test.specify "should allow counting group sizes and elements" <|
            aggregates = [Count Nothing, Count_Not_Nothing "price", Count_Nothing "price"]

            t1 = determinize_by "name" (t.aggregate ([Group_By "name"] + aggregates) . to_dataframe)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            t1.at  "Count" . to_vector . should_equal [2, 1, 5, 1, 7]
            t1.at  "Count Not Nothing price" . to_vector . should_equal [2, 1, 3, 0, 5]
            t1.at  "Count Nothing price" . to_vector . should_equal [0, 0, 2, 1, 2]

            t2 = t.aggregate aggregates . to_dataframe
            t2.at  "Count" . to_vector . should_equal [16]
            t2.at  "Count Not Nothing price" . to_vector . should_equal [11]
            t2.at  "Count Nothing price" . to_vector . should_equal [5]

        Test.specify "should allow to count distinct values" <|
            aggregates = [Count_Distinct "quantity", Count_Distinct "price" (ignore_nothing=True), Count_Distinct "price" (ignore_nothing=False)]

            t1 = determinize_by "name" (t.aggregate [Group_By "name"]+aggregates . to_dataframe)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            # t1.at  "Count Distinct quantity" . to_vector . should_equal [2, 1, 3, 0]
            # TODO

            t2 = t.aggregate aggregates . to_dataframe
            t2 . at "Count Distinct quantity" . to_vector . should_equal [10]
            t2 . at "Count Distinct price" . to_vector . should_equal [7]
            #t2 . at "Count Distinct price 2" . to_vector . should_equal [8]

        Test.specify "should allow to count distinct values over multiple fields" pending="TODO" <|
            aggregates = [Count_Distinct ["price", "quantity"]]

            t1 = determinize_by "name" (t.aggregate [Group_By "name"]+aggregates . to_dataframe)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            # t1.at  "Count Distinct quantity" . to_vector . should_equal [2, 1, 3, 0]
            # TODO

            t2 = t.aggregate aggregates . to_dataframe
            t2 . at "Count Distinct price quantity" . to_vector . should_equal [13]

        Test.specify "should allow simple arithmetic aggregations" <|
            aggregates = [Sum "price" Nothing, Sum "quantity" Nothing, Average "price" Nothing]
            ## TODO can check the datatypes

            t1 = determinize_by "name" (t.aggregate ([Group_By "name" Nothing] + aggregates) . to_dataframe)
            t1.at  "name" . to_vector . should_equal ["bar", "baz", "foo", "quux", "zzzz"]
            t1.at  "Sum price" . to_vector . should_equal [100.5, 6.7, 1, Nothing, 2]
            t1.at  "Sum quantity" . to_vector . should_equal [80, 40, 120, 70, 2]
            t1.at  "Average price" . to_vector . should_equal [50.25, 6.7, (1/3), Nothing, (2/5)]

            t2 = t.aggregate aggregates . to_dataframe
            t2.at  "Sum price" . to_vector . should_equal [110.2]
            t2.at  "Sum quantity" . to_vector . should_equal [312]
            t2.at  "Average price" . to_vector . should_equal [(110.2 / 11)]


    tables = ["T1", "T2", "T3", "T4", "T5", "T6", "T7", "T8", "TA", "TB", "T9", "Big", "clothes", "M_TA", "M_TB", "M_TC", "Tix"]
    tables.each clean_table
