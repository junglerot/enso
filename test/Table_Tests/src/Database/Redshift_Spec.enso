from Standard.Base import all
import Standard.Base.System.Environment
import Standard.Base.Runtime.Ref

from Standard.Database import all
from Standard.Database.Connection.Connection import Sql_Error
import Standard.Test
import Standard.Table as Materialized_Table
import project.Database.Common_Spec
import project.Database.Helpers.Name_Generator
import project.Common_Table_Spec
import project.Aggregate_Spec

redshift_specific_spec connection pending =
    Test.group "[Redshift] Info" pending=pending <|
        tinfo = Name_Generator.random_name "Tinfo"
        connection.execute_update 'CREATE TEMPORARY TABLE "'+tinfo+'" ("strs" VARCHAR, "ints" INTEGER, "bools" BOOLEAN, "reals" REAL)'
        t = connection.access_table tinfo
        t.insert ["a", Nothing, False, 1.2]
        t.insert ["abc", Nothing, Nothing, 1.3]
        t.insert ["def", 42, True, 1.4]
        Test.specify "should return Table information" <|
            i = t.info
            i.index . to_vector . should_equal ["strs", "ints", "bools", "reals"]
            i.at "Items Count" . to_vector . should_equal [3, 1, 2, 3]
            i.at "SQL Type" . to_vector . should_equal ["varchar", "int4", "bool", "float4"]
        Test.specify "should infer standard types correctly" <|
            t.at "strs" . sql_type . is_definitely_text . should_be_true
            t.at "ints" . sql_type . is_definitely_integer . should_be_true
            t.at "bools" . sql_type . is_definitely_boolean . should_be_true
            t.at "reals" . sql_type . is_definitely_double . should_be_true
        connection.execute_update 'DROP TABLE "'+tinfo+'"'

run_tests connection pending=Nothing =
    prefix = "[Redshift] "
    name_counter = Ref.new 0
    tables = Vector.new_builder
    table_builder columns =
        ix = name_counter.get
        name_counter . put ix+1
        name = Name_Generator.random_name "table_"+ix.to_text

        in_mem_table = Materialized_Table.new columns
        case connection.upload_table name in_mem_table of
            table ->
                tables.append name
                table
    clean_tables table_names =
        table_names.each name->
            sql = 'DROP TABLE "' + name + '"'
            Panic.rethrow <| connection.execute_update sql

    Common_Spec.spec prefix connection pending=pending
    here.redshift_specific_spec connection pending=pending
    Common_Table_Spec.spec prefix table_builder supports_case_sensitive_columns=True pending=pending

    selection = Aggregate_Spec.Test_Selection text_concat=False text_shortest_longest=False first_last=False first_last_row_order=False multi_distinct=False aggregation_problems=False
    agg_in_memory_table = (Enso_Project.data / "data.csv") . read
    agg_table = connection.upload_table (Name_Generator.random_name "Agg1") agg_in_memory_table
    tables.append agg_table.name
    empty_agg_table = connection.upload_table (Name_Generator.random_name "Agg_Empty") (agg_in_memory_table.take_start 0)
    tables.append empty_agg_table.name
    materialize = .to_dataframe
    Aggregate_Spec.aggregate_spec prefix agg_table empty_agg_table table_builder materialize is_database=True selection pending=pending

    clean_tables tables.to_vector

spec =
    credentials = Enso_Project.data / 'redshift_credentials.json'
    case credentials.exists of
        True ->
            creds = Json.parse credentials.read_text . unwrap
            access_key = ['AccessKeyID', creds.get 'access_key_id']
            secret_key = ['SecretAccessKey', creds.get 'secret_access_key']
            uri = creds.get 'db_uri'
            user = creds.get 'db_user'
            props = [access_key, secret_key]
            connection = Database.connect uri user=user custom_properties=props
            here.run_tests connection
        False ->
            msg = """
                Redshift connection is not set up. Please create a JSON file containing
                the credentials in `data/redshift_credentials.json`
            connection = Error.throw msg
            here.run_tests connection pending=msg
