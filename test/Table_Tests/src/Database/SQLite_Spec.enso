from Standard.Base import all
import Standard.Base.Runtime.Ref.Ref
import Standard.Base.Errors.File_Error.File_Error

import Standard.Table.Data.Type.Value_Type.Bits
from Standard.Table import Table, Value_Type

from Standard.Database import all
from Standard.Database.Errors import SQL_Error

from Standard.Test import Test, Test_Suite
import Standard.Test.Extensions

import project.Database.Common.Common_Spec
import project.Database.Transaction_Spec
import project.Database.Upload_Spec
import project.Database.Types.SQLite_Type_Mapping_Spec
import project.Database.Helpers.Name_Generator
import project.Common_Table_Operations

sqlite_specific_spec prefix connection setup =
    table_builder = setup.table_builder

    Test.group prefix+"Schemas and Databases" <|
        Test.specify "should be able to get current database and list databases" <|
            connection.database . should_equal Nothing
            connection.databases . should_equal [Nothing]
            Meta.is_same_object connection (connection.set_database Nothing) . should_be_true

        Test.specify "should be able to get current schema and list schemas" <|
            connection.schema . should_equal Nothing
            connection.schemas . should_equal [Nothing]
            Meta.is_same_object connection (connection.set_schema Nothing) . should_be_true

        Test.specify "does not allow changing schema or database" <|
            connection.set_schema "foo" . should_fail_with SQL_Error
            connection.set_database "foo" . should_fail_with SQL_Error

    Test.group prefix+"Tables and Table Types" <|
        tinfo = Name_Generator.random_name "TestTable"
        connection.execute_update 'CREATE TABLE "'+tinfo+'" ("A" VARCHAR)'

        vinfo = Name_Generator.random_name "TestView"
        connection.execute_update 'CREATE VIEW "'+vinfo+'" AS SELECT "A" FROM "'+tinfo+'";'

        temporary_table = Name_Generator.random_name "TemporaryTable"
        (Table.new [["X", [1, 2, 3]]]).select_into_database_table connection temporary_table temporary=True

        Test.specify "should be able to list table types" <|
            table_types = connection.table_types
            table_types.length . should_not_equal 0
            table_types.contains "TABLE" . should_be_true
            table_types.contains "VIEW" . should_be_true

        Test.specify "should be able to list tables" <|
            tables = connection.tables
            tables.row_count . should_not_equal 0
            tables.columns.map .name . should_equal ["Database", "Schema", "Name", "Type", "Description"]

            table_names = tables.at "Name" . to_vector
            table_names.should_contain tinfo
            table_names.should_contain vinfo
            table_names.should_contain temporary_table

        Test.specify "should be able to filter tables by name" <|
            tables = connection.tables tinfo
            tables.row_count . should_equal 1
            tables.at "Database" . to_vector . at 0 . should_equal Nothing
            tables.at "Schema" . to_vector . at 0 . should_equal Nothing
            tables.at "Name" . to_vector . at 0 . should_equal tinfo
            tables.at "Type" . to_vector . at 0 . should_equal "TABLE"

            connection.tables "TestT_ble%" . row_count . should_equal 1
            connection.tables "Temporary%ble%" . row_count . should_equal 1
            connection.tables "Temporary%ble%" . at "Type" . to_vector . should_equal ["GLOBAL TEMPORARY"]
            connection.tables "N_nexistent%" . row_count . should_equal 0

        Test.specify "should be able to filter tables by type" <|
            tables = connection.tables types=["VIEW"]
            tables.row_count . should_not_equal 0
            tables.at "Name" . to_vector . contains tinfo . should_be_false
            tables.at "Name" . to_vector . contains vinfo . should_be_true

    Test.group prefix+"Error Handling" <|
        Test.specify "should wrap errors" <|
            connection.read (SQL_Query.Raw_SQL "foobar") . should_fail_with SQL_Error
            connection.execute_update "foobar" . should_fail_with SQL_Error

            action = connection.read (SQL_Query.Raw_SQL "SELECT A FROM undefined_table")
            action . should_fail_with SQL_Error
            action.catch.to_text . should_equal "There was an SQL error: [SQLITE_ERROR] SQL error or missing database (no such table: undefined_table). [Query was: SELECT A FROM undefined_table]"

    tinfo = Name_Generator.random_name "Tinfo"
    connection.execute_update 'CREATE TABLE "'+tinfo+'" ("strs" VARCHAR, "ints" INTEGER, "bools" BOOLEAN, "reals" REAL)'
    Test.group prefix+"Metadata" <|
        t = connection.query (SQL_Query.Table_Name tinfo)
        row1 = ["a", Nothing, False, 1.2]
        row2 = ["abc", Nothing, Nothing, 1.3]
        row3 = ["def", 42, True, 1.4]
        Panic.rethrow <|
            (Table.from_rows ["strs", "ints", "bools", "reals"] [row1, row2, row3]).update_database_table t update_action=Update_Action.Insert

        Test.specify "should return Table information" <|
            i = t.info
            i.at "Column" . to_vector . should_equal ["strs", "ints", "bools", "reals"]
            i.at "Items Count" . to_vector . should_equal [3, 1, 2, 3]
            i.at "Value Type" . to_vector . should_equal [Value_Type.Char, Value_Type.Integer, Value_Type.Boolean, Value_Type.Float]
        Test.specify "should infer standard types correctly" <|
            t.at "strs" . value_type . is_text . should_be_true
            t.at "ints" . value_type . is_integer . should_be_true
            t.at "bools" . value_type . is_boolean . should_be_true
            t.at "reals" . value_type . is_floating_point . should_be_true

            t.at "ints" . value_type . is_text . should_be_false
            t.at "strs" . value_type . is_integer . should_be_false
            t.at "reals" . value_type . is_boolean . should_be_false
            t.at "bools" . value_type . is_floating_point . should_be_false

    Test.group prefix+"Dialect-specific codegen" <|
        Test.specify "should generate queries for the Distinct operation" <|
            t = connection.query (SQL_Query.Table_Name tinfo)
            code_template = 'SELECT "{Tinfo}"."strs" AS "strs", "{Tinfo}"."ints" AS "ints", "{Tinfo}"."bools" AS "bools", "{Tinfo}"."reals" AS "reals" FROM (SELECT "{Tinfo}_inner"."strs" AS "strs", "{Tinfo}_inner"."ints" AS "ints", "{Tinfo}_inner"."bools" AS "bools", "{Tinfo}_inner"."reals" AS "reals" FROM (SELECT "{Tinfo}"."strs" AS "strs", "{Tinfo}"."ints" AS "ints", "{Tinfo}"."bools" AS "bools", "{Tinfo}"."reals" AS "reals" FROM "{Tinfo}" AS "{Tinfo}") AS "{Tinfo}_inner" GROUP BY "{Tinfo}_inner"."strs") AS "{Tinfo}"'
            expected_code = code_template.replace "{Tinfo}" tinfo
            t.distinct ["strs"] . to_sql . prepare . should_equal [expected_code, []]

    Test.group prefix+"math functions" <|
        Test.specify "round, trunc, ceil, floor" <|
            col = table_builder [["x", [0.1, 0.9, 3.1, 3.9, -0.1, -0.9, -3.1, -3.9]]] . at "x"

            col . cast Value_Type.Float . round . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . round . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Decimal . round . value_type . should_equal Value_Type.Float

            col . cast Value_Type.Float . round 1 . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . round 1 . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Decimal . round 1 . value_type . should_equal Value_Type.Float

            col . cast Value_Type.Float . round use_bankers=True . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . round use_bankers=True . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Decimal . round use_bankers=True . value_type . should_equal Value_Type.Float

            col . cast Value_Type.Float . ceil . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . ceil . value_type . should_equal Value_Type.Integer
            col . cast Value_Type.Decimal . ceil . value_type . should_equal Value_Type.Float

            col . cast Value_Type.Float . floor . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . floor . value_type . should_equal Value_Type.Integer
            col . cast Value_Type.Decimal . floor . value_type . should_equal Value_Type.Float

            col . cast Value_Type.Float . truncate . value_type . should_equal Value_Type.Float
            col . cast Value_Type.Integer . truncate . value_type . should_equal Value_Type.Integer
            col . cast Value_Type.Decimal . truncate . value_type . should_equal Value_Type.Float

        do_op n op =
            table = table_builder [["x", [n]]]
            result = table.at "x" |> op
            result.to_vector.at 0
        do_round n dp=0 use_bankers=False = do_op n (_.round dp use_bankers)

        Test.specify "Can round correctly near the precision limit" <|
            # This value varies depending on the version of SQLite.
            do_round 1.2222222222222225 15 . should_equal 1.222222222222223 0.000000000000002
            do_round -1.2222222222222225 15 . should_equal -1.222222222222223 0.000000000000002
            do_round 1.2222222222222235 15 . should_equal 1.222222222222223
            do_round -1.2222222222222235 15 . should_equal -1.222222222222223

        Test.specify "Can round correctly near the precision limit, using banker's rounding" <|
            do_round 1.2222222222222225 15 use_bankers=True . should_equal 1.222222222222222
            do_round -1.2222222222222225 15 use_bankers=True . should_equal -1.222222222222222
            do_round 1.2222222222222235 15 use_bankers=True . should_equal 1.222222222222224
            do_round -1.2222222222222235 15 use_bankers=True . should_equal -1.222222222222224

        Test.specify "Can handle NaN/Infinity" <|
            nan_result = if setup.test_selection.is_nan_and_nothing_distinct then Number.nan else Nothing
            ops = [.round, .truncate, .ceil, .floor]
            ops.each op->
                do_op Number.nan op . should_equal nan_result
                do_op Number.positive_infinity op . should_equal Number.positive_infinity
                do_op Number.negative_infinity op . should_equal Number.negative_infinity

        Test.specify "round returns the correct type" <|
            do_round 231.2 1 . should_be_a Decimal
            do_round 231.2 0 . should_be_a Decimal
            do_round 231.2 . should_be_a Decimal
            do_round 231.2 -1 . should_be_a Decimal

        Test.specify "round returns the correct type" <|
            do_round 231 1 . should_be_a Decimal
            do_round 231 0 . should_be_a Decimal
            do_round 231 . should_be_a Decimal
            do_round 231 -1 . should_be_a Decimal

sqlite_spec connection prefix =
    name_counter = Ref.new 0
    table_builder columns =
        ix = name_counter.get
        name_counter . put ix+1
        name = Name_Generator.random_name "table_"+ix.to_text

        in_mem_table = Table.new columns
        in_mem_table.select_into_database_table connection name primary_key=Nothing
    materialize = .read

    Common_Spec.spec prefix connection

    common_selection = Common_Table_Operations.Main.Test_Selection.Config supports_case_sensitive_columns=False order_by=True natural_ordering=False case_insensitive_ordering=True case_insensitive_ascii_only=True take_drop=False is_nan_and_nothing_distinct=False date_time=False

    ## For now `advanced_stats`, `first_last`, `text_shortest_longest` and
       `multi_distinct` remain disabled, because SQLite does not provide the
       needed aggregate functions and emulating them is highly problematic.
       We can rethink in the future how these could be emulated. Two of the
       possible solutions are:
       - creating complex nested queries using NTILE to compute the stats,
       - compiling SQLite library on our own and adding native extensions for
         the missing statistics.
    aggregate_selection = Common_Table_Operations.Aggregate_Spec.Test_Selection.Config advanced_stats=False text_shortest_longest=False first_last=False first_last_row_order=False multi_distinct=False aggregation_problems=False nan=False date_support=False
    agg_in_memory_table = (enso_project.data / "data.csv") . read
    agg_table = agg_in_memory_table.select_into_database_table connection (Name_Generator.random_name "Agg1") primary_key=Nothing temporary=True
    empty_agg_table = (agg_in_memory_table.take (First 0)).select_into_database_table connection (Name_Generator.random_name "Agg_Empty") primary_key=Nothing temporary=True

    setup = Common_Table_Operations.Main.Test_Setup.Config prefix agg_table empty_agg_table table_builder materialize is_database=True test_selection=common_selection aggregate_test_selection=aggregate_selection connection=connection
    sqlite_specific_spec prefix connection setup
    Common_Table_Operations.Main.spec setup

    connection.close

spec =
    enso_project.data.create_directory
    file = enso_project.data / "transient" / "sqlite_test.db"
    file.delete_if_exists
    in_file_prefix = "[SQLite File] "
    sqlite_spec (Database.connect (SQLite file)) in_file_prefix
    Transaction_Spec.spec (Database.connect (SQLite file)) in_file_prefix
    Upload_Spec.spec (_ -> Database.connect (SQLite file)) in_file_prefix
    file.delete

    in_memory_prefix = "[SQLite In-Memory] "
    sqlite_spec (Database.connect (SQLite In_Memory)) in_memory_prefix
    Transaction_Spec.spec (Database.connect (SQLite In_Memory)) in_memory_prefix
    Upload_Spec.spec (_ -> Database.connect (SQLite In_Memory)) in_memory_prefix persistent_connector=False

    SQLite_Type_Mapping_Spec.spec

    Test.group "SQLite_Format should allow connecting to SQLite files" <|
        file.delete_if_exists

        connection = Database.connect (SQLite file)
        connection.execute_update 'CREATE TABLE "Dummy" ("strs" VARCHAR, "ints" INTEGER, "bools" BOOLEAN, "reals" REAL)'
        connection.close

        Test.specify "should recognise a SQLite database file" <|
            Auto_Detect.get_reading_format file . should_be_a SQLite_Format

        Test.specify "should recognise a sqlite file by extension for writing" <|
            Auto_Detect.get_writing_format (enso_project.data / "nonexistent-data.db") . should_be_a SQLite_Format
            Auto_Detect.get_writing_format (enso_project.data / "nonexistent-data.sqlite") . should_be_a SQLite_Format

        Test.specify "should not recognise nonexistent or empty files for reading" <|
            r1 = Data.read (enso_project.data / "nonexistent-data.db")
            r1.should_fail_with File_Error
            r1.catch . should_be_a File_Error.Not_Found

            empty = enso_project.data / "transient" / "empty-data.db"
            "".write empty on_existing_file=Existing_File_Behavior.Overwrite . should_succeed
            r2 = Data.read empty
            r2.should_fail_with File_Error
            r2.catch . should_be_a File_Error.Unsupported_Type
            empty.delete_if_exists

            broken = enso_project.data / "transient" / "empty-data.db"
            "SOME_RANDOM_DATA".write empty on_existing_file=Existing_File_Behavior.Overwrite . should_succeed
            r3 = Data.read broken
            r3.should_fail_with File_Error
            r3.catch . should_be_a File_Error.Unsupported_Type
            broken.delete_if_exists

        Test.specify "should connect to a db file" <|
            connection = Data.read file
            tables = connection.tables
            tables.row_count . should_not_equal 0
            connection.close

        file.delete_if_exists

        Test.specify 'should not duplicate warnings' <|
            c = Database.connect (SQLite In_Memory)
            t0 = Table.new [["X", ["a", "bc", "def"]]]
            t1 = t0.select_into_database_table c "Tabela"
            t2 = t1.cast "X" (Value_Type.Char size=1)
            Warning.get_all t2 . length . should_equal 1

main = Test_Suite.run_main spec
