from Standard.Base import all

import Standard.Database.Data.Internal.Helpers
import Standard.Database.Data.Internal.Aggregate_Helper
import Standard.Database.Data.Internal.IR
import Standard.Database.Data.Sql
import Standard.Table.Data.Column as Materialized_Column
import Standard.Table.Data.Table as Materialized_Table
import Standard.Table.Internal.Java_Exports
import Standard.Table.Internal.Table_Helpers
import Standard.Table.Internal.Problem_Builder
import Standard.Table.IO.File_Format
import Standard.Base.System.File.Existing_File_Behavior

import Standard.Table.Data.Aggregate_Column
import Standard.Table.Internal.Aggregate_Column_Helper
from Standard.Database.Data.Column as Column_Module import Column, Aggregate_Column_Builder
from Standard.Database.Data.Internal.IR import Internal_Column
from Standard.Table.Data.Table import No_Such_Column_Error
from Standard.Table.Data.Column_Selector as Column_Selector_Module import Column_Selector, By_Index
from Standard.Base.Data.Text.Text_Ordering as Text_Ordering_Module import Text_Ordering
from Standard.Table.Data.Data_Formatter as Data_Formatter_Module import Data_Formatter
from Standard.Base.Error.Problem_Behavior as Problem_Behavior_Module import Problem_Behavior, Report_Warning
from Standard.Database.Error as Database_Errors import Unsupported_Database_Operation_Error
import Standard.Table.Data.Column_Name_Mapping
import Standard.Table.Data.Position
import Standard.Table.Data.Sort_Column_Selector
import Standard.Table.Data.Sort_Column
import Standard.Table.Data.Match_Columns

polyglot java import java.sql.JDBCType

## Represents a column-oriented table data structure backed by a database.
type Table

    ## PRIVATE

       Represents a column-oriented table data structure backed by a database.

       Arguments:
       - name: The name of the table.
       - connection: The connection with which the table is associated.
       - internal_columns: The internal representation of the table columns.
       - context: The context associated with this table.
    # type Table (name : Text) (connection : Connection)
    #            (internal_columns : Vector Internal_Column)
    #            (context : IR.Context)
    type Table name connection internal_columns context

    ## UNSTABLE

       Returns a text containing an ASCII-art table displaying this data.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
         - format_terminal: whether ANSI-terminal formatting should be used
    display : Integer -> Boolean -> Text
    display self show_rows=10 format_terminal=False =
        df = self.reset_index.to_dataframe max_rows=show_rows
        indices_count = self.context.meta_index.length
        all_rows_count = self.row_count
        display_dataframe df indices_count all_rows_count format_terminal

    ## UNSTABLE

       Prints an ASCII-art table with this data to the standard output.

       Arguments:
         - show_rows: the number of initial rows that should be displayed.
    print : Integer -> Nothing
    print self show_rows=10 =
        IO.println (self.display show_rows format_terminal=True)
        IO.println ''

    ## UNSTABLE

       Converts this table into a JSON structure.
    to_json : Json
    to_json self = case self.internal_columns.is_empty of
        True ->
            Json.from_pairs [["query", Nothing], ["message", "The table has no columns so a query cannot be generated."]]
        False -> self.to_sql.to_json

    ## UNSTABLE

       Returns the column with the given name.

       Arguments:
       - name: The name of the column to get.
    at : Text -> Column ! No_Such_Column_Error
    at self name =
        candidates = self.internal_columns + self.context.meta_index
        internal = candidates.find (p -> p.name == name)
        self.make_column internal . map_error (_ -> No_Such_Column_Error name)

    ## Returns a new table with a chosen subset of columns, as specified by the
       `columns`, from the input table. Any unmatched input columns will be
       dropped from the output.

       Arguments:
       - columns: Column selection criteria.
       - reorder: By default, or if set to `False`, columns in the output will
         be in the same order as in the input table. If `True`, the order in the
         output table will match the order in the columns list.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If a column in columns is not in the input table, a
           `Missing_Input_Columns`.
         - If duplicate columns, names or indices are provided, a
           `Duplicate_Column_Selectors`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If two distinct indices would refer to the same column, a
           `Input_Indices_Already_Matched`, indicating that the additional
           indices will not introduce additional columns.
         - If there are no columns in the output table, a `No_Output_Columns`.

       > Example
         Select columns by name.

             table.select_columns (By_Name ["bar", "foo"])

       ## TODO [RW] default arguments do not work on atoms, once this is fixed,
          the above should be replaced with just `By_Name`.
          See: https://github.com/enso-org/enso/issues/1600


       > Example
         Select columns matching a regular expression.

             table.select_columns (By_Name ["foo.+", "b.*"] (Regex_Matcher case_sensitive=Case_Insensitive))

       > Example
         Select the first two columns and the last column, moving the last one to front.

             table.select_columns (By_Index [-1, 0, 1]) reorder=True

       > Example
         Select columns with the same names as the ones provided.

             table.select_columns (By_Column [column1, column2])
    select_columns : Column_Selector -> Boolean -> Problem_Behavior -> Table
    select_columns self (columns = By_Index [0]) (reorder = False) (on_problems = Report_Warning) =
        new_columns = Table_Helpers.select_columns internal_columns=self.internal_columns selector=columns reorder=reorder on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the chosen set of columns, as specified by the
       `columns`, removed from the input table. Any unmatched input columns will
       be kept in the output. Columns are returned in the same order as in the
       input.

       Arguments:
       - columns: Criteria specifying which columns should be removed.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If a column in columns is not in the input table, a
           `Missing_Input_Columns`.
         - If duplicate columns, names or indices are provided, a
           `Duplicate_Column_Selectors`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If two distinct indices would refer to the same column, a
           `Input_Indices_Already_Matched`, indicating that the additional
           indices will not introduce additional columns.
         - If there are no columns in the output table, a `No_Output_Columns`.

       > Example
         Remove columns with given names.

             table.remove_columns (By_Name ["bar", "foo"])

       ## TODO [RW] default arguments do not work on atoms, once this is fixed,
          the above should be replaced with just `By_Name`.
          See: https://github.com/enso-org/enso/issues/1600

       > Example
         Remove columns matching a regular expression.

             table.remove_columns (By_Name ["foo.+", "b.*"] (Regex_Matcher case_sensitive=Case_Insensitive))

       > Example
         Remove the first two columns and the last column.

             table.remove_columns (By_Index [-1, 0, 1])

       > Example
         Remove columns with the same names as the ones provided.

             table.remove_columns (By_Column [column1, column2])
    remove_columns : Column_Selector -> Problem_Behavior -> Table
    remove_columns self (columns = By_Index [0]) (on_problems = Report_Warning) =
        new_columns = Table_Helpers.remove_columns internal_columns=self.internal_columns selector=columns on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the specified selection of columns moved to
       either the start or the end in the specified order.

       Arguments:
       - columns: Criteria specifying which columns should be reordered and
         specifying their order.
       - position: Specifies how to place the selected columns in relation to
         the remaining columns which were not matched by `columns` (if any).
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If a column in columns is not in the input table, a
           `Missing_Input_Columns`.
         - If duplicate columns, names or indices are provided, a
           `Duplicate_Column_Selectors`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If two distinct indices would refer to the same column, a
           `Input_Indices_Already_Matched`, indicating that the additional
           indices will not introduce additional columns.

       > Example
         Move a column with a specified name to back.

             table.reorder_columns (By_Name ["foo"]) position=After_Other_Columns

       ## TODO [RW] default arguments do not work on atoms, once this is fixed,
          the above should be replaced with just `By_Name`.
          See: https://github.com/enso-org/enso/issues/1600

       > Example
         Move columns matching a regular expression to front, keeping columns matching "foo.+" before columns matching "b.*".

             table.reorder_columns (By_Name ["foo.+", "b.*"] (Regex_Matcher case_sensitive=Case_Insensitive))

       > Example
         Swap the first two columns.

             table.reorder_columns (By_Index [1, 0]) position=Before_Other_Columns

       > Example
         Move the first column to back.

             table.reorder_columns (By_Index [0]) position=After_Other_Columns

       > Example
         Move the columns with names matching the provided columns to the front.

             table.reorder_columns (By_Column [column1, column2])
    reorder_columns : Column_Selector -> Position.Position -> Problem_Behavior -> Table
    reorder_columns self (columns = By_Index [0]) (position = Position.Before_Other_Columns) (on_problems = Report_Warning) =
        new_columns = Table_Helpers.reorder_columns internal_columns=self.internal_columns selector=columns position=position on_problems=on_problems
        self.updated_columns new_columns

    ## Returns a new table with the columns sorted by name according to the
       specified sort method. By default, sorting will be according to
       case-sensitive ascending order based on the `Text.compare_to` operator.

       Arguments:
       - direction: Whether sorting should be in ascending or descending order.
       - text_ordering: The sort methodology to use.

       > Example
         Sort columns according to the default ordering.

             table.sort_columns

       > Example
         Sort columns according to the natural case-insensitive ordering.

             table.sort_columns text_ordering=(Text_Ordering sort_digits_as_numbers=True case_sensitive=Case_Insensitive)

       > Example
         Sort columns in descending order.

             table.reorder_columns Sort_Direction.Descending
    sort_columns : Sort_Direction -> Text_Ordering -> Table
    sort_columns self direction=Sort_Direction.Ascending text_ordering=Text_Ordering =
        new_columns = Table_Helpers.sort_columns internal_columns=self.internal_columns direction text_ordering
        self.updated_columns new_columns

    ## Returns a new table with the columns renamed based on either a mapping
       from the old name to the new or a positional list of new names.

       Arguments:
       - column_map: Mapping from old column names to new.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If a column in columns is not in the input table, a
           `Missing_Input_Columns`.
         - If duplicate columns, names or indices are provided, a
           `Duplicate_Column_Selectors`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If two distinct indices would refer to the same column, a
           `Input_Indices_Already_Matched`, indicating that the additional
           indices will not introduce additional columns.
         - If any of the new names are invalid, an
           `Invalid_Output_Column_Names`.
         - If any of the new names clash either with existing names or each
           other, a Duplicate_Output_Column_Names.

       > Example
    rename_columns : Column_Name_Mapping -> Problem_Behavior -> Table
    rename_columns self (column_map=(Column_Name_Mapping.By_Position ["Column"])) (on_problems=Report_Warning) =
        new_names = Table_Helpers.rename_columns internal_columns=self.internal_columns mapping=column_map on_problems=on_problems
        if new_names.is_error then new_names else
            new_columns = self.internal_columns.map_with_index i->c->(c.rename (new_names.at i))
            self.updated_columns new_columns

    ## PRIVATE

       Resolves the column name to a column within this table.

       Arguments:
       - column: The name (or column handle) for the column you want to resolve.

       If instead of a name, a column is provided, it is returned as-is as long
       as it comes from the same context.
    resolve : Text | Column -> Column
    resolve self column = case column of
        Text -> Panic.rethrow (self.at column)
        _ ->
            if Helpers.check_integrity self column then column else
                Panic.throw (Integrity_Error "Column "+column.name)

    ## UNSTABLE

       Selects only the rows of this table that correspond to `True` values in
       `filter`.

       Arguments:
       - filter: A column of boolean values that will be used to mask the table
         rows.

       This is useful for filtering the rows by given predicate.

       > Example
         Select only the rows of `my_table` where the `"Status"` column has the
         value `"Valid"`
             my_table.where (my_table.at "Status" == "Valid")
    where : Column -> Table
    where self filter =
        case Helpers.check_integrity self filter of
            False ->
                Error.throw (Integrity_Error "Column "+filter.name)
            True ->
                new_filters = self.context.where_filters + [filter.expression]
                new_ctx = self.context.set_where_filters new_filters
                self.updated_context new_ctx

    ## UNSTABLE

       Returns a new Table that will include at most `max_rows` rows from the
       original Table.

       Arguments:
       - max_rows: The maximum number of rows to get from the table.

       Since this Table is backed by an SQL database, the Table returned by the
       `limit` method is deterministic only if the Table has been ordered (using
       the `order_by` method).

       Otherwise, no order is imposed, so the returned Table will include at most
       `max_rows` rows, but there are no guarantees on which rows will be
       selected. Moreover, even if the underlying table in the database did not
       change, different sets of rows may be returned each time the returned
       Table is materialized.

       The limit is applied at the very end, so the new Table behaves exactly as
       the old one, just limiting its results when being materialized.
       Specifically, applying further filters will still apply to the whole
       result set and the limit will be taken after applying these filters.

       > For example:
         In the call below, assuming that the table of `t1` contains rows for
         numbers 1, 2, ..., 10, will return rows starting from 6 and not an empty
         result as one could expect if the limit was applied before the filters.
             t1 = table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name "A"]) . limit 5
             t2 = t1.where (t1.at 'A' > 5)
             t2.to_dataframe
    limit : Integer -> Table
    limit self max_rows =
        new_ctx = self.context.set_limit max_rows
        self.updated_context new_ctx

    ## UNSTABLE

       Sets the column value at the given name.

       Arguments:
       - name: The name of the column to set.
       - column: The new value for the column called `name`.

       If a column with the given name already exists, it will be replaced.
       Otherwise a new column is added.
    set : Text -> Column -> Table
    set self name column = case Helpers.ensure_name_is_sane name of
        True ->
            is_used_in_index = self.context.meta_index.exists i-> i.name == name
            case is_used_in_index of
                True -> Error.throw <| Illegal_State_Error "Cannot override column "+name+", because it is used as an index. Remove the index or use a different name."
                False ->
                    new_col = Internal_Column name column.sql_type column.expression
                    replace = self.internal_columns.exists (c -> c.name == name)
                    case replace of
                        True ->
                            new_cols = self.internal_columns.map (c -> if c.name == name then new_col else c)
                            self.updated_columns new_cols
                        False ->
                            self.updated_columns (self.internal_columns + [new_col])

    ## UNSTABLE

       Returns the vector of columns contained in this table.
    columns : Vector Column
    columns self = self.internal_columns . map self.make_column

    ## UNSTABLE

       Sets the index of this table, using the column with the provided name.

       Arguments:
       - index: The column to use as the index of the table.
    set_index : Text | Column | Vector Text -> Table
    set_index self index = Panic.recover Any <|
        new_index = (Helpers.unify_vector_singleton index).map (self.at >> .as_internal)
        new_ctx = self.context.set_index new_index
        new_cols = self.internal_columns.filter col->
            turned_into_index = new_index.exists i-> i.name == col.name
            turned_into_index.not
        self.updated_context new_ctx . updated_columns new_cols

    ## UNSTABLE

       Returns the (possibly empty) list of indices for this table.
    indices : Vector Column
    indices self =
        self.context.meta_index.map self.make_column

    ## UNSTABLE

       Returns the index (or indexes) of this table, as a column (indexed by
       itself).

       Throws `No_Index_Set_Error` if there is no index set.
    index : Column | Vector Column ! Materialized_Table.No_Index_Set_Error
    index self =
        ixes = self.indices
        len = ixes.length
        if len == 0 then Error.throw Materialized_Table.No_Index_Set_Error else
            if len == 1 then ixes.at 0 else ixes

    ## Sorts the rows of the table according to the specified columns and order.

       Arguments:
       - columns: The columns and order to sort the table.
       - text_ordering: The ordering method to use on text values.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default. The following problems can occur:
         - If a column in `columns` is not present in the input table, a
           `Missing_Input_Columns`.
         - If duplicate columns, names or indices are provided, a
           `Duplicate_Column_Selectors`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If two distinct indices refer to the same column, an
           `Input_Indices_Already_Matched`.
         - If two name matchers match the same column, a
           `Column_Matched_By_Multiple_Selectors`.
         - If no valid columns are selected, a `No_Input_Columns_Selected`.
         - If values do not implement an ordering, an
           `Incomparable_Values_Error`.

       Missing (`Nothing`) values are sorted as less than any other object.

       > Example
         Order the table by the column "alpha" in ascending order.

             table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name "alpha"])

       > Example
         Order the table by the second column in ascending order. In case of any
         ties, break them based on the 7th column from the end of the table in
         descending order.

             table.order_by (Sort_Column_Selector.By_Index [Sort_Column.Index 1, Sort_Column.Index -7 Sort_Direction.Descending])
       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`.

             table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name 'Quantity'])

       > Example
         Sorting `table` in descending order by the value in column `'Quantity'`.

             table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name 'Quantity' Sort_Direction.Descending])

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` for breaking ties.

             table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name 'Quantity', Sort_Column.Name 'Rating'])

       > Example
         Sorting `table` in ascending order by the value in column `'Quantity'`,
         using the value in column `'Rating'` in descending order for breaking
         ties.

             table.order_by (Sort_Column_Selector.By_Name [Sort_Column.Name 'Quantity', Sort_Column.Name 'Rating' Sort_Direction.Descending])
    order_by : Sort_Column_Selector -> Text_Ordering -> Problem_Behavior -> Table
    order_by self (columns = (Sort_Column_Selector.By_Name [(Sort_Column.Name (self.columns.at 0 . name))])) text_ordering=Text_Ordering on_problems=Report_Warning = Panic.handle_wrapped_dataflow_error <|
        problem_builder = Problem_Builder.new
        columns_for_ordering = Table_Helpers.prepare_order_by self.columns columns problem_builder
        problem_builder.attach_problems_before on_problems <|
            new_order_descriptors = columns_for_ordering.map selected_column->
                internal_column = selected_column.column
                associated_selector = selected_column.associated_selector
                ## TODO [RW] this is only needed because `Vector.map` does not
                   propagate dataflow errors correctly. See:
                   https://www.pivotaltracker.com/story/show/181057718
                Panic.throw_wrapped_if_error <|
                    self.connection.dialect.prepare_order_descriptor internal_column associated_selector.direction text_ordering
            new_ctx = self.context.add_orders new_order_descriptors
            self.updated_context new_ctx

    ## UNSTABLE

       Efficiently joins two tables based on either the index or a key column.

       Arguments:
       - other: the table being the right operand of this join operation.
       - on: the column(s) or expression(s) of `self` that should be used as
         the join key. If this argument is not provided, the index of `self`
         will be used.
       - drop_unmatched: whether the rows of `self` without corresponding
         matches in `other` should be dropped from the result.
       - left_suffix: a suffix that should be added to the columns of `self`
         when there's a name conflict with a column of `other`.
       - right_suffix: a suffix that should be added to the columns of `other`
         when there's a name conflict with a column of `self`.

       The resulting table contains rows of `self` extended with rows of
       `other` with matching indexes. If the index in `other` is not unique,
       the corresponding rows of `self` will be duplicated in the result.
    join : Table | Column -> Nothing | Text | Column | Vector (Text | Column) -> Boolean -> Text -> Text -> Table
    join self other on=Nothing drop_unmatched=False left_suffix='_left' right_suffix='_right' = case other of
        Column _ _ _ _ _ -> self.join other.to_table on drop_unmatched left_suffix right_suffix
        Table _ _ _ _ -> Panic.recover Any <|
            Panic.rethrow (Helpers.ensure_name_is_sane left_suffix && Helpers.ensure_name_is_sane right_suffix)
            if left_suffix == right_suffix then
                Panic.throw <| Illegal_State_Error "left_suffix must be different from right_suffix"
            kind = if drop_unmatched then IR.Join_Inner else IR.Join_Left

            # Prepare the left and right pairs of indices along which the join will be performed.
            left_join_index : Vector Internal_Column
            left_join_index = case on of
                Nothing -> self.context.meta_index
                _ ->
                    (Helpers.unify_vector_singleton on).map (self.resolve >> .as_internal)
            right_join_index = other.context.meta_index
            if left_join_index.length != right_join_index.length then
                Panic.throw <| Illegal_State_Error "Cannot join with multi-indexes of different lengths."

            # TODO [RW] We may be able to avoid creating subqueries if there are no groups, orders or wheres,
            #  so it may be worth optimizing that here (#1515).
            new_table_name = self.name + "_" + other.name
            aliases = case self.name == other.name of
                True -> [self.name+left_suffix, other.name+right_suffix]
                False -> [self.name, other.name]
            left_alias = aliases.first
            right_alias = aliases.second

            # Ensure that the join indices (which are not directly visible to the user, but must be materialized in the sub-query)
            # get a fresh set of names, so that they do not collide with other parts of the query.
            left_used_names = self.internal_columns_with_index.map .name
            left_join_index_fresh = freshen_columns left_used_names left_join_index

            # Create subqueries that encapsulate the original queries and provide needed columns.
            # We only include the meta_index from the left table, because only this one will be kept in the result.
            # The generated new sets of columns refer to the encapsulated expressions within the subquery and are
            # valid in contexts whose from_spec is this subquery directly or it is a join containing this subquery.
            # TODO [RW] Not all of these included columns are actually usable from the external context, so
            #  in the future we may consider pruning some of them as additional optimization and simplification of the query.
            left_config = self.context.as_subquery left_alias [self.internal_columns, self.context.meta_index, left_join_index_fresh]
            right_config = other.context.as_subquery right_alias [other.internal_columns, right_join_index]

            left_subquery = left_config.first
            left_new_columns = left_config.second.at 0
            left_new_meta_index = left_config.second.at 1
            left_new_join_index = left_config.second.at 2

            right_subquery = right_config.first
            right_new_columns = right_config.second.at 0
            right_new_join_index = right_config.second.at 1

            # Generate new names for all columns (including the indices) that will be retained in the created Table.
            left_names_before = (left_new_meta_index + left_new_columns).map .name
            right_names_before = right_new_columns.map .name
            new_names = combine_names left_names_before right_names_before left_suffix right_suffix
            left_indices_count = left_new_meta_index.length
            left_new_meta_index_names = new_names.first.take_start left_indices_count
            left_new_columns_names = new_names.first.drop_start left_indices_count
            right_new_columns_names = new_names.second

            # Rename columns to the newly allocated names
            new_index = internal_rename_columns left_new_meta_index left_new_meta_index_names
            left_renamed_columns = internal_rename_columns left_new_columns left_new_columns_names
            right_renamed_columns = internal_rename_columns right_new_columns right_new_columns_names
            new_columns = left_renamed_columns + right_renamed_columns

            on_exprs = left_new_join_index.zip right_new_join_index l-> r->
                IR.Operation "=" [l.expression, r.expression]
            new_from = IR.Join kind left_subquery right_subquery on_exprs
            new_limit = Nothing
            new_ctx = IR.Context new_from [] [] [] new_index new_limit

            Table new_table_name self.connection new_columns new_ctx

    ## ALIAS group, summarize

       Aggregates the rows in a table using any `Group_By` entries in columns.
       The columns argument specifies which additional aggregations to perform and to return.

       Arguments:
       - columns: Vector of `Aggregate_Column` specifying the aggregated table.
       - on_problems: Specifies how to handle problems if they occur, reporting
         them as warnings by default.

         The following problems can occur:
         - If a column name is not in the input table, a `Missing_Input_Columns`.
         - If a column index is out of range, a `Column_Indexes_Out_Of_Range`.
         - If there are no valid columns in the output table, a `No_Output_Columns`.
         - If there are invalid column names in the output table, a `Invalid_Output_Column_Names`.
         - If there are duplicate column names in the output table, a `Duplicate_Output_Column_Names`.
         - If grouping on or computing the `Mode` on a floating point number, a `Floating_Point_Grouping`.
         - If an aggregation fails, an `Invalid_Aggregation_Method`.
         - If when concatenating values there is an quoted delimited, an `Unquoted_Delimiter`
         - If there are more than 10 issues with a single column, an `Additional_Warnings`.

       > Example
         Group by the Key column, count the rows

              table.aggregate [Group_By "Key", Count Nothing]
    aggregate : [Aggregate_Column] -> Problem_Behavior -> Table
    aggregate self columns (on_problems=Report_Warning) =
        validated = Aggregate_Column_Helper.prepare_aggregate_columns columns self
        on_problems.attach_problems_before validated.problems <|
            key_columns = validated.key_columns
            resolved_aggregates = validated.valid_columns
            key_expressions = key_columns.map .expression
            new_ctx = self.context.set_groups key_expressions
            results = resolved_aggregates.map p->
                agg = p.second
                new_name = p.first
                Aggregate_Helper.make_aggregate_column self agg new_name . catch
            partitioned = results.partition (_.is_an Internal_Column)
            ## When working on join we may encounter further issues with having
               aggregate columns exposed directly, it may be useful to re-use
               the `lift_aggregate` method to push the aggregates into a
               subquery.
            new_columns = partitioned.first
            problems = partitioned.second
            on_problems.attach_problems_before problems <|
                self.updated_context_and_columns new_ctx new_columns

    ## Parsing values is not supported in database tables, the table has to be
       materialized first with `to_dataframe`.
    parse_values : Data_Formatter -> (Nothing | [Column_Type_Selection]) -> Problem_Behavior -> Table
    parse_values self value_formatter=Data_Formatter column_types=Nothing on_problems=Report_Warning =
        ## Avoid unused arguments warning. We cannot rename arguments to `_`,
           because we need to keep the API consistent with the in-memory table.
        _ = [value_formatter, column_types, on_problems]
        msg = "Parsing values is not supported in database tables, the table has to be materialized first with `to_dataframe`."
        Error.throw (Unsupported_Database_Operation_Error msg)

    ## UNSTABLE

       Returns a new Table without rows that contained missing values in any of
       the columns.
    drop_missing_rows : Table
    drop_missing_rows self =
        filters = self.columns.map (c -> c.is_missing.not.expression)
        new_ctx = self.context.set_where_filters (self.context.where_filters + filters)
        self.updated_context new_ctx

    ## Returns a new Table without columns that contained any missing values.

       This operation needs to actually materialize the underlying query in
       order to know which columns to drop.
    drop_missing_columns : Table
    drop_missing_columns self =
        rows_expr = IR.Operation "COUNT_ROWS" []
        all_rows_column_name = "row_count"
        make_count_expr expr = IR.Operation "COUNT" [expr]
        cols = self.internal_columns.map (c -> [c.name, make_count_expr c.expression])
        query = IR.Select [[all_rows_column_name, rows_expr]]+cols self.context
        sql = self.connection.dialect.generate_sql query
        table = self.connection.execute_query sql
        all_rows = table.at all_rows_column_name . at 0
        kept_columns = self.internal_columns . filter c->
            all_rows == table.at c.name . at 0
        self.updated_columns kept_columns

    ## Returns the amount of rows in this table.
    row_count : Integer
    row_count self = if self.internal_columns.is_empty then 0 else
        expr = IR.Operation "COUNT_ROWS" []
        column_name = "row_count"
        ## We need to keep some column in the subquery which will determine if
           the query is performing regular selection or aggregation. To avoid
           computing too much we do not pass all the columns but only the first
           one.
        setup = self.context.as_subquery self.name [[self.internal_columns.first]]
        new_ctx = IR.subquery_as_ctx setup.first
        query = IR.Select [[column_name, expr]] new_ctx
        sql = self.connection.dialect.generate_sql query
        table = self.connection.execute_query sql
        table.at column_name . at 0

    ## UNSTABLE

       Returns a materialized dataframe containing rows of this table.

       Arguments:
       - max_rows: specifies a maximum amount of rows to fetch; if not set, all
         available rows are fetched.
    to_dataframe : (Integer | Nothing) -> Materialized_Table.Table
    to_dataframe self max_rows=Nothing =
        case self.context.meta_index.length > 1 of
            True -> Error.throw <| Illegal_State_Error "Multi-indexes are not implemented in the dataframes, if you want to materialize such a Table, remove the index first using `set_index`."
            False ->
                preprocessed = self.reset_index.limit max_rows
                case preprocessed.internal_columns.is_empty of
                    True ->
                        internal_table = Java_Exports.make_table_without_columns self.row_count
                        Materialized_Table.Table internal_table
                    False ->
                        sql = preprocessed.to_sql
                        expected_types = preprocessed.internal_columns.map .sql_type
                        table = self.connection.execute_query sql expected_types
                        case self.context.meta_index.length == 1 of
                            False -> table
                            True ->
                                ix_col_name = table.columns.first.name
                                table.set_index ix_col_name

    ## PRIVATE

       Brings the index back as columns.
    reset_index : Table
    reset_index self =
        new_cols = self.internal_columns_with_index
        new_ctx = self.context.set_index []
        self.updated_context new_ctx . updated_columns new_cols

    ## UNSTABLE

       Returns an SQL statement that will be used for materializing this table.
    to_sql : Sql.Statement
    to_sql self =
        cols = self.internal_columns.map (c -> [c.name, c.expression])
        case cols.is_empty of
            True -> Error.throw <| Unsupported_Database_Operation_Error "Cannot generate SQL for a table with no columns."
            False ->
                query = IR.Select cols self.context
                self.connection.dialect.generate_sql query

    ## Returns a Table describing this table's contents.

       The table lists all columns, counts of non-null items and storage types
       of each column.
    info : Table
    info self =
        cols = self.internal_columns
        count_query =
            ## Performing a subquery is the most robust way to handle both
               regular columns and aggregates.
               Naively wrapping each column in a `COUNT(...)` will not
               always work as aggregates cannot be nested.
            setup = self.context.as_subquery self.name [self.internal_columns]
            new_ctx = IR.subquery_as_ctx setup.first
            new_columns = setup.second.first.map column->
                [column.name, IR.Operation "COUNT" [column.expression]]
            query = IR.Select new_columns new_ctx
            self.connection.dialect.generate_sql query
        count_table = self.connection.execute_query count_query
        counts = if cols.is_empty then [] else count_table.columns.map c-> c.at 0
        types = cols.map c-> c.sql_type.name
        Materialized_Table.new [["Column", cols.map .name], ["Items Count", counts], ["SQL Type", types]] . set_index "Column"

    ## PRIVATE

       Helper to create columns from internal columns.

       Arguments:
       - internal: The internal column to use for creating a column.
    make_column : Internal_Column -> Column
    make_column self internal =
        # TODO [RW] Many places assume that index names are distinct from column names, so when creating a column from
        # index we need to ensure that the names do not collide. In the future we may consider trying to get rid of
        # these distinctness assumptions, to avoid this renaming.
        ixes = freshen_columns [internal.name] self.context.meta_index
        new_ctx = self.context.set_index ixes
        Column internal.name self.connection internal.sql_type internal.expression new_ctx

    ## PRIVATE

       Returns a copy of this table with updated internal columns.

       Arguments:
       - columns: The columns with which to update this table.
    updated_columns : Vector Internal_Column -> Table
    updated_columns self internal_columns = Table self.name self.connection internal_columns self.context

    ## PRIVATE

       Returns a copy of this table with updated context.

       Arguments:
       - ctx: The new context for this table.
    updated_context : Context -> Table
    updated_context self ctx = Table self.name self.connection self.internal_columns ctx

    ## PRIVATE

       Returns a copy of this table with updated context and columns.

       Arguments:
       - ctx: The new context for this table.
       - internal_columns: The new columns to include in the table.
    updated_context_and_columns : Context -> Vector Internal_Column -> Table
    updated_context_and_columns self ctx internal_columns = Table self.name self.connection internal_columns ctx

    ## PRIVATE

       Returns a vector that contains first the internal representations of all
       indices and then all columns.
    internal_columns_with_index : Vector Internal_Column
    internal_columns_with_index self =
        self.context.meta_index + self.internal_columns


    ## PRIVATE

       Inserts a new row to the table.

       Arguments:
       - values: The values making up the row of the table.

       It actually modifies the underlying table in the database.  It can only
       be called on the Table if no operations modifying it have been performed
       like modifying, removing or adding columns, filtering, grouping etc.
    insert : Vector Any -> Nothing
    insert self values =
        table_name = case self.context.from_spec of
            IR.From_Table name _ -> name
            _ -> Error.throw <| Illegal_State_Error "Inserting can only be performed on tables as returned by `access_table`, any further processing is not allowed."
        # TODO [RW] before removing the PRIVATE tag, add a check that no bad stuff was done to the table as described above
        pairs = self.internal_columns.zip values col-> value->
            [col.name, IR.Constant col.sql_type value]
        query = self.connection.dialect.generate_sql <| IR.Insert table_name pairs
        affected_rows = self.connection.execute_update query
        case affected_rows == 1 of
            False -> Error.throw <| Illegal_State_Error "The update unexpectedly affected "+affected_rows.to_text+" rows."
            True -> Nothing

    ## This function writes the table into a file.

       The specific behavior of the various `File_Format`s is specified below.

       Arguments:
       - path: The path to the output file.
       - format: The format of the file.
         If `File_Format.Auto` is specified; the file extension determines the
         specific type and uses the default settings for that type to be used.
         Details of this type are below.
       - on_existing_file: Specified how to handle if the file already exists.
       - match_columns: Specifies how to match columns against an existing file.
         If `Match_Columns.By_Name` - the columns are mapped by name against an
         existing file. If there is a mismatch, then a `Column_Name_Mismatch`
         error is raised.
         If `Match_Columns.By_Position` - the columns are mapped by position
         against an existing file. If there is a mismatch, then a
         `Column_Count_Mismatch` error is raised.
       - on_problems: Specifies how to handle if a problem occurs, raising as a
         warning by default. The specific issues depend on the `File_Format`
         argument.

       Returns:
       - If an unsupported `File_Format` is specified, an
         `Illegal_Argument_Error` is raised.
       - If the path to the parent location cannot be found or the filename is
         invalid, a `File_Not_Found` is raised.
       - If another IO error occurs, such as access denied, an `IO_Error` is
         raised.
       - If appending and the columns do not match, a `Column_Mismatch` is
         raised.
       - Other specific errors or warnings that can be raised depend on the
         format argument.
       - Otherwise, the file is loaded following the rules of the format
         parameter.

       ? `File_Format` write behaviors

         - `File_Format.Auto`: The file format is determined by the file
           extension of the path argument.
         - `File_Format.Bytes` and `File_Format.Text`: The Table does not
           support these types in the `write` function. If passed as format, an
           `Illegal_Argument_Error` is raised. To write out the table as plain
           text, the user needs to call the `Text.from Table` method and then
           use the `Text.write` function.

       > Example
         Write a database table to a CSV file.

             import Standard.Examples
             import Standard.Database

             example_to_csv =
                 connection = Database.connect (SQLite (File.new "db.sqlite"))
                 table = connection.access_table "Table"
                 table.write (enso_project.data / "example_csv_output.csv")
    write : File|Text -> File_Format -> Existing_File_Behavior -> Match_Columns -> Problem_Behavior -> Nothing ! Column_Mismatch | Illegal_Argument_Error | File_Not_Found | IO_Error
    write self path format=File_Format.Auto on_existing_file=Existing_File_Behavior.Backup match_columns=Match_Columns.By_Name on_problems=Report_Warning =
        # TODO This should ideally be done in a streaming manner, or at least respect the row limits.
        self.to_dataframe.write path format on_existing_file match_columns on_problems

type Integrity_Error

    ## UNSTABLE

       Signalizes that an operation tried using objects coming from different
       contexts.

       To use columns from different tables, you must first join them.
    type Integrity_Error object_description

    # Return a readable description of this error.
    to_text : Text
    to_text self = self.object_description + " comes from a different context."

    to_display_text : Text
    to_display_text self = self.to_text

## PRIVATE

   Creates a Table out of a connection, name and list of column names.

   Arguments:
   - connection: The connection to a database.
   - table_name: The name of the table to get.
   - columns: The names of the columns to get.
# make_table : Connection -> Text -> Vector [Text, Sql.Sql_Type] -> Table
make_table : Connection -> Text -> Vector -> Table
make_table connection table_name columns =
    ctx = IR.make_ctx_from table_name
    cols = columns.map (p -> Internal_Column p.first p.second (IR.Column table_name p.first))
    Table table_name connection cols ctx

## PRIVATE

   Renders an ASCII-art representation for a Table from a dataframe that
   contains a fragment of the underlying data and count of all rows.

   Arguments:
   - df: The materialized dataframe that contains the data to be displayed, it
     should have no indices set.
   - indices_count: Indicates how many columns from the materialized dataframe
     should be treated as indices in the display (index columns will be bold if
     `format_terminal` is enabled).
   - all_rows_count: The count of all rows in the underlying Table; if
     `all_rows_count` is bigger than the amount of rows of `df`, an additional
     line will be included that will say how many hidden rows there are.
   - format_term: A boolean flag, specifying whether to use ANSI escape codes
     for rich formatting in the terminal.
display_dataframe : Materialized_Table.Table -> Integer -> Integer -> Boolean -> Text
display_dataframe df indices_count all_rows_count format_terminal =
    cols = Vector.Vector df.java_table.getColumns
    col_names = cols.map .getName
    col_vals = cols.map .getStorage
    display_rows = df.row_count
    rows = Vector.new display_rows row_num->
        col_vals.map col->
            if col.isNa row_num then "Nothing" else Materialized_Column.get_item_string col row_num
    table = Materialized_Table.print_table col_names rows indices_count format_terminal
    if display_rows == all_rows_count then table else
        missing_rows_count = all_rows_count - display_rows
        missing = '\n\u2026 and ' + missing_rows_count.to_text + ' hidden rows.'
        table + missing

## PRIVATE

   Creates a list of non-colliding names by merging the two lists and
   appending suffixes if necessary.

   Arguments:
   - left_names: The names on the left.
   - right_names: The names on the right.
   - left_suffix: The suffix to apply to colliding names on the left.
   - right_suffix: The suffix to apply to colliding names on the right.

   If even after appending the suffixes it is impossible to have unique names,
   it throws a panic. It returns two vectors, one for each input. It assumes
   that the names within each argument itself are unique.
combine_names left_names right_names left_suffix right_suffix =
    make_count_map names =
        map = names.fold Map.empty acc-> name->
            count = acc.get_or_else name 0 + 1
            acc.insert name count
        name-> map.get_or_else name 0
    original_names_count = make_count_map left_names+right_names
    add_suffix_if_necessary suffix name = case original_names_count name > 1 of
        True -> [name, name+suffix]
        False -> [name, name]
    left_pairs = left_names.map <| add_suffix_if_necessary left_suffix
    right_pairs = right_names.map <| add_suffix_if_necessary right_suffix

    new_names_count = make_count_map (left_pairs+right_pairs . map .second)
    catch_ambiguity pairs = pairs.each pair->
        original_name = pair.first
        new_name = pair.second
        case new_name!=original_name && (new_names_count new_name > 1) of
            True ->
                Panic.throw <| Illegal_State_Error "Duplicate column "+original_name+" was about to be renamed to "+new_name+" to disambiguate column names, but a column with name "+new_name+" already exists too. Please rename the columns before joining to avoid ambiguity."
            False -> Nothing
    catch_ambiguity left_pairs
    catch_ambiguity right_pairs
    new_left_names = left_pairs.map .second
    new_right_names = right_pairs.map .second
    [new_left_names, new_right_names]

## PRIVATE

   Transforms `preferred_names` names in such a way to not collide with
   `used_names`.

   Arguments:
   - used_names: The names that have already been used.
   - preferred_names: The names that the user wants to use.

   If a name from `preferred_names` does not collide with others, it is kept as
   is, otherwise numerical suffixes are added.
fresh_names : Vector Text -> Vector Text -> Vector Text
fresh_names used_names preferred_names =
   freshen currently_used name ix =
       new_name = if ix == 0 then name else name+"_"+ix.to_text
       case currently_used.contains new_name of
           False -> new_name
           True -> freshen currently_used name ix+1
   res = preferred_names . fold [used_names, []] acc-> name->
       used = acc.first
       new_name = freshen used name 0
       [used_names + [new_name], acc.second + [new_name]]
   res.second

## PRIVATE

   Transforms the vector of columns, changing names of each column to the
   corresponding name from the second vector.

   Arguments:
   - columns: A vector of columns to rename.
   - new_names: The new names for the columns.
internal_rename_columns : Vector Internal_Column -> Vector Text -> Vector Internal_Column
internal_rename_columns columns new_names =
    columns.zip new_names col-> name->
        col.rename name

## PRIVATE

   Ensures that the provided columns do not clash with the vector of names
   provided as first argument.

   Arguments:
   - used_names: The already used names.
   - columns: The columns to rename to avoid clashes.

   Original column names are kept if possible, but if they would clash, the
   columns are renamed.
freshen_columns : Vector Text -> Vector Internal_Column -> Vector Internal_Column
freshen_columns used_names columns =
    new_names = fresh_names used_names (columns.map .name)
    internal_rename_columns columns new_names

